2024-05-17 07:46:26,292:INFO: device: cuda:0 n_gpu: 1
2024-05-17 07:46:26,359:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-17 07:46:26,652:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-17 07:46:26,652:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-17 07:46:26,652:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-17 07:46:26,653:WARNING: 	 embed_dim: 512
2024-05-17 07:46:26,653:WARNING: 	 image_resolution: 224
2024-05-17 07:46:26,654:WARNING: 	 vision_layers: 12
2024-05-17 07:46:26,654:WARNING: 	 vision_width: 768
2024-05-17 07:46:26,654:WARNING: 	 vision_patch_size: 32
2024-05-17 07:46:26,654:WARNING: 	 context_length: 77
2024-05-17 07:46:26,654:WARNING: 	 vocab_size: 49408
2024-05-17 07:46:26,654:WARNING: 	 transformer_width: 512
2024-05-17 07:46:26,654:WARNING: 	 transformer_heads: 8
2024-05-17 07:46:26,654:WARNING: 	 transformer_layers: 12
2024-05-17 07:46:26,654:WARNING: 	 cut_top_layer: 0
2024-05-17 07:46:27,668:WARNING: 	 sim_type: seqTransf
2024-05-17 07:46:32,164:INFO: --------------------
2024-05-17 07:46:32,165:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-17 07:46:34,386:INFO: ***** Running test *****
2024-05-17 07:46:34,386:INFO:   Num examples = 29
2024-05-17 07:46:34,386:INFO:   Batch size = 64
2024-05-17 07:46:34,386:INFO:   Num steps = 1
2024-05-17 07:47:40,111:INFO: device: cuda:0 n_gpu: 1
2024-05-17 07:47:40,180:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-17 07:47:40,402:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-17 07:47:40,402:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-17 07:47:40,403:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-17 07:47:40,403:WARNING: 	 embed_dim: 512
2024-05-17 07:47:40,403:WARNING: 	 image_resolution: 224
2024-05-17 07:47:40,403:WARNING: 	 vision_layers: 12
2024-05-17 07:47:40,403:WARNING: 	 vision_width: 768
2024-05-17 07:47:40,403:WARNING: 	 vision_patch_size: 32
2024-05-17 07:47:40,403:WARNING: 	 context_length: 77
2024-05-17 07:47:40,403:WARNING: 	 vocab_size: 49408
2024-05-17 07:47:40,403:WARNING: 	 transformer_width: 512
2024-05-17 07:47:40,403:WARNING: 	 transformer_heads: 8
2024-05-17 07:47:40,403:WARNING: 	 transformer_layers: 12
2024-05-17 07:47:40,403:WARNING: 	 cut_top_layer: 0
2024-05-17 07:47:41,369:WARNING: 	 sim_type: seqTransf
2024-05-17 07:47:45,847:INFO: --------------------
2024-05-17 07:47:45,847:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-17 07:47:47,607:INFO: ***** Running test *****
2024-05-17 07:47:47,607:INFO:   Num examples = 29
2024-05-17 07:47:47,607:INFO:   Batch size = 64
2024-05-17 07:47:47,607:INFO:   Num steps = 1
2024-05-17 08:05:24,743:INFO: device: cuda:0 n_gpu: 1
2024-05-17 08:05:24,813:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-17 08:05:25,024:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-17 08:05:25,024:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-17 08:05:25,024:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-17 08:05:25,024:WARNING: 	 embed_dim: 512
2024-05-17 08:05:25,024:WARNING: 	 image_resolution: 224
2024-05-17 08:05:25,024:WARNING: 	 vision_layers: 12
2024-05-17 08:05:25,024:WARNING: 	 vision_width: 768
2024-05-17 08:05:25,024:WARNING: 	 vision_patch_size: 32
2024-05-17 08:05:25,024:WARNING: 	 context_length: 77
2024-05-17 08:05:25,024:WARNING: 	 vocab_size: 49408
2024-05-17 08:05:25,025:WARNING: 	 transformer_width: 512
2024-05-17 08:05:25,025:WARNING: 	 transformer_heads: 8
2024-05-17 08:05:25,025:WARNING: 	 transformer_layers: 12
2024-05-17 08:05:25,025:WARNING: 	 cut_top_layer: 0
2024-05-17 08:05:25,977:WARNING: 	 sim_type: seqTransf
2024-05-17 08:05:30,439:INFO: --------------------
2024-05-17 08:05:30,439:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-17 08:05:32,164:INFO: ***** Running test *****
2024-05-17 08:05:32,164:INFO:   Num examples = 1
2024-05-17 08:05:32,164:INFO:   Batch size = 64
2024-05-17 08:05:32,164:INFO:   Num steps = 1
2024-05-17 08:05:32,974:INFO: sim matrix size: 1, 1
2024-05-17 08:05:32,974:INFO: 	 Length-T: 1, Length-V:1
2024-05-17 08:05:32,974:INFO: Text-to-Video:
2024-05-17 08:05:32,974:INFO: 	>>>  R@1: 100.0 - R@5: 100.0 - R@10: 100.0 - Median R: 1.0 - Mean R: 1.0
2024-05-17 08:05:32,974:INFO: Video-to-Text:
2024-05-17 08:05:32,974:INFO: 	>>>  V2T$R@1: 100.0 - V2T$R@5: 100.0 - V2T$R@10: 100.0 - V2T$Median R: 1.0 - V2T$Mean R: 1.0
2024-05-17 08:07:19,273:INFO: device: cuda:0 n_gpu: 1
2024-05-17 08:07:19,340:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-17 08:07:19,564:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-17 08:07:19,565:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-17 08:07:19,565:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-17 08:07:19,566:WARNING: 	 embed_dim: 512
2024-05-17 08:07:19,566:WARNING: 	 image_resolution: 224
2024-05-17 08:07:19,566:WARNING: 	 vision_layers: 12
2024-05-17 08:07:19,566:WARNING: 	 vision_width: 768
2024-05-17 08:07:19,566:WARNING: 	 vision_patch_size: 32
2024-05-17 08:07:19,566:WARNING: 	 context_length: 77
2024-05-17 08:07:19,566:WARNING: 	 vocab_size: 49408
2024-05-17 08:07:19,566:WARNING: 	 transformer_width: 512
2024-05-17 08:07:19,566:WARNING: 	 transformer_heads: 8
2024-05-17 08:07:19,567:WARNING: 	 transformer_layers: 12
2024-05-17 08:07:19,567:WARNING: 	 cut_top_layer: 0
2024-05-17 08:07:20,549:WARNING: 	 sim_type: seqTransf
2024-05-17 08:07:25,075:INFO: --------------------
2024-05-17 08:07:25,075:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-17 08:07:26,814:INFO: ***** Running test *****
2024-05-17 08:07:26,814:INFO:   Num examples = 1
2024-05-17 08:07:26,814:INFO:   Batch size = 64
2024-05-17 08:07:26,814:INFO:   Num steps = 1
2024-05-18 09:15:09,654:INFO: device: cuda:0 n_gpu: 1
2024-05-18 09:15:09,725:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-18 09:15:10,643:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-18 09:15:10,644:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-18 09:15:10,644:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-18 09:15:10,645:WARNING: 	 embed_dim: 512
2024-05-18 09:15:10,645:WARNING: 	 image_resolution: 224
2024-05-18 09:15:10,645:WARNING: 	 vision_layers: 12
2024-05-18 09:15:10,645:WARNING: 	 vision_width: 768
2024-05-18 09:15:10,645:WARNING: 	 vision_patch_size: 32
2024-05-18 09:15:10,645:WARNING: 	 context_length: 77
2024-05-18 09:15:10,645:WARNING: 	 vocab_size: 49408
2024-05-18 09:15:10,645:WARNING: 	 transformer_width: 512
2024-05-18 09:15:10,645:WARNING: 	 transformer_heads: 8
2024-05-18 09:15:10,645:WARNING: 	 transformer_layers: 12
2024-05-18 09:15:10,646:WARNING: 	 cut_top_layer: 0
2024-05-18 09:15:11,530:WARNING: 	 sim_type: seqTransf
2024-05-18 09:15:15,363:INFO: --------------------
2024-05-18 09:15:15,364:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-18 09:15:19,705:INFO: ***** Running test *****
2024-05-18 09:15:19,705:INFO:   Num examples = 1
2024-05-18 09:15:19,705:INFO:   Batch size = 64
2024-05-18 09:15:19,705:INFO:   Num steps = 1
2024-05-18 12:36:15,166:INFO: sim matrix size: 1, 1
2024-05-18 12:36:32,941:INFO: 	 Length-T: 1, Length-V:1
2024-05-18 12:36:34,610:INFO: Text-to-Video:
2024-05-18 12:36:36,084:INFO: 	>>>  R@1: 100.0 - R@5: 100.0 - R@10: 100.0 - Median R: 1.0 - Mean R: 1.0
2024-05-18 12:36:36,838:INFO: Video-to-Text:
2024-05-18 12:36:41,514:INFO: 	>>>  V2T$R@1: 100.0 - V2T$R@5: 100.0 - V2T$R@10: 100.0 - V2T$Median R: 1.0 - V2T$Mean R: 1.0
2024-05-19 04:47:46,567:INFO: device: cuda:0 n_gpu: 1
2024-05-19 04:47:46,634:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-19 04:47:47,553:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-19 04:47:47,554:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-19 04:47:47,554:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-19 04:47:47,555:WARNING: 	 embed_dim: 512
2024-05-19 04:47:47,555:WARNING: 	 image_resolution: 224
2024-05-19 04:47:47,555:WARNING: 	 vision_layers: 12
2024-05-19 04:47:47,555:WARNING: 	 vision_width: 768
2024-05-19 04:47:47,555:WARNING: 	 vision_patch_size: 32
2024-05-19 04:47:47,555:WARNING: 	 context_length: 77
2024-05-19 04:47:47,555:WARNING: 	 vocab_size: 49408
2024-05-19 04:47:47,555:WARNING: 	 transformer_width: 512
2024-05-19 04:47:47,555:WARNING: 	 transformer_heads: 8
2024-05-19 04:47:47,555:WARNING: 	 transformer_layers: 12
2024-05-19 04:47:47,555:WARNING: 	 cut_top_layer: 0
2024-05-19 04:47:48,437:WARNING: 	 sim_type: seqTransf
2024-05-19 04:47:52,270:INFO: --------------------
2024-05-19 04:47:52,270:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-19 04:47:56,610:INFO: ***** Running test *****
2024-05-19 04:47:56,610:INFO:   Num examples = 1
2024-05-19 04:47:56,610:INFO:   Batch size = 64
2024-05-19 04:47:56,611:INFO:   Num steps = 1
2024-05-19 05:48:39,127:INFO: device: cuda:0 n_gpu: 1
2024-05-19 05:48:39,128:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-19 05:48:39,360:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-19 05:48:39,360:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-19 05:48:39,360:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-19 05:48:39,361:WARNING: 	 embed_dim: 512
2024-05-19 05:48:39,361:WARNING: 	 image_resolution: 224
2024-05-19 05:48:39,362:WARNING: 	 vision_layers: 12
2024-05-19 05:48:39,362:WARNING: 	 vision_width: 768
2024-05-19 05:48:39,362:WARNING: 	 vision_patch_size: 32
2024-05-19 05:48:39,362:WARNING: 	 context_length: 77
2024-05-19 05:48:39,362:WARNING: 	 vocab_size: 49408
2024-05-19 05:48:39,362:WARNING: 	 transformer_width: 512
2024-05-19 05:48:39,362:WARNING: 	 transformer_heads: 8
2024-05-19 05:48:39,362:WARNING: 	 transformer_layers: 12
2024-05-19 05:48:39,362:WARNING: 	 cut_top_layer: 0
2024-05-19 05:48:40,235:WARNING: 	 sim_type: seqTransf
2024-05-19 05:48:44,007:INFO: --------------------
2024-05-19 05:48:44,007:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-19 05:49:50,608:INFO: device: cuda:0 n_gpu: 1
2024-05-19 05:49:50,609:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-19 05:49:50,838:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-19 05:49:50,839:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-19 05:49:50,839:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-19 05:49:50,840:WARNING: 	 embed_dim: 512
2024-05-19 05:49:50,840:WARNING: 	 image_resolution: 224
2024-05-19 05:49:50,840:WARNING: 	 vision_layers: 12
2024-05-19 05:49:50,840:WARNING: 	 vision_width: 768
2024-05-19 05:49:50,840:WARNING: 	 vision_patch_size: 32
2024-05-19 05:49:50,840:WARNING: 	 context_length: 77
2024-05-19 05:49:50,840:WARNING: 	 vocab_size: 49408
2024-05-19 05:49:50,840:WARNING: 	 transformer_width: 512
2024-05-19 05:49:50,840:WARNING: 	 transformer_heads: 8
2024-05-19 05:49:50,840:WARNING: 	 transformer_layers: 12
2024-05-19 05:49:50,840:WARNING: 	 cut_top_layer: 0
2024-05-19 05:49:51,696:WARNING: 	 sim_type: seqTransf
2024-05-19 05:49:55,498:INFO: --------------------
2024-05-19 05:49:55,498:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-19 05:50:28,644:INFO: device: cuda:0 n_gpu: 1
2024-05-19 05:50:28,644:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-19 05:50:28,869:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-19 05:50:28,869:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-19 05:50:28,869:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-19 05:50:28,870:WARNING: 	 embed_dim: 512
2024-05-19 05:50:28,870:WARNING: 	 image_resolution: 224
2024-05-19 05:50:28,870:WARNING: 	 vision_layers: 12
2024-05-19 05:50:28,871:WARNING: 	 vision_width: 768
2024-05-19 05:50:28,871:WARNING: 	 vision_patch_size: 32
2024-05-19 05:50:28,871:WARNING: 	 context_length: 77
2024-05-19 05:50:28,871:WARNING: 	 vocab_size: 49408
2024-05-19 05:50:28,871:WARNING: 	 transformer_width: 512
2024-05-19 05:50:28,871:WARNING: 	 transformer_heads: 8
2024-05-19 05:50:28,871:WARNING: 	 transformer_layers: 12
2024-05-19 05:50:28,871:WARNING: 	 cut_top_layer: 0
2024-05-19 05:50:29,720:WARNING: 	 sim_type: seqTransf
2024-05-19 05:50:33,517:INFO: --------------------
2024-05-19 05:50:33,517:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-19 05:51:07,401:INFO: device: cuda:0 n_gpu: 1
2024-05-19 05:51:07,402:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-19 05:51:07,626:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-19 05:51:07,627:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-19 05:51:07,627:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-19 05:51:07,628:WARNING: 	 embed_dim: 512
2024-05-19 05:51:07,628:WARNING: 	 image_resolution: 224
2024-05-19 05:51:07,628:WARNING: 	 vision_layers: 12
2024-05-19 05:51:07,628:WARNING: 	 vision_width: 768
2024-05-19 05:51:07,628:WARNING: 	 vision_patch_size: 32
2024-05-19 05:51:07,628:WARNING: 	 context_length: 77
2024-05-19 05:51:07,628:WARNING: 	 vocab_size: 49408
2024-05-19 05:51:07,628:WARNING: 	 transformer_width: 512
2024-05-19 05:51:07,628:WARNING: 	 transformer_heads: 8
2024-05-19 05:51:07,628:WARNING: 	 transformer_layers: 12
2024-05-19 05:51:07,628:WARNING: 	 cut_top_layer: 0
2024-05-19 05:51:08,526:WARNING: 	 sim_type: seqTransf
2024-05-19 05:51:12,317:INFO: --------------------
2024-05-19 05:51:12,317:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-19 05:53:21,796:INFO: device: cuda:0 n_gpu: 1
2024-05-19 05:53:21,796:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-19 05:53:22,023:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-19 05:53:22,024:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-19 05:53:22,024:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-19 05:53:22,025:WARNING: 	 embed_dim: 512
2024-05-19 05:53:22,025:WARNING: 	 image_resolution: 224
2024-05-19 05:53:22,025:WARNING: 	 vision_layers: 12
2024-05-19 05:53:22,025:WARNING: 	 vision_width: 768
2024-05-19 05:53:22,025:WARNING: 	 vision_patch_size: 32
2024-05-19 05:53:22,025:WARNING: 	 context_length: 77
2024-05-19 05:53:22,025:WARNING: 	 vocab_size: 49408
2024-05-19 05:53:22,026:WARNING: 	 transformer_width: 512
2024-05-19 05:53:22,026:WARNING: 	 transformer_heads: 8
2024-05-19 05:53:22,026:WARNING: 	 transformer_layers: 12
2024-05-19 05:53:22,026:WARNING: 	 cut_top_layer: 0
2024-05-19 05:53:22,903:WARNING: 	 sim_type: seqTransf
2024-05-19 05:53:26,695:INFO: --------------------
2024-05-19 05:53:26,695:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-19 06:01:24,512:INFO: device: cuda:0 n_gpu: 1
2024-05-19 06:01:24,512:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-19 06:01:24,742:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-19 06:01:24,743:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-19 06:01:24,743:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-19 06:01:24,744:WARNING: 	 embed_dim: 512
2024-05-19 06:01:24,744:WARNING: 	 image_resolution: 224
2024-05-19 06:01:24,744:WARNING: 	 vision_layers: 12
2024-05-19 06:01:24,744:WARNING: 	 vision_width: 768
2024-05-19 06:01:24,744:WARNING: 	 vision_patch_size: 32
2024-05-19 06:01:24,744:WARNING: 	 context_length: 77
2024-05-19 06:01:24,744:WARNING: 	 vocab_size: 49408
2024-05-19 06:01:24,744:WARNING: 	 transformer_width: 512
2024-05-19 06:01:24,744:WARNING: 	 transformer_heads: 8
2024-05-19 06:01:24,744:WARNING: 	 transformer_layers: 12
2024-05-19 06:01:24,744:WARNING: 	 cut_top_layer: 0
2024-05-19 06:01:25,594:WARNING: 	 sim_type: seqTransf
2024-05-19 06:01:29,371:INFO: --------------------
2024-05-19 06:01:29,371:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-19 06:05:03,280:INFO: device: cuda:0 n_gpu: 1
2024-05-19 06:05:03,280:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-19 06:05:03,510:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-19 06:05:03,512:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-19 06:05:03,512:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-19 06:05:03,512:WARNING: 	 embed_dim: 512
2024-05-19 06:05:03,512:WARNING: 	 image_resolution: 224
2024-05-19 06:05:03,513:WARNING: 	 vision_layers: 12
2024-05-19 06:05:03,513:WARNING: 	 vision_width: 768
2024-05-19 06:05:03,513:WARNING: 	 vision_patch_size: 32
2024-05-19 06:05:03,513:WARNING: 	 context_length: 77
2024-05-19 06:05:03,513:WARNING: 	 vocab_size: 49408
2024-05-19 06:05:03,513:WARNING: 	 transformer_width: 512
2024-05-19 06:05:03,513:WARNING: 	 transformer_heads: 8
2024-05-19 06:05:03,513:WARNING: 	 transformer_layers: 12
2024-05-19 06:05:03,513:WARNING: 	 cut_top_layer: 0
2024-05-19 06:05:04,394:WARNING: 	 sim_type: seqTransf
2024-05-19 06:05:08,215:INFO: --------------------
2024-05-19 06:05:08,215:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-19 06:09:06,444:INFO: device: cuda:0 n_gpu: 1
2024-05-19 06:09:06,514:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-19 06:09:06,744:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-19 06:09:06,746:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-19 06:09:06,746:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-19 06:09:06,746:WARNING: 	 embed_dim: 512
2024-05-19 06:09:06,747:WARNING: 	 image_resolution: 224
2024-05-19 06:09:06,747:WARNING: 	 vision_layers: 12
2024-05-19 06:09:06,747:WARNING: 	 vision_width: 768
2024-05-19 06:09:06,747:WARNING: 	 vision_patch_size: 32
2024-05-19 06:09:06,747:WARNING: 	 context_length: 77
2024-05-19 06:09:06,747:WARNING: 	 vocab_size: 49408
2024-05-19 06:09:06,747:WARNING: 	 transformer_width: 512
2024-05-19 06:09:06,747:WARNING: 	 transformer_heads: 8
2024-05-19 06:09:06,747:WARNING: 	 transformer_layers: 12
2024-05-19 06:09:06,747:WARNING: 	 cut_top_layer: 0
2024-05-19 06:09:07,602:WARNING: 	 sim_type: seqTransf
2024-05-19 06:09:11,392:INFO: --------------------
2024-05-19 06:09:11,392:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-19 06:09:13,520:INFO: ***** Running test *****
2024-05-19 06:09:13,521:INFO:   Num examples = 1
2024-05-19 06:09:13,521:INFO:   Batch size = 64
2024-05-19 06:09:13,521:INFO:   Num steps = 1
2024-05-19 06:10:07,169:INFO: device: cuda:0 n_gpu: 1
2024-05-19 06:10:07,238:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-19 06:10:07,469:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-19 06:10:07,470:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-19 06:10:07,470:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-19 06:10:07,471:WARNING: 	 embed_dim: 512
2024-05-19 06:10:07,471:WARNING: 	 image_resolution: 224
2024-05-19 06:10:07,471:WARNING: 	 vision_layers: 12
2024-05-19 06:10:07,471:WARNING: 	 vision_width: 768
2024-05-19 06:10:07,471:WARNING: 	 vision_patch_size: 32
2024-05-19 06:10:07,471:WARNING: 	 context_length: 77
2024-05-19 06:10:07,471:WARNING: 	 vocab_size: 49408
2024-05-19 06:10:07,471:WARNING: 	 transformer_width: 512
2024-05-19 06:10:07,471:WARNING: 	 transformer_heads: 8
2024-05-19 06:10:07,472:WARNING: 	 transformer_layers: 12
2024-05-19 06:10:07,472:WARNING: 	 cut_top_layer: 0
2024-05-19 06:10:08,323:WARNING: 	 sim_type: seqTransf
2024-05-19 06:10:12,120:INFO: --------------------
2024-05-19 06:10:12,121:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-19 06:10:14,212:INFO: ***** Running test *****
2024-05-19 06:10:14,212:INFO:   Num examples = 1
2024-05-19 06:10:14,212:INFO:   Batch size = 64
2024-05-19 06:10:14,212:INFO:   Num steps = 1
2024-05-19 06:11:18,641:INFO: device: cuda:0 n_gpu: 1
2024-05-19 06:11:18,711:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-19 06:11:18,948:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-19 06:11:18,949:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-19 06:11:18,949:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-19 06:11:18,950:WARNING: 	 embed_dim: 512
2024-05-19 06:11:18,950:WARNING: 	 image_resolution: 224
2024-05-19 06:11:18,950:WARNING: 	 vision_layers: 12
2024-05-19 06:11:18,950:WARNING: 	 vision_width: 768
2024-05-19 06:11:18,950:WARNING: 	 vision_patch_size: 32
2024-05-19 06:11:18,950:WARNING: 	 context_length: 77
2024-05-19 06:11:18,950:WARNING: 	 vocab_size: 49408
2024-05-19 06:11:18,950:WARNING: 	 transformer_width: 512
2024-05-19 06:11:18,950:WARNING: 	 transformer_heads: 8
2024-05-19 06:11:18,951:WARNING: 	 transformer_layers: 12
2024-05-19 06:11:18,951:WARNING: 	 cut_top_layer: 0
2024-05-19 06:11:19,824:WARNING: 	 sim_type: seqTransf
2024-05-19 06:11:23,657:INFO: --------------------
2024-05-19 06:11:23,657:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-19 06:11:25,781:INFO: ***** Running test *****
2024-05-19 06:11:25,781:INFO:   Num examples = 1
2024-05-19 06:11:25,781:INFO:   Batch size = 64
2024-05-19 06:11:25,781:INFO:   Num steps = 1
2024-05-19 06:12:13,949:INFO: device: cuda:0 n_gpu: 1
2024-05-19 06:12:14,018:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-19 06:12:14,257:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-19 06:12:14,259:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-19 06:12:14,259:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-19 06:12:14,260:WARNING: 	 embed_dim: 512
2024-05-19 06:12:14,260:WARNING: 	 image_resolution: 224
2024-05-19 06:12:14,260:WARNING: 	 vision_layers: 12
2024-05-19 06:12:14,260:WARNING: 	 vision_width: 768
2024-05-19 06:12:14,260:WARNING: 	 vision_patch_size: 32
2024-05-19 06:12:14,260:WARNING: 	 context_length: 77
2024-05-19 06:12:14,260:WARNING: 	 vocab_size: 49408
2024-05-19 06:12:14,260:WARNING: 	 transformer_width: 512
2024-05-19 06:12:14,260:WARNING: 	 transformer_heads: 8
2024-05-19 06:12:14,260:WARNING: 	 transformer_layers: 12
2024-05-19 06:12:14,260:WARNING: 	 cut_top_layer: 0
2024-05-19 06:12:15,121:WARNING: 	 sim_type: seqTransf
2024-05-19 06:12:18,899:INFO: --------------------
2024-05-19 06:12:18,899:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-19 06:12:20,984:INFO: ***** Running test *****
2024-05-19 06:12:20,984:INFO:   Num examples = 1
2024-05-19 06:12:20,984:INFO:   Batch size = 64
2024-05-19 06:12:20,984:INFO:   Num steps = 1
2024-05-19 06:14:24,249:INFO: device: cuda:0 n_gpu: 1
2024-05-19 06:14:24,249:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-19 06:14:24,482:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-19 06:14:24,483:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-19 06:14:24,483:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-19 06:14:24,484:WARNING: 	 embed_dim: 512
2024-05-19 06:14:24,484:WARNING: 	 image_resolution: 224
2024-05-19 06:14:24,484:WARNING: 	 vision_layers: 12
2024-05-19 06:14:24,484:WARNING: 	 vision_width: 768
2024-05-19 06:14:24,484:WARNING: 	 vision_patch_size: 32
2024-05-19 06:14:24,484:WARNING: 	 context_length: 77
2024-05-19 06:14:24,484:WARNING: 	 vocab_size: 49408
2024-05-19 06:14:24,484:WARNING: 	 transformer_width: 512
2024-05-19 06:14:24,485:WARNING: 	 transformer_heads: 8
2024-05-19 06:14:24,485:WARNING: 	 transformer_layers: 12
2024-05-19 06:14:24,485:WARNING: 	 cut_top_layer: 0
2024-05-19 06:14:25,351:WARNING: 	 sim_type: seqTransf
2024-05-19 06:14:29,172:INFO: --------------------
2024-05-19 06:14:29,172:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-19 06:17:55,708:INFO: device: cuda:0 n_gpu: 1
2024-05-19 06:17:55,709:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-19 06:17:55,938:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-19 06:17:55,939:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-19 06:17:55,940:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-19 06:17:55,940:WARNING: 	 embed_dim: 512
2024-05-19 06:17:55,940:WARNING: 	 image_resolution: 224
2024-05-19 06:17:55,941:WARNING: 	 vision_layers: 12
2024-05-19 06:17:55,941:WARNING: 	 vision_width: 768
2024-05-19 06:17:55,941:WARNING: 	 vision_patch_size: 32
2024-05-19 06:17:55,941:WARNING: 	 context_length: 77
2024-05-19 06:17:55,941:WARNING: 	 vocab_size: 49408
2024-05-19 06:17:55,941:WARNING: 	 transformer_width: 512
2024-05-19 06:17:55,941:WARNING: 	 transformer_heads: 8
2024-05-19 06:17:55,941:WARNING: 	 transformer_layers: 12
2024-05-19 06:17:55,941:WARNING: 	 cut_top_layer: 0
2024-05-19 06:17:56,801:WARNING: 	 sim_type: seqTransf
2024-05-19 06:18:00,622:INFO: --------------------
2024-05-19 06:18:00,622:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-19 06:19:28,437:INFO: device: cuda:0 n_gpu: 1
2024-05-19 06:19:28,438:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-19 06:19:28,675:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-19 06:19:28,676:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-19 06:19:28,676:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-19 06:19:28,677:WARNING: 	 embed_dim: 512
2024-05-19 06:19:28,677:WARNING: 	 image_resolution: 224
2024-05-19 06:19:28,677:WARNING: 	 vision_layers: 12
2024-05-19 06:19:28,677:WARNING: 	 vision_width: 768
2024-05-19 06:19:28,678:WARNING: 	 vision_patch_size: 32
2024-05-19 06:19:28,678:WARNING: 	 context_length: 77
2024-05-19 06:19:28,678:WARNING: 	 vocab_size: 49408
2024-05-19 06:19:28,678:WARNING: 	 transformer_width: 512
2024-05-19 06:19:28,678:WARNING: 	 transformer_heads: 8
2024-05-19 06:19:28,678:WARNING: 	 transformer_layers: 12
2024-05-19 06:19:28,678:WARNING: 	 cut_top_layer: 0
2024-05-19 06:19:29,570:WARNING: 	 sim_type: seqTransf
2024-05-19 06:19:33,380:INFO: --------------------
2024-05-19 06:19:33,381:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-19 06:20:34,412:INFO: device: cuda:0 n_gpu: 1
2024-05-19 06:20:34,412:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-19 06:20:34,643:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-19 06:20:34,644:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-19 06:20:34,644:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-19 06:20:34,645:WARNING: 	 embed_dim: 512
2024-05-19 06:20:34,645:WARNING: 	 image_resolution: 224
2024-05-19 06:20:34,645:WARNING: 	 vision_layers: 12
2024-05-19 06:20:34,645:WARNING: 	 vision_width: 768
2024-05-19 06:20:34,645:WARNING: 	 vision_patch_size: 32
2024-05-19 06:20:34,646:WARNING: 	 context_length: 77
2024-05-19 06:20:34,646:WARNING: 	 vocab_size: 49408
2024-05-19 06:20:34,646:WARNING: 	 transformer_width: 512
2024-05-19 06:20:34,646:WARNING: 	 transformer_heads: 8
2024-05-19 06:20:34,646:WARNING: 	 transformer_layers: 12
2024-05-19 06:20:34,646:WARNING: 	 cut_top_layer: 0
2024-05-19 06:20:35,536:WARNING: 	 sim_type: seqTransf
2024-05-19 06:20:39,321:INFO: --------------------
2024-05-19 06:20:39,321:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-19 06:21:20,037:INFO: device: cuda:0 n_gpu: 1
2024-05-19 06:21:20,037:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-19 06:21:20,277:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-19 06:21:20,278:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-19 06:21:20,278:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-19 06:21:20,279:WARNING: 	 embed_dim: 512
2024-05-19 06:21:20,279:WARNING: 	 image_resolution: 224
2024-05-19 06:21:20,279:WARNING: 	 vision_layers: 12
2024-05-19 06:21:20,279:WARNING: 	 vision_width: 768
2024-05-19 06:21:20,279:WARNING: 	 vision_patch_size: 32
2024-05-19 06:21:20,279:WARNING: 	 context_length: 77
2024-05-19 06:21:20,280:WARNING: 	 vocab_size: 49408
2024-05-19 06:21:20,280:WARNING: 	 transformer_width: 512
2024-05-19 06:21:20,280:WARNING: 	 transformer_heads: 8
2024-05-19 06:21:20,280:WARNING: 	 transformer_layers: 12
2024-05-19 06:21:20,280:WARNING: 	 cut_top_layer: 0
2024-05-19 06:21:21,169:WARNING: 	 sim_type: seqTransf
2024-05-19 06:21:24,987:INFO: --------------------
2024-05-19 06:21:24,987:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-19 06:30:52,080:INFO: device: cuda:0 n_gpu: 1
2024-05-19 06:30:52,081:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-19 06:30:52,319:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-19 06:30:52,320:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-19 06:30:52,320:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-19 06:30:52,321:WARNING: 	 embed_dim: 512
2024-05-19 06:30:52,321:WARNING: 	 image_resolution: 224
2024-05-19 06:30:52,321:WARNING: 	 vision_layers: 12
2024-05-19 06:30:52,321:WARNING: 	 vision_width: 768
2024-05-19 06:30:52,321:WARNING: 	 vision_patch_size: 32
2024-05-19 06:30:52,321:WARNING: 	 context_length: 77
2024-05-19 06:30:52,321:WARNING: 	 vocab_size: 49408
2024-05-19 06:30:52,321:WARNING: 	 transformer_width: 512
2024-05-19 06:30:52,321:WARNING: 	 transformer_heads: 8
2024-05-19 06:30:52,321:WARNING: 	 transformer_layers: 12
2024-05-19 06:30:52,321:WARNING: 	 cut_top_layer: 0
2024-05-19 06:30:53,225:WARNING: 	 sim_type: seqTransf
2024-05-19 06:30:57,024:INFO: --------------------
2024-05-19 06:30:57,025:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-19 06:32:35,016:INFO: device: cuda:0 n_gpu: 1
2024-05-19 06:32:35,016:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-19 06:32:35,247:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-19 06:32:35,248:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-19 06:32:35,248:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-19 06:32:35,249:WARNING: 	 embed_dim: 512
2024-05-19 06:32:35,249:WARNING: 	 image_resolution: 224
2024-05-19 06:32:35,249:WARNING: 	 vision_layers: 12
2024-05-19 06:32:35,249:WARNING: 	 vision_width: 768
2024-05-19 06:32:35,250:WARNING: 	 vision_patch_size: 32
2024-05-19 06:32:35,250:WARNING: 	 context_length: 77
2024-05-19 06:32:35,250:WARNING: 	 vocab_size: 49408
2024-05-19 06:32:35,250:WARNING: 	 transformer_width: 512
2024-05-19 06:32:35,250:WARNING: 	 transformer_heads: 8
2024-05-19 06:32:35,250:WARNING: 	 transformer_layers: 12
2024-05-19 06:32:35,250:WARNING: 	 cut_top_layer: 0
2024-05-19 06:32:36,136:WARNING: 	 sim_type: seqTransf
2024-05-19 06:32:39,975:INFO: --------------------
2024-05-19 06:32:39,975:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-19 06:33:46,036:INFO: device: cuda:0 n_gpu: 1
2024-05-19 06:33:46,037:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-19 06:33:46,267:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-19 06:33:46,268:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-19 06:33:46,269:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-19 06:33:46,269:WARNING: 	 embed_dim: 512
2024-05-19 06:33:46,269:WARNING: 	 image_resolution: 224
2024-05-19 06:33:46,270:WARNING: 	 vision_layers: 12
2024-05-19 06:33:46,270:WARNING: 	 vision_width: 768
2024-05-19 06:33:46,270:WARNING: 	 vision_patch_size: 32
2024-05-19 06:33:46,270:WARNING: 	 context_length: 77
2024-05-19 06:33:46,270:WARNING: 	 vocab_size: 49408
2024-05-19 06:33:46,270:WARNING: 	 transformer_width: 512
2024-05-19 06:33:46,270:WARNING: 	 transformer_heads: 8
2024-05-19 06:33:46,270:WARNING: 	 transformer_layers: 12
2024-05-19 06:33:46,270:WARNING: 	 cut_top_layer: 0
2024-05-19 06:33:47,158:WARNING: 	 sim_type: seqTransf
2024-05-19 06:33:50,960:INFO: --------------------
2024-05-19 06:33:50,960:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-19 06:34:34,496:INFO: device: cuda:0 n_gpu: 1
2024-05-19 06:34:34,564:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-19 06:34:34,797:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-19 06:34:34,798:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-19 06:34:34,798:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-19 06:34:34,799:WARNING: 	 embed_dim: 512
2024-05-19 06:34:34,799:WARNING: 	 image_resolution: 224
2024-05-19 06:34:34,799:WARNING: 	 vision_layers: 12
2024-05-19 06:34:34,799:WARNING: 	 vision_width: 768
2024-05-19 06:34:34,799:WARNING: 	 vision_patch_size: 32
2024-05-19 06:34:34,799:WARNING: 	 context_length: 77
2024-05-19 06:34:34,799:WARNING: 	 vocab_size: 49408
2024-05-19 06:34:34,799:WARNING: 	 transformer_width: 512
2024-05-19 06:34:34,799:WARNING: 	 transformer_heads: 8
2024-05-19 06:34:34,799:WARNING: 	 transformer_layers: 12
2024-05-19 06:34:34,799:WARNING: 	 cut_top_layer: 0
2024-05-19 06:34:35,664:WARNING: 	 sim_type: seqTransf
2024-05-19 06:34:39,465:INFO: --------------------
2024-05-19 06:34:39,465:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-19 06:34:41,575:INFO: ***** Running test *****
2024-05-19 06:34:41,576:INFO:   Num examples = 1
2024-05-19 06:34:41,576:INFO:   Batch size = 64
2024-05-19 06:34:41,576:INFO:   Num steps = 1
2024-05-19 06:36:42,691:INFO: device: cuda:0 n_gpu: 1
2024-05-19 06:36:42,692:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-19 06:36:42,925:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-19 06:36:42,926:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-19 06:36:42,926:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-19 06:36:42,927:WARNING: 	 embed_dim: 512
2024-05-19 06:36:42,927:WARNING: 	 image_resolution: 224
2024-05-19 06:36:42,927:WARNING: 	 vision_layers: 12
2024-05-19 06:36:42,928:WARNING: 	 vision_width: 768
2024-05-19 06:36:42,928:WARNING: 	 vision_patch_size: 32
2024-05-19 06:36:42,928:WARNING: 	 context_length: 77
2024-05-19 06:36:42,928:WARNING: 	 vocab_size: 49408
2024-05-19 06:36:42,928:WARNING: 	 transformer_width: 512
2024-05-19 06:36:42,928:WARNING: 	 transformer_heads: 8
2024-05-19 06:36:42,928:WARNING: 	 transformer_layers: 12
2024-05-19 06:36:42,928:WARNING: 	 cut_top_layer: 0
2024-05-19 06:36:43,804:WARNING: 	 sim_type: seqTransf
2024-05-19 06:36:47,606:INFO: --------------------
2024-05-19 06:36:47,606:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-19 06:43:56,800:INFO: device: cuda:0 n_gpu: 1
2024-05-19 06:43:56,801:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-19 06:43:57,039:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-19 06:43:57,040:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-19 06:43:57,040:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-19 06:43:57,041:WARNING: 	 embed_dim: 512
2024-05-19 06:43:57,041:WARNING: 	 image_resolution: 224
2024-05-19 06:43:57,041:WARNING: 	 vision_layers: 12
2024-05-19 06:43:57,041:WARNING: 	 vision_width: 768
2024-05-19 06:43:57,041:WARNING: 	 vision_patch_size: 32
2024-05-19 06:43:57,041:WARNING: 	 context_length: 77
2024-05-19 06:43:57,041:WARNING: 	 vocab_size: 49408
2024-05-19 06:43:57,041:WARNING: 	 transformer_width: 512
2024-05-19 06:43:57,041:WARNING: 	 transformer_heads: 8
2024-05-19 06:43:57,041:WARNING: 	 transformer_layers: 12
2024-05-19 06:43:57,042:WARNING: 	 cut_top_layer: 0
2024-05-19 06:43:57,922:WARNING: 	 sim_type: seqTransf
2024-05-19 06:44:01,701:INFO: --------------------
2024-05-19 06:44:01,701:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-19 06:51:09,092:INFO: device: cuda:0 n_gpu: 1
2024-05-19 06:51:09,092:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-19 06:51:09,323:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-19 06:51:09,324:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-19 06:51:09,324:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-19 06:51:09,325:WARNING: 	 embed_dim: 512
2024-05-19 06:51:09,325:WARNING: 	 image_resolution: 224
2024-05-19 06:51:09,325:WARNING: 	 vision_layers: 12
2024-05-19 06:51:09,325:WARNING: 	 vision_width: 768
2024-05-19 06:51:09,325:WARNING: 	 vision_patch_size: 32
2024-05-19 06:51:09,325:WARNING: 	 context_length: 77
2024-05-19 06:51:09,325:WARNING: 	 vocab_size: 49408
2024-05-19 06:51:09,325:WARNING: 	 transformer_width: 512
2024-05-19 06:51:09,325:WARNING: 	 transformer_heads: 8
2024-05-19 06:51:09,325:WARNING: 	 transformer_layers: 12
2024-05-19 06:51:09,325:WARNING: 	 cut_top_layer: 0
2024-05-19 06:51:10,205:WARNING: 	 sim_type: seqTransf
2024-05-19 06:51:14,063:INFO: --------------------
2024-05-19 06:51:14,063:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-19 06:54:09,044:INFO: device: cuda:0 n_gpu: 1
2024-05-19 06:54:09,044:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-19 06:54:09,276:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-19 06:54:09,278:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-19 06:54:09,278:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-19 06:54:09,278:WARNING: 	 embed_dim: 512
2024-05-19 06:54:09,279:WARNING: 	 image_resolution: 224
2024-05-19 06:54:09,279:WARNING: 	 vision_layers: 12
2024-05-19 06:54:09,279:WARNING: 	 vision_width: 768
2024-05-19 06:54:09,279:WARNING: 	 vision_patch_size: 32
2024-05-19 06:54:09,279:WARNING: 	 context_length: 77
2024-05-19 06:54:09,279:WARNING: 	 vocab_size: 49408
2024-05-19 06:54:09,279:WARNING: 	 transformer_width: 512
2024-05-19 06:54:09,279:WARNING: 	 transformer_heads: 8
2024-05-19 06:54:09,279:WARNING: 	 transformer_layers: 12
2024-05-19 06:54:09,279:WARNING: 	 cut_top_layer: 0
2024-05-19 06:54:10,170:WARNING: 	 sim_type: seqTransf
2024-05-19 06:54:13,983:INFO: --------------------
2024-05-19 06:54:13,984:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-19 06:55:40,331:INFO: device: cuda:0 n_gpu: 1
2024-05-19 06:55:40,400:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-19 06:55:40,630:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-19 06:55:40,631:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-19 06:55:40,631:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-19 06:55:40,632:WARNING: 	 embed_dim: 512
2024-05-19 06:55:40,632:WARNING: 	 image_resolution: 224
2024-05-19 06:55:40,632:WARNING: 	 vision_layers: 12
2024-05-19 06:55:40,633:WARNING: 	 vision_width: 768
2024-05-19 06:55:40,633:WARNING: 	 vision_patch_size: 32
2024-05-19 06:55:40,633:WARNING: 	 context_length: 77
2024-05-19 06:55:40,633:WARNING: 	 vocab_size: 49408
2024-05-19 06:55:40,633:WARNING: 	 transformer_width: 512
2024-05-19 06:55:40,633:WARNING: 	 transformer_heads: 8
2024-05-19 06:55:40,633:WARNING: 	 transformer_layers: 12
2024-05-19 06:55:40,633:WARNING: 	 cut_top_layer: 0
2024-05-19 06:55:41,506:WARNING: 	 sim_type: seqTransf
2024-05-19 06:55:45,292:INFO: --------------------
2024-05-19 06:55:45,293:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-19 06:55:47,388:INFO: ***** Running test *****
2024-05-19 06:55:47,388:INFO:   Num examples = 1
2024-05-19 06:55:47,388:INFO:   Batch size = 64
2024-05-19 06:55:47,389:INFO:   Num steps = 1
2024-05-19 10:29:28,156:INFO: device: cuda:0 n_gpu: 1
2024-05-19 10:29:28,156:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-19 10:29:29,076:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-19 10:29:29,077:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-19 10:29:29,077:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-19 10:29:29,078:WARNING: 	 embed_dim: 512
2024-05-19 10:29:29,078:WARNING: 	 image_resolution: 224
2024-05-19 10:29:29,079:WARNING: 	 vision_layers: 12
2024-05-19 10:29:29,079:WARNING: 	 vision_width: 768
2024-05-19 10:29:29,079:WARNING: 	 vision_patch_size: 32
2024-05-19 10:29:29,079:WARNING: 	 context_length: 77
2024-05-19 10:29:29,079:WARNING: 	 vocab_size: 49408
2024-05-19 10:29:29,079:WARNING: 	 transformer_width: 512
2024-05-19 10:29:29,079:WARNING: 	 transformer_heads: 8
2024-05-19 10:29:29,079:WARNING: 	 transformer_layers: 12
2024-05-19 10:29:29,079:WARNING: 	 cut_top_layer: 0
2024-05-19 10:29:29,970:WARNING: 	 sim_type: seqTransf
2024-05-19 10:29:33,799:INFO: --------------------
2024-05-19 10:29:33,799:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-19 10:30:49,422:INFO: device: cuda:0 n_gpu: 1
2024-05-19 10:30:49,423:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-19 10:30:49,660:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-19 10:30:49,662:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-19 10:30:49,662:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-19 10:30:49,663:WARNING: 	 embed_dim: 512
2024-05-19 10:30:49,663:WARNING: 	 image_resolution: 224
2024-05-19 10:30:49,663:WARNING: 	 vision_layers: 12
2024-05-19 10:30:49,663:WARNING: 	 vision_width: 768
2024-05-19 10:30:49,663:WARNING: 	 vision_patch_size: 32
2024-05-19 10:30:49,663:WARNING: 	 context_length: 77
2024-05-19 10:30:49,663:WARNING: 	 vocab_size: 49408
2024-05-19 10:30:49,663:WARNING: 	 transformer_width: 512
2024-05-19 10:30:49,663:WARNING: 	 transformer_heads: 8
2024-05-19 10:30:49,663:WARNING: 	 transformer_layers: 12
2024-05-19 10:30:49,663:WARNING: 	 cut_top_layer: 0
2024-05-19 10:30:50,539:WARNING: 	 sim_type: seqTransf
2024-05-19 10:30:54,341:INFO: --------------------
2024-05-19 10:30:54,342:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-19 10:50:55,593:INFO: device: cuda:0 n_gpu: 1
2024-05-19 10:50:55,661:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-19 10:50:55,886:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-19 10:50:55,887:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-19 10:50:55,887:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-19 10:50:55,888:WARNING: 	 embed_dim: 512
2024-05-19 10:50:55,888:WARNING: 	 image_resolution: 224
2024-05-19 10:50:55,888:WARNING: 	 vision_layers: 12
2024-05-19 10:50:55,888:WARNING: 	 vision_width: 768
2024-05-19 10:50:55,888:WARNING: 	 vision_patch_size: 32
2024-05-19 10:50:55,888:WARNING: 	 context_length: 77
2024-05-19 10:50:55,888:WARNING: 	 vocab_size: 49408
2024-05-19 10:50:55,888:WARNING: 	 transformer_width: 512
2024-05-19 10:50:55,888:WARNING: 	 transformer_heads: 8
2024-05-19 10:50:55,888:WARNING: 	 transformer_layers: 12
2024-05-19 10:50:55,888:WARNING: 	 cut_top_layer: 0
2024-05-19 10:50:56,734:WARNING: 	 sim_type: seqTransf
2024-05-19 10:51:00,512:INFO: --------------------
2024-05-19 10:51:00,512:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-19 10:51:02,597:INFO: ***** Running test *****
2024-05-19 10:51:02,597:INFO:   Num examples = 1
2024-05-19 10:51:02,598:INFO:   Batch size = 64
2024-05-19 10:51:02,598:INFO:   Num steps = 1
2024-05-19 10:52:26,562:INFO: device: cuda:0 n_gpu: 1
2024-05-19 10:52:26,634:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-19 10:52:26,869:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-19 10:52:26,870:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-19 10:52:26,870:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-19 10:52:26,871:WARNING: 	 embed_dim: 512
2024-05-19 10:52:26,871:WARNING: 	 image_resolution: 224
2024-05-19 10:52:26,871:WARNING: 	 vision_layers: 12
2024-05-19 10:52:26,871:WARNING: 	 vision_width: 768
2024-05-19 10:52:26,871:WARNING: 	 vision_patch_size: 32
2024-05-19 10:52:26,871:WARNING: 	 context_length: 77
2024-05-19 10:52:26,871:WARNING: 	 vocab_size: 49408
2024-05-19 10:52:26,872:WARNING: 	 transformer_width: 512
2024-05-19 10:52:26,872:WARNING: 	 transformer_heads: 8
2024-05-19 10:52:26,872:WARNING: 	 transformer_layers: 12
2024-05-19 10:52:26,872:WARNING: 	 cut_top_layer: 0
2024-05-19 10:52:27,731:WARNING: 	 sim_type: seqTransf
2024-05-19 10:52:31,515:INFO: --------------------
2024-05-19 10:52:31,515:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-19 10:52:33,595:INFO: ***** Running test *****
2024-05-19 10:52:33,595:INFO:   Num examples = 1
2024-05-19 10:52:33,595:INFO:   Batch size = 64
2024-05-19 10:52:33,595:INFO:   Num steps = 1
2024-05-19 10:52:59,142:INFO: device: cuda:0 n_gpu: 1
2024-05-19 10:52:59,211:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-19 10:52:59,438:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-19 10:52:59,439:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-19 10:52:59,440:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-19 10:52:59,440:WARNING: 	 embed_dim: 512
2024-05-19 10:52:59,441:WARNING: 	 image_resolution: 224
2024-05-19 10:52:59,441:WARNING: 	 vision_layers: 12
2024-05-19 10:52:59,441:WARNING: 	 vision_width: 768
2024-05-19 10:52:59,441:WARNING: 	 vision_patch_size: 32
2024-05-19 10:52:59,441:WARNING: 	 context_length: 77
2024-05-19 10:52:59,441:WARNING: 	 vocab_size: 49408
2024-05-19 10:52:59,441:WARNING: 	 transformer_width: 512
2024-05-19 10:52:59,441:WARNING: 	 transformer_heads: 8
2024-05-19 10:52:59,441:WARNING: 	 transformer_layers: 12
2024-05-19 10:52:59,441:WARNING: 	 cut_top_layer: 0
2024-05-19 10:53:00,303:WARNING: 	 sim_type: seqTransf
2024-05-19 10:53:04,088:INFO: --------------------
2024-05-19 10:53:04,088:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-19 10:53:06,178:INFO: ***** Running test *****
2024-05-19 10:53:06,178:INFO:   Num examples = 1
2024-05-19 10:53:06,178:INFO:   Batch size = 64
2024-05-19 10:53:06,178:INFO:   Num steps = 1
2024-05-19 10:54:15,414:INFO: device: cuda:0 n_gpu: 1
2024-05-19 10:54:15,483:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-19 10:54:15,732:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-19 10:54:15,733:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-19 10:54:15,733:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-19 10:54:15,734:WARNING: 	 embed_dim: 512
2024-05-19 10:54:15,734:WARNING: 	 image_resolution: 224
2024-05-19 10:54:15,734:WARNING: 	 vision_layers: 12
2024-05-19 10:54:15,734:WARNING: 	 vision_width: 768
2024-05-19 10:54:15,734:WARNING: 	 vision_patch_size: 32
2024-05-19 10:54:15,734:WARNING: 	 context_length: 77
2024-05-19 10:54:15,734:WARNING: 	 vocab_size: 49408
2024-05-19 10:54:15,734:WARNING: 	 transformer_width: 512
2024-05-19 10:54:15,735:WARNING: 	 transformer_heads: 8
2024-05-19 10:54:15,735:WARNING: 	 transformer_layers: 12
2024-05-19 10:54:15,735:WARNING: 	 cut_top_layer: 0
2024-05-19 10:54:16,597:WARNING: 	 sim_type: seqTransf
2024-05-19 10:54:20,419:INFO: --------------------
2024-05-19 10:54:20,419:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-19 10:54:22,541:INFO: ***** Running test *****
2024-05-19 10:54:22,541:INFO:   Num examples = 1
2024-05-19 10:54:22,541:INFO:   Batch size = 64
2024-05-19 10:54:22,541:INFO:   Num steps = 1
2024-05-20 05:51:26,797:INFO: device: cuda:0 n_gpu: 1
2024-05-20 05:51:26,864:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-20 05:51:27,151:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-20 05:51:27,152:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-20 05:51:27,152:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-20 05:51:27,153:WARNING: 	 embed_dim: 512
2024-05-20 05:51:27,153:WARNING: 	 image_resolution: 224
2024-05-20 05:51:27,153:WARNING: 	 vision_layers: 12
2024-05-20 05:51:27,153:WARNING: 	 vision_width: 768
2024-05-20 05:51:27,153:WARNING: 	 vision_patch_size: 32
2024-05-20 05:51:27,153:WARNING: 	 context_length: 77
2024-05-20 05:51:27,153:WARNING: 	 vocab_size: 49408
2024-05-20 05:51:27,153:WARNING: 	 transformer_width: 512
2024-05-20 05:51:27,153:WARNING: 	 transformer_heads: 8
2024-05-20 05:51:27,153:WARNING: 	 transformer_layers: 12
2024-05-20 05:51:27,153:WARNING: 	 cut_top_layer: 0
2024-05-20 05:51:28,166:WARNING: 	 sim_type: seqTransf
2024-05-20 05:51:32,662:INFO: --------------------
2024-05-20 05:51:32,662:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-20 05:51:34,893:INFO: ***** Running test *****
2024-05-20 05:51:34,893:INFO:   Num examples = 1
2024-05-20 05:51:34,893:INFO:   Batch size = 64
2024-05-20 05:51:34,893:INFO:   Num steps = 1
2024-05-20 05:52:00,449:INFO: sim matrix size: 1, 1
2024-05-20 05:52:00,450:INFO: 	 Length-T: 1, Length-V:1
2024-05-20 05:52:00,450:INFO: Text-to-Video:
2024-05-20 05:52:00,450:INFO: 	>>>  R@1: 100.0 - R@5: 100.0 - R@10: 100.0 - Median R: 1.0 - Mean R: 1.0
2024-05-20 05:52:00,450:INFO: Video-to-Text:
2024-05-20 05:52:00,451:INFO: 	>>>  V2T$R@1: 100.0 - V2T$R@5: 100.0 - V2T$R@10: 100.0 - V2T$Median R: 1.0 - V2T$Mean R: 1.0
2024-05-20 05:52:46,219:INFO: device: cuda:0 n_gpu: 1
2024-05-20 05:52:46,287:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-20 05:52:46,534:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-20 05:52:46,535:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-20 05:52:46,535:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-20 05:52:46,536:WARNING: 	 embed_dim: 512
2024-05-20 05:52:46,536:WARNING: 	 image_resolution: 224
2024-05-20 05:52:46,536:WARNING: 	 vision_layers: 12
2024-05-20 05:52:46,536:WARNING: 	 vision_width: 768
2024-05-20 05:52:46,536:WARNING: 	 vision_patch_size: 32
2024-05-20 05:52:46,536:WARNING: 	 context_length: 77
2024-05-20 05:52:46,536:WARNING: 	 vocab_size: 49408
2024-05-20 05:52:46,536:WARNING: 	 transformer_width: 512
2024-05-20 05:52:46,536:WARNING: 	 transformer_heads: 8
2024-05-20 05:52:46,536:WARNING: 	 transformer_layers: 12
2024-05-20 05:52:46,536:WARNING: 	 cut_top_layer: 0
2024-05-20 05:52:47,510:WARNING: 	 sim_type: seqTransf
2024-05-20 05:52:51,987:INFO: --------------------
2024-05-20 05:52:51,987:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-20 05:52:53,728:INFO: ***** Running test *****
2024-05-20 05:52:53,728:INFO:   Num examples = 1
2024-05-20 05:52:53,728:INFO:   Batch size = 64
2024-05-20 05:52:53,728:INFO:   Num steps = 1
2024-05-20 05:57:37,063:INFO: device: cuda:0 n_gpu: 1
2024-05-20 05:57:37,133:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-20 05:57:37,370:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-20 05:57:37,371:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-20 05:57:37,371:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-20 05:57:37,372:WARNING: 	 embed_dim: 512
2024-05-20 05:57:37,372:WARNING: 	 image_resolution: 224
2024-05-20 05:57:37,372:WARNING: 	 vision_layers: 12
2024-05-20 05:57:37,372:WARNING: 	 vision_width: 768
2024-05-20 05:57:37,372:WARNING: 	 vision_patch_size: 32
2024-05-20 05:57:37,373:WARNING: 	 context_length: 77
2024-05-20 05:57:37,373:WARNING: 	 vocab_size: 49408
2024-05-20 05:57:37,373:WARNING: 	 transformer_width: 512
2024-05-20 05:57:37,373:WARNING: 	 transformer_heads: 8
2024-05-20 05:57:37,373:WARNING: 	 transformer_layers: 12
2024-05-20 05:57:37,373:WARNING: 	 cut_top_layer: 0
2024-05-20 05:57:38,366:WARNING: 	 sim_type: seqTransf
2024-05-20 05:57:42,855:INFO: --------------------
2024-05-20 05:57:42,856:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-20 05:57:44,630:INFO: ***** Running test *****
2024-05-20 05:57:44,630:INFO:   Num examples = 1
2024-05-20 05:57:44,630:INFO:   Batch size = 64
2024-05-20 05:57:44,630:INFO:   Num steps = 1
2024-05-20 06:26:08,346:INFO: device: cuda:0 n_gpu: 1
2024-05-20 06:26:08,346:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-20 06:26:08,570:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-20 06:26:08,570:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-20 06:26:08,570:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-20 06:26:08,570:WARNING: 	 embed_dim: 512
2024-05-20 06:26:08,570:WARNING: 	 image_resolution: 224
2024-05-20 06:26:08,570:WARNING: 	 vision_layers: 12
2024-05-20 06:26:08,570:WARNING: 	 vision_width: 768
2024-05-20 06:26:08,570:WARNING: 	 vision_patch_size: 32
2024-05-20 06:26:08,570:WARNING: 	 context_length: 77
2024-05-20 06:26:08,570:WARNING: 	 vocab_size: 49408
2024-05-20 06:26:08,570:WARNING: 	 transformer_width: 512
2024-05-20 06:26:08,570:WARNING: 	 transformer_heads: 8
2024-05-20 06:26:08,570:WARNING: 	 transformer_layers: 12
2024-05-20 06:26:08,570:WARNING: 	 cut_top_layer: 0
2024-05-20 06:26:09,538:WARNING: 	 sim_type: seqTransf
2024-05-20 06:26:14,011:INFO: --------------------
2024-05-20 06:26:14,011:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-20 06:29:27,030:INFO: device: cuda:0 n_gpu: 1
2024-05-20 06:29:27,030:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-20 06:29:27,254:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-20 06:29:27,254:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-20 06:29:27,255:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-20 06:29:27,255:WARNING: 	 embed_dim: 512
2024-05-20 06:29:27,255:WARNING: 	 image_resolution: 224
2024-05-20 06:29:27,255:WARNING: 	 vision_layers: 12
2024-05-20 06:29:27,255:WARNING: 	 vision_width: 768
2024-05-20 06:29:27,255:WARNING: 	 vision_patch_size: 32
2024-05-20 06:29:27,255:WARNING: 	 context_length: 77
2024-05-20 06:29:27,255:WARNING: 	 vocab_size: 49408
2024-05-20 06:29:27,255:WARNING: 	 transformer_width: 512
2024-05-20 06:29:27,255:WARNING: 	 transformer_heads: 8
2024-05-20 06:29:27,255:WARNING: 	 transformer_layers: 12
2024-05-20 06:29:27,255:WARNING: 	 cut_top_layer: 0
2024-05-20 06:29:28,228:WARNING: 	 sim_type: seqTransf
2024-05-20 06:29:32,709:INFO: --------------------
2024-05-20 06:29:32,709:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-20 06:31:46,711:INFO: device: cuda:0 n_gpu: 1
2024-05-20 06:31:46,711:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-20 06:31:46,944:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-20 06:31:46,946:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-20 06:31:46,946:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-20 06:31:46,947:WARNING: 	 embed_dim: 512
2024-05-20 06:31:46,947:WARNING: 	 image_resolution: 224
2024-05-20 06:31:46,947:WARNING: 	 vision_layers: 12
2024-05-20 06:31:46,947:WARNING: 	 vision_width: 768
2024-05-20 06:31:46,947:WARNING: 	 vision_patch_size: 32
2024-05-20 06:31:46,947:WARNING: 	 context_length: 77
2024-05-20 06:31:46,947:WARNING: 	 vocab_size: 49408
2024-05-20 06:31:46,947:WARNING: 	 transformer_width: 512
2024-05-20 06:31:46,947:WARNING: 	 transformer_heads: 8
2024-05-20 06:31:46,947:WARNING: 	 transformer_layers: 12
2024-05-20 06:31:46,947:WARNING: 	 cut_top_layer: 0
2024-05-20 06:31:47,932:WARNING: 	 sim_type: seqTransf
2024-05-20 06:31:52,420:INFO: --------------------
2024-05-20 06:31:52,420:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-20 06:32:45,612:INFO: device: cuda:0 n_gpu: 1
2024-05-20 06:32:45,612:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-20 06:32:45,840:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-20 06:32:45,841:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-20 06:32:45,841:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-20 06:32:45,841:WARNING: 	 embed_dim: 512
2024-05-20 06:32:45,841:WARNING: 	 image_resolution: 224
2024-05-20 06:32:45,841:WARNING: 	 vision_layers: 12
2024-05-20 06:32:45,841:WARNING: 	 vision_width: 768
2024-05-20 06:32:45,841:WARNING: 	 vision_patch_size: 32
2024-05-20 06:32:45,841:WARNING: 	 context_length: 77
2024-05-20 06:32:45,841:WARNING: 	 vocab_size: 49408
2024-05-20 06:32:45,841:WARNING: 	 transformer_width: 512
2024-05-20 06:32:45,841:WARNING: 	 transformer_heads: 8
2024-05-20 06:32:45,841:WARNING: 	 transformer_layers: 12
2024-05-20 06:32:45,841:WARNING: 	 cut_top_layer: 0
2024-05-20 06:32:46,819:WARNING: 	 sim_type: seqTransf
2024-05-20 06:32:51,309:INFO: --------------------
2024-05-20 06:32:51,309:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-20 06:33:59,032:INFO: device: cuda:0 n_gpu: 1
2024-05-20 06:33:59,032:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-20 06:33:59,257:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-20 06:33:59,257:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-20 06:33:59,257:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-20 06:33:59,258:WARNING: 	 embed_dim: 512
2024-05-20 06:33:59,258:WARNING: 	 image_resolution: 224
2024-05-20 06:33:59,258:WARNING: 	 vision_layers: 12
2024-05-20 06:33:59,258:WARNING: 	 vision_width: 768
2024-05-20 06:33:59,258:WARNING: 	 vision_patch_size: 32
2024-05-20 06:33:59,258:WARNING: 	 context_length: 77
2024-05-20 06:33:59,258:WARNING: 	 vocab_size: 49408
2024-05-20 06:33:59,258:WARNING: 	 transformer_width: 512
2024-05-20 06:33:59,258:WARNING: 	 transformer_heads: 8
2024-05-20 06:33:59,258:WARNING: 	 transformer_layers: 12
2024-05-20 06:33:59,258:WARNING: 	 cut_top_layer: 0
2024-05-20 06:34:00,237:WARNING: 	 sim_type: seqTransf
2024-05-20 06:34:04,732:INFO: --------------------
2024-05-20 06:34:04,733:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-20 06:34:40,152:INFO: device: cuda:0 n_gpu: 1
2024-05-20 06:34:40,152:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-20 06:34:40,385:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-20 06:34:40,386:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-20 06:34:40,386:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-20 06:34:40,387:WARNING: 	 embed_dim: 512
2024-05-20 06:34:40,387:WARNING: 	 image_resolution: 224
2024-05-20 06:34:40,387:WARNING: 	 vision_layers: 12
2024-05-20 06:34:40,387:WARNING: 	 vision_width: 768
2024-05-20 06:34:40,387:WARNING: 	 vision_patch_size: 32
2024-05-20 06:34:40,388:WARNING: 	 context_length: 77
2024-05-20 06:34:40,388:WARNING: 	 vocab_size: 49408
2024-05-20 06:34:40,388:WARNING: 	 transformer_width: 512
2024-05-20 06:34:40,388:WARNING: 	 transformer_heads: 8
2024-05-20 06:34:40,388:WARNING: 	 transformer_layers: 12
2024-05-20 06:34:40,388:WARNING: 	 cut_top_layer: 0
2024-05-20 06:34:41,388:WARNING: 	 sim_type: seqTransf
2024-05-20 06:34:45,888:INFO: --------------------
2024-05-20 06:34:45,889:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-20 06:35:26,543:INFO: device: cuda:0 n_gpu: 1
2024-05-20 06:35:26,543:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-20 06:35:26,777:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-20 06:35:26,778:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-20 06:35:26,778:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-20 06:35:26,779:WARNING: 	 embed_dim: 512
2024-05-20 06:35:26,779:WARNING: 	 image_resolution: 224
2024-05-20 06:35:26,779:WARNING: 	 vision_layers: 12
2024-05-20 06:35:26,779:WARNING: 	 vision_width: 768
2024-05-20 06:35:26,779:WARNING: 	 vision_patch_size: 32
2024-05-20 06:35:26,779:WARNING: 	 context_length: 77
2024-05-20 06:35:26,779:WARNING: 	 vocab_size: 49408
2024-05-20 06:35:26,779:WARNING: 	 transformer_width: 512
2024-05-20 06:35:26,779:WARNING: 	 transformer_heads: 8
2024-05-20 06:35:26,779:WARNING: 	 transformer_layers: 12
2024-05-20 06:35:26,779:WARNING: 	 cut_top_layer: 0
2024-05-20 06:35:27,768:WARNING: 	 sim_type: seqTransf
2024-05-20 06:35:32,254:INFO: --------------------
2024-05-20 06:35:32,254:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-20 06:56:55,119:INFO: device: cuda:0 n_gpu: 1
2024-05-20 06:56:55,120:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-20 06:56:55,346:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-20 06:56:55,346:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-20 06:56:55,346:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-20 06:56:55,347:WARNING: 	 embed_dim: 512
2024-05-20 06:56:55,347:WARNING: 	 image_resolution: 224
2024-05-20 06:56:55,347:WARNING: 	 vision_layers: 12
2024-05-20 06:56:55,347:WARNING: 	 vision_width: 768
2024-05-20 06:56:55,347:WARNING: 	 vision_patch_size: 32
2024-05-20 06:56:55,347:WARNING: 	 context_length: 77
2024-05-20 06:56:55,347:WARNING: 	 vocab_size: 49408
2024-05-20 06:56:55,347:WARNING: 	 transformer_width: 512
2024-05-20 06:56:55,347:WARNING: 	 transformer_heads: 8
2024-05-20 06:56:55,347:WARNING: 	 transformer_layers: 12
2024-05-20 06:56:55,347:WARNING: 	 cut_top_layer: 0
2024-05-20 06:56:56,315:WARNING: 	 sim_type: seqTransf
2024-05-20 06:57:00,800:INFO: --------------------
2024-05-20 06:57:00,800:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-20 07:23:18,561:INFO: device: cuda:0 n_gpu: 1
2024-05-20 07:23:18,561:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-20 07:23:18,794:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-20 07:23:18,795:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-20 07:23:18,795:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-20 07:23:18,796:WARNING: 	 embed_dim: 512
2024-05-20 07:23:18,796:WARNING: 	 image_resolution: 224
2024-05-20 07:23:18,796:WARNING: 	 vision_layers: 12
2024-05-20 07:23:18,796:WARNING: 	 vision_width: 768
2024-05-20 07:23:18,796:WARNING: 	 vision_patch_size: 32
2024-05-20 07:23:18,796:WARNING: 	 context_length: 77
2024-05-20 07:23:18,796:WARNING: 	 vocab_size: 49408
2024-05-20 07:23:18,796:WARNING: 	 transformer_width: 512
2024-05-20 07:23:18,796:WARNING: 	 transformer_heads: 8
2024-05-20 07:23:18,796:WARNING: 	 transformer_layers: 12
2024-05-20 07:23:18,796:WARNING: 	 cut_top_layer: 0
2024-05-20 07:23:19,792:WARNING: 	 sim_type: seqTransf
2024-05-20 07:23:24,287:INFO: --------------------
2024-05-20 07:23:24,287:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-20 07:24:50,226:INFO: device: cuda:0 n_gpu: 1
2024-05-20 07:24:50,226:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-20 07:24:50,460:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-20 07:24:50,461:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-20 07:24:50,461:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-20 07:24:50,462:WARNING: 	 embed_dim: 512
2024-05-20 07:24:50,462:WARNING: 	 image_resolution: 224
2024-05-20 07:24:50,462:WARNING: 	 vision_layers: 12
2024-05-20 07:24:50,462:WARNING: 	 vision_width: 768
2024-05-20 07:24:50,462:WARNING: 	 vision_patch_size: 32
2024-05-20 07:24:50,462:WARNING: 	 context_length: 77
2024-05-20 07:24:50,462:WARNING: 	 vocab_size: 49408
2024-05-20 07:24:50,462:WARNING: 	 transformer_width: 512
2024-05-20 07:24:50,462:WARNING: 	 transformer_heads: 8
2024-05-20 07:24:50,463:WARNING: 	 transformer_layers: 12
2024-05-20 07:24:50,463:WARNING: 	 cut_top_layer: 0
2024-05-20 07:24:51,464:WARNING: 	 sim_type: seqTransf
2024-05-20 07:24:55,974:INFO: --------------------
2024-05-20 07:24:55,975:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-20 07:25:55,221:INFO: device: cuda:0 n_gpu: 1
2024-05-20 07:25:55,222:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-20 07:25:55,455:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-20 07:25:55,456:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-20 07:25:55,456:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-20 07:25:55,457:WARNING: 	 embed_dim: 512
2024-05-20 07:25:55,457:WARNING: 	 image_resolution: 224
2024-05-20 07:25:55,457:WARNING: 	 vision_layers: 12
2024-05-20 07:25:55,457:WARNING: 	 vision_width: 768
2024-05-20 07:25:55,457:WARNING: 	 vision_patch_size: 32
2024-05-20 07:25:55,458:WARNING: 	 context_length: 77
2024-05-20 07:25:55,458:WARNING: 	 vocab_size: 49408
2024-05-20 07:25:55,458:WARNING: 	 transformer_width: 512
2024-05-20 07:25:55,458:WARNING: 	 transformer_heads: 8
2024-05-20 07:25:55,458:WARNING: 	 transformer_layers: 12
2024-05-20 07:25:55,458:WARNING: 	 cut_top_layer: 0
2024-05-20 07:25:56,451:WARNING: 	 sim_type: seqTransf
2024-05-20 07:26:00,950:INFO: --------------------
2024-05-20 07:26:00,950:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-20 07:33:59,545:INFO: device: cuda:0 n_gpu: 1
2024-05-20 07:33:59,546:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-20 07:33:59,779:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-20 07:33:59,780:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-20 07:33:59,781:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-20 07:33:59,781:WARNING: 	 embed_dim: 512
2024-05-20 07:33:59,781:WARNING: 	 image_resolution: 224
2024-05-20 07:33:59,781:WARNING: 	 vision_layers: 12
2024-05-20 07:33:59,782:WARNING: 	 vision_width: 768
2024-05-20 07:33:59,782:WARNING: 	 vision_patch_size: 32
2024-05-20 07:33:59,782:WARNING: 	 context_length: 77
2024-05-20 07:33:59,782:WARNING: 	 vocab_size: 49408
2024-05-20 07:33:59,782:WARNING: 	 transformer_width: 512
2024-05-20 07:33:59,782:WARNING: 	 transformer_heads: 8
2024-05-20 07:33:59,782:WARNING: 	 transformer_layers: 12
2024-05-20 07:33:59,782:WARNING: 	 cut_top_layer: 0
2024-05-20 07:34:00,780:WARNING: 	 sim_type: seqTransf
2024-05-20 07:34:05,280:INFO: --------------------
2024-05-20 07:34:05,280:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-20 07:53:04,268:INFO: device: cuda:0 n_gpu: 1
2024-05-20 07:53:04,268:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-20 07:53:04,502:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-20 07:53:04,504:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-20 07:53:04,504:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-20 07:53:04,505:WARNING: 	 embed_dim: 512
2024-05-20 07:53:04,505:WARNING: 	 image_resolution: 224
2024-05-20 07:53:04,505:WARNING: 	 vision_layers: 12
2024-05-20 07:53:04,505:WARNING: 	 vision_width: 768
2024-05-20 07:53:04,505:WARNING: 	 vision_patch_size: 32
2024-05-20 07:53:04,505:WARNING: 	 context_length: 77
2024-05-20 07:53:04,505:WARNING: 	 vocab_size: 49408
2024-05-20 07:53:04,505:WARNING: 	 transformer_width: 512
2024-05-20 07:53:04,505:WARNING: 	 transformer_heads: 8
2024-05-20 07:53:04,505:WARNING: 	 transformer_layers: 12
2024-05-20 07:53:04,505:WARNING: 	 cut_top_layer: 0
2024-05-20 07:53:05,520:WARNING: 	 sim_type: seqTransf
2024-05-20 07:53:10,005:INFO: --------------------
2024-05-20 07:53:10,005:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-20 07:53:43,855:INFO: device: cuda:0 n_gpu: 1
2024-05-20 07:53:43,855:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-20 07:53:44,092:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-20 07:53:44,093:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-20 07:53:44,093:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-20 07:53:44,094:WARNING: 	 embed_dim: 512
2024-05-20 07:53:44,094:WARNING: 	 image_resolution: 224
2024-05-20 07:53:44,094:WARNING: 	 vision_layers: 12
2024-05-20 07:53:44,094:WARNING: 	 vision_width: 768
2024-05-20 07:53:44,094:WARNING: 	 vision_patch_size: 32
2024-05-20 07:53:44,094:WARNING: 	 context_length: 77
2024-05-20 07:53:44,094:WARNING: 	 vocab_size: 49408
2024-05-20 07:53:44,094:WARNING: 	 transformer_width: 512
2024-05-20 07:53:44,094:WARNING: 	 transformer_heads: 8
2024-05-20 07:53:44,094:WARNING: 	 transformer_layers: 12
2024-05-20 07:53:44,094:WARNING: 	 cut_top_layer: 0
2024-05-20 07:53:45,096:WARNING: 	 sim_type: seqTransf
2024-05-20 07:53:49,599:INFO: --------------------
2024-05-20 07:53:49,600:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-20 07:54:05,709:INFO: device: cuda:0 n_gpu: 1
2024-05-20 07:54:05,709:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-20 07:54:05,947:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-20 07:54:05,948:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-20 07:54:05,948:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-20 07:54:05,949:WARNING: 	 embed_dim: 512
2024-05-20 07:54:05,949:WARNING: 	 image_resolution: 224
2024-05-20 07:54:05,949:WARNING: 	 vision_layers: 12
2024-05-20 07:54:05,950:WARNING: 	 vision_width: 768
2024-05-20 07:54:05,950:WARNING: 	 vision_patch_size: 32
2024-05-20 07:54:05,950:WARNING: 	 context_length: 77
2024-05-20 07:54:05,950:WARNING: 	 vocab_size: 49408
2024-05-20 07:54:05,950:WARNING: 	 transformer_width: 512
2024-05-20 07:54:05,950:WARNING: 	 transformer_heads: 8
2024-05-20 07:54:05,950:WARNING: 	 transformer_layers: 12
2024-05-20 07:54:05,950:WARNING: 	 cut_top_layer: 0
2024-05-20 07:54:06,938:WARNING: 	 sim_type: seqTransf
2024-05-20 07:54:11,432:INFO: --------------------
2024-05-20 07:54:11,432:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-20 07:54:51,055:INFO: device: cuda:0 n_gpu: 1
2024-05-20 07:54:51,055:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-20 07:54:51,293:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-20 07:54:51,294:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-20 07:54:51,294:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-20 07:54:51,295:WARNING: 	 embed_dim: 512
2024-05-20 07:54:51,295:WARNING: 	 image_resolution: 224
2024-05-20 07:54:51,295:WARNING: 	 vision_layers: 12
2024-05-20 07:54:51,295:WARNING: 	 vision_width: 768
2024-05-20 07:54:51,295:WARNING: 	 vision_patch_size: 32
2024-05-20 07:54:51,295:WARNING: 	 context_length: 77
2024-05-20 07:54:51,296:WARNING: 	 vocab_size: 49408
2024-05-20 07:54:51,296:WARNING: 	 transformer_width: 512
2024-05-20 07:54:51,296:WARNING: 	 transformer_heads: 8
2024-05-20 07:54:51,296:WARNING: 	 transformer_layers: 12
2024-05-20 07:54:51,296:WARNING: 	 cut_top_layer: 0
2024-05-20 07:54:52,296:WARNING: 	 sim_type: seqTransf
2024-05-20 07:54:56,793:INFO: --------------------
2024-05-20 07:54:56,794:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-20 07:55:52,986:INFO: device: cuda:0 n_gpu: 1
2024-05-20 07:55:52,987:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-20 07:55:53,226:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-20 07:55:53,227:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-20 07:55:53,227:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-20 07:55:53,228:WARNING: 	 embed_dim: 512
2024-05-20 07:55:53,228:WARNING: 	 image_resolution: 224
2024-05-20 07:55:53,228:WARNING: 	 vision_layers: 12
2024-05-20 07:55:53,228:WARNING: 	 vision_width: 768
2024-05-20 07:55:53,229:WARNING: 	 vision_patch_size: 32
2024-05-20 07:55:53,229:WARNING: 	 context_length: 77
2024-05-20 07:55:53,229:WARNING: 	 vocab_size: 49408
2024-05-20 07:55:53,229:WARNING: 	 transformer_width: 512
2024-05-20 07:55:53,229:WARNING: 	 transformer_heads: 8
2024-05-20 07:55:53,229:WARNING: 	 transformer_layers: 12
2024-05-20 07:55:53,229:WARNING: 	 cut_top_layer: 0
2024-05-20 07:55:54,220:WARNING: 	 sim_type: seqTransf
2024-05-20 07:55:58,713:INFO: --------------------
2024-05-20 07:55:58,713:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-20 07:57:24,727:INFO: device: cuda:0 n_gpu: 1
2024-05-20 07:57:24,727:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-20 07:57:24,961:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-20 07:57:24,962:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-20 07:57:24,962:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-20 07:57:24,963:WARNING: 	 embed_dim: 512
2024-05-20 07:57:24,963:WARNING: 	 image_resolution: 224
2024-05-20 07:57:24,963:WARNING: 	 vision_layers: 12
2024-05-20 07:57:24,963:WARNING: 	 vision_width: 768
2024-05-20 07:57:24,963:WARNING: 	 vision_patch_size: 32
2024-05-20 07:57:24,964:WARNING: 	 context_length: 77
2024-05-20 07:57:24,964:WARNING: 	 vocab_size: 49408
2024-05-20 07:57:24,964:WARNING: 	 transformer_width: 512
2024-05-20 07:57:24,964:WARNING: 	 transformer_heads: 8
2024-05-20 07:57:24,964:WARNING: 	 transformer_layers: 12
2024-05-20 07:57:24,964:WARNING: 	 cut_top_layer: 0
2024-05-20 07:57:25,957:WARNING: 	 sim_type: seqTransf
2024-05-20 07:57:30,439:INFO: --------------------
2024-05-20 07:57:30,439:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-20 08:02:12,558:INFO: device: cuda:0 n_gpu: 1
2024-05-20 08:02:12,626:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-20 08:02:12,861:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-20 08:02:12,862:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-20 08:02:12,862:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-20 08:02:12,863:WARNING: 	 embed_dim: 512
2024-05-20 08:02:12,863:WARNING: 	 image_resolution: 224
2024-05-20 08:02:12,863:WARNING: 	 vision_layers: 12
2024-05-20 08:02:12,863:WARNING: 	 vision_width: 768
2024-05-20 08:02:12,863:WARNING: 	 vision_patch_size: 32
2024-05-20 08:02:12,863:WARNING: 	 context_length: 77
2024-05-20 08:02:12,863:WARNING: 	 vocab_size: 49408
2024-05-20 08:02:12,863:WARNING: 	 transformer_width: 512
2024-05-20 08:02:12,863:WARNING: 	 transformer_heads: 8
2024-05-20 08:02:12,863:WARNING: 	 transformer_layers: 12
2024-05-20 08:02:12,864:WARNING: 	 cut_top_layer: 0
2024-05-20 08:02:13,859:WARNING: 	 sim_type: seqTransf
2024-05-20 08:02:18,363:INFO: --------------------
2024-05-20 08:02:18,363:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-20 08:02:20,138:INFO: ***** Running test *****
2024-05-20 08:02:20,138:INFO:   Num examples = 2
2024-05-20 08:02:20,138:INFO:   Batch size = 64
2024-05-20 08:02:20,139:INFO:   Num steps = 1
2024-05-20 08:09:15,431:INFO: device: cuda:0 n_gpu: 1
2024-05-20 08:09:15,498:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-20 08:09:15,734:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-20 08:09:15,735:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-20 08:09:15,735:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-20 08:09:15,736:WARNING: 	 embed_dim: 512
2024-05-20 08:09:15,736:WARNING: 	 image_resolution: 224
2024-05-20 08:09:15,736:WARNING: 	 vision_layers: 12
2024-05-20 08:09:15,736:WARNING: 	 vision_width: 768
2024-05-20 08:09:15,736:WARNING: 	 vision_patch_size: 32
2024-05-20 08:09:15,736:WARNING: 	 context_length: 77
2024-05-20 08:09:15,736:WARNING: 	 vocab_size: 49408
2024-05-20 08:09:15,736:WARNING: 	 transformer_width: 512
2024-05-20 08:09:15,736:WARNING: 	 transformer_heads: 8
2024-05-20 08:09:15,736:WARNING: 	 transformer_layers: 12
2024-05-20 08:09:15,736:WARNING: 	 cut_top_layer: 0
2024-05-20 08:09:16,715:WARNING: 	 sim_type: seqTransf
2024-05-20 08:09:21,202:INFO: --------------------
2024-05-20 08:09:21,203:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-20 08:09:22,945:INFO: ***** Running test *****
2024-05-20 08:09:22,946:INFO:   Num examples = 2
2024-05-20 08:09:22,946:INFO:   Batch size = 64
2024-05-20 08:09:22,946:INFO:   Num steps = 1
2024-05-20 08:13:45,084:INFO: device: cuda:0 n_gpu: 1
2024-05-20 08:13:45,084:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-20 08:13:45,319:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-20 08:13:45,320:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-20 08:13:45,320:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-20 08:13:45,321:WARNING: 	 embed_dim: 512
2024-05-20 08:13:45,321:WARNING: 	 image_resolution: 224
2024-05-20 08:13:45,321:WARNING: 	 vision_layers: 12
2024-05-20 08:13:45,322:WARNING: 	 vision_width: 768
2024-05-20 08:13:45,322:WARNING: 	 vision_patch_size: 32
2024-05-20 08:13:45,322:WARNING: 	 context_length: 77
2024-05-20 08:13:45,322:WARNING: 	 vocab_size: 49408
2024-05-20 08:13:45,322:WARNING: 	 transformer_width: 512
2024-05-20 08:13:45,322:WARNING: 	 transformer_heads: 8
2024-05-20 08:13:45,322:WARNING: 	 transformer_layers: 12
2024-05-20 08:13:45,322:WARNING: 	 cut_top_layer: 0
2024-05-20 08:13:46,305:WARNING: 	 sim_type: seqTransf
2024-05-20 08:13:50,811:INFO: --------------------
2024-05-20 08:13:50,811:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-20 08:14:09,666:INFO: device: cuda:0 n_gpu: 1
2024-05-20 08:14:09,667:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-20 08:14:09,898:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-20 08:14:09,899:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-20 08:14:09,899:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-20 08:14:09,900:WARNING: 	 embed_dim: 512
2024-05-20 08:14:09,900:WARNING: 	 image_resolution: 224
2024-05-20 08:14:09,900:WARNING: 	 vision_layers: 12
2024-05-20 08:14:09,900:WARNING: 	 vision_width: 768
2024-05-20 08:14:09,900:WARNING: 	 vision_patch_size: 32
2024-05-20 08:14:09,900:WARNING: 	 context_length: 77
2024-05-20 08:14:09,900:WARNING: 	 vocab_size: 49408
2024-05-20 08:14:09,900:WARNING: 	 transformer_width: 512
2024-05-20 08:14:09,901:WARNING: 	 transformer_heads: 8
2024-05-20 08:14:09,901:WARNING: 	 transformer_layers: 12
2024-05-20 08:14:09,901:WARNING: 	 cut_top_layer: 0
2024-05-20 08:14:10,889:WARNING: 	 sim_type: seqTransf
2024-05-20 08:14:15,382:INFO: --------------------
2024-05-20 08:14:15,382:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-20 08:15:31,269:INFO: device: cuda:0 n_gpu: 1
2024-05-20 08:15:31,270:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-20 08:15:31,504:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-20 08:15:31,506:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-20 08:15:31,506:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-20 08:15:31,506:WARNING: 	 embed_dim: 512
2024-05-20 08:15:31,507:WARNING: 	 image_resolution: 224
2024-05-20 08:15:31,507:WARNING: 	 vision_layers: 12
2024-05-20 08:15:31,507:WARNING: 	 vision_width: 768
2024-05-20 08:15:31,507:WARNING: 	 vision_patch_size: 32
2024-05-20 08:15:31,507:WARNING: 	 context_length: 77
2024-05-20 08:15:31,507:WARNING: 	 vocab_size: 49408
2024-05-20 08:15:31,507:WARNING: 	 transformer_width: 512
2024-05-20 08:15:31,507:WARNING: 	 transformer_heads: 8
2024-05-20 08:15:31,507:WARNING: 	 transformer_layers: 12
2024-05-20 08:15:31,507:WARNING: 	 cut_top_layer: 0
2024-05-20 08:15:32,499:WARNING: 	 sim_type: seqTransf
2024-05-20 08:15:36,998:INFO: --------------------
2024-05-20 08:15:36,998:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-20 08:16:48,967:INFO: device: cuda:0 n_gpu: 1
2024-05-20 08:16:48,967:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-20 08:16:49,199:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-20 08:16:49,201:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-20 08:16:49,201:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-20 08:16:49,201:WARNING: 	 embed_dim: 512
2024-05-20 08:16:49,202:WARNING: 	 image_resolution: 224
2024-05-20 08:16:49,202:WARNING: 	 vision_layers: 12
2024-05-20 08:16:49,202:WARNING: 	 vision_width: 768
2024-05-20 08:16:49,202:WARNING: 	 vision_patch_size: 32
2024-05-20 08:16:49,202:WARNING: 	 context_length: 77
2024-05-20 08:16:49,202:WARNING: 	 vocab_size: 49408
2024-05-20 08:16:49,202:WARNING: 	 transformer_width: 512
2024-05-20 08:16:49,202:WARNING: 	 transformer_heads: 8
2024-05-20 08:16:49,202:WARNING: 	 transformer_layers: 12
2024-05-20 08:16:49,202:WARNING: 	 cut_top_layer: 0
2024-05-20 08:16:50,175:WARNING: 	 sim_type: seqTransf
2024-05-20 08:16:54,657:INFO: --------------------
2024-05-20 08:16:54,657:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-20 08:35:04,219:INFO: device: cuda:0 n_gpu: 1
2024-05-20 08:35:04,219:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-20 08:35:04,460:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-20 08:35:04,461:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-20 08:35:04,461:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-20 08:35:04,462:WARNING: 	 embed_dim: 512
2024-05-20 08:35:04,462:WARNING: 	 image_resolution: 224
2024-05-20 08:35:04,462:WARNING: 	 vision_layers: 12
2024-05-20 08:35:04,462:WARNING: 	 vision_width: 768
2024-05-20 08:35:04,462:WARNING: 	 vision_patch_size: 32
2024-05-20 08:35:04,462:WARNING: 	 context_length: 77
2024-05-20 08:35:04,462:WARNING: 	 vocab_size: 49408
2024-05-20 08:35:04,462:WARNING: 	 transformer_width: 512
2024-05-20 08:35:04,462:WARNING: 	 transformer_heads: 8
2024-05-20 08:35:04,462:WARNING: 	 transformer_layers: 12
2024-05-20 08:35:04,462:WARNING: 	 cut_top_layer: 0
2024-05-20 08:35:05,447:WARNING: 	 sim_type: seqTransf
2024-05-20 08:35:09,947:INFO: --------------------
2024-05-20 08:35:09,947:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-20 08:44:51,392:INFO: device: cuda:0 n_gpu: 1
2024-05-20 08:44:51,459:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-20 08:44:51,697:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-20 08:44:51,698:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-20 08:44:51,698:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-20 08:44:51,699:WARNING: 	 embed_dim: 512
2024-05-20 08:44:51,699:WARNING: 	 image_resolution: 224
2024-05-20 08:44:51,699:WARNING: 	 vision_layers: 12
2024-05-20 08:44:51,699:WARNING: 	 vision_width: 768
2024-05-20 08:44:51,699:WARNING: 	 vision_patch_size: 32
2024-05-20 08:44:51,699:WARNING: 	 context_length: 77
2024-05-20 08:44:51,700:WARNING: 	 vocab_size: 49408
2024-05-20 08:44:51,700:WARNING: 	 transformer_width: 512
2024-05-20 08:44:51,700:WARNING: 	 transformer_heads: 8
2024-05-20 08:44:51,700:WARNING: 	 transformer_layers: 12
2024-05-20 08:44:51,700:WARNING: 	 cut_top_layer: 0
2024-05-20 08:44:52,686:WARNING: 	 sim_type: seqTransf
2024-05-20 08:44:57,176:INFO: --------------------
2024-05-20 08:44:57,176:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-20 08:44:58,930:INFO: ***** Running test *****
2024-05-20 08:44:58,930:INFO:   Num examples = 1
2024-05-20 08:44:58,930:INFO:   Batch size = 64
2024-05-20 08:44:58,930:INFO:   Num steps = 1
2024-05-20 08:54:24,651:INFO: device: cuda:0 n_gpu: 1
2024-05-20 08:54:24,651:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-20 08:54:24,873:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-20 08:54:24,874:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-20 08:54:24,874:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-20 08:54:24,874:WARNING: 	 embed_dim: 512
2024-05-20 08:54:24,874:WARNING: 	 image_resolution: 224
2024-05-20 08:54:24,874:WARNING: 	 vision_layers: 12
2024-05-20 08:54:24,874:WARNING: 	 vision_width: 768
2024-05-20 08:54:24,874:WARNING: 	 vision_patch_size: 32
2024-05-20 08:54:24,874:WARNING: 	 context_length: 77
2024-05-20 08:54:24,874:WARNING: 	 vocab_size: 49408
2024-05-20 08:54:24,874:WARNING: 	 transformer_width: 512
2024-05-20 08:54:24,874:WARNING: 	 transformer_heads: 8
2024-05-20 08:54:24,874:WARNING: 	 transformer_layers: 12
2024-05-20 08:54:24,874:WARNING: 	 cut_top_layer: 0
2024-05-20 08:54:25,846:WARNING: 	 sim_type: seqTransf
2024-05-20 08:54:30,392:INFO: --------------------
2024-05-20 08:54:30,392:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-20 08:55:13,739:INFO: device: cuda:0 n_gpu: 1
2024-05-20 08:55:13,740:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-20 08:55:13,972:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-20 08:55:13,973:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-20 08:55:13,973:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-20 08:55:13,974:WARNING: 	 embed_dim: 512
2024-05-20 08:55:13,974:WARNING: 	 image_resolution: 224
2024-05-20 08:55:13,974:WARNING: 	 vision_layers: 12
2024-05-20 08:55:13,974:WARNING: 	 vision_width: 768
2024-05-20 08:55:13,974:WARNING: 	 vision_patch_size: 32
2024-05-20 08:55:13,974:WARNING: 	 context_length: 77
2024-05-20 08:55:13,974:WARNING: 	 vocab_size: 49408
2024-05-20 08:55:13,974:WARNING: 	 transformer_width: 512
2024-05-20 08:55:13,975:WARNING: 	 transformer_heads: 8
2024-05-20 08:55:13,975:WARNING: 	 transformer_layers: 12
2024-05-20 08:55:13,975:WARNING: 	 cut_top_layer: 0
2024-05-20 08:55:14,963:WARNING: 	 sim_type: seqTransf
2024-05-20 08:55:19,455:INFO: --------------------
2024-05-20 08:55:19,455:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-20 08:58:45,315:INFO: device: cuda:0 n_gpu: 1
2024-05-20 08:58:45,315:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-20 08:58:45,539:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-20 08:58:45,539:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-20 08:58:45,539:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-20 08:58:45,539:WARNING: 	 embed_dim: 512
2024-05-20 08:58:45,539:WARNING: 	 image_resolution: 224
2024-05-20 08:58:45,539:WARNING: 	 vision_layers: 12
2024-05-20 08:58:45,539:WARNING: 	 vision_width: 768
2024-05-20 08:58:45,539:WARNING: 	 vision_patch_size: 32
2024-05-20 08:58:45,539:WARNING: 	 context_length: 77
2024-05-20 08:58:45,539:WARNING: 	 vocab_size: 49408
2024-05-20 08:58:45,539:WARNING: 	 transformer_width: 512
2024-05-20 08:58:45,539:WARNING: 	 transformer_heads: 8
2024-05-20 08:58:45,539:WARNING: 	 transformer_layers: 12
2024-05-20 08:58:45,539:WARNING: 	 cut_top_layer: 0
2024-05-20 08:58:46,509:WARNING: 	 sim_type: seqTransf
2024-05-20 08:58:50,999:INFO: --------------------
2024-05-20 08:58:50,999:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-20 09:01:35,242:INFO: device: cuda:0 n_gpu: 1
2024-05-20 09:01:35,310:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-20 09:01:35,541:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-20 09:01:35,542:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-20 09:01:35,542:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-20 09:01:35,543:WARNING: 	 embed_dim: 512
2024-05-20 09:01:35,543:WARNING: 	 image_resolution: 224
2024-05-20 09:01:35,543:WARNING: 	 vision_layers: 12
2024-05-20 09:01:35,543:WARNING: 	 vision_width: 768
2024-05-20 09:01:35,543:WARNING: 	 vision_patch_size: 32
2024-05-20 09:01:35,544:WARNING: 	 context_length: 77
2024-05-20 09:01:35,544:WARNING: 	 vocab_size: 49408
2024-05-20 09:01:35,544:WARNING: 	 transformer_width: 512
2024-05-20 09:01:35,544:WARNING: 	 transformer_heads: 8
2024-05-20 09:01:35,544:WARNING: 	 transformer_layers: 12
2024-05-20 09:01:35,544:WARNING: 	 cut_top_layer: 0
2024-05-20 09:01:36,532:WARNING: 	 sim_type: seqTransf
2024-05-20 09:01:41,030:INFO: --------------------
2024-05-20 09:01:41,031:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-20 09:01:42,767:INFO: ***** Running test *****
2024-05-20 09:01:42,767:INFO:   Num examples = 1
2024-05-20 09:01:42,767:INFO:   Batch size = 64
2024-05-20 09:01:42,767:INFO:   Num steps = 1
2024-05-20 09:04:59,624:INFO: device: cuda:0 n_gpu: 1
2024-05-20 09:04:59,624:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-20 09:04:59,855:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-20 09:04:59,856:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-20 09:04:59,856:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-20 09:04:59,857:WARNING: 	 embed_dim: 512
2024-05-20 09:04:59,857:WARNING: 	 image_resolution: 224
2024-05-20 09:04:59,857:WARNING: 	 vision_layers: 12
2024-05-20 09:04:59,857:WARNING: 	 vision_width: 768
2024-05-20 09:04:59,857:WARNING: 	 vision_patch_size: 32
2024-05-20 09:04:59,858:WARNING: 	 context_length: 77
2024-05-20 09:04:59,858:WARNING: 	 vocab_size: 49408
2024-05-20 09:04:59,858:WARNING: 	 transformer_width: 512
2024-05-20 09:04:59,858:WARNING: 	 transformer_heads: 8
2024-05-20 09:04:59,858:WARNING: 	 transformer_layers: 12
2024-05-20 09:04:59,858:WARNING: 	 cut_top_layer: 0
2024-05-20 09:05:00,836:WARNING: 	 sim_type: seqTransf
2024-05-20 09:05:05,342:INFO: --------------------
2024-05-20 09:05:05,342:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-20 09:06:14,687:INFO: device: cuda:0 n_gpu: 1
2024-05-20 09:06:14,687:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-20 09:06:14,920:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-20 09:06:14,921:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-20 09:06:14,921:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-20 09:06:14,922:WARNING: 	 embed_dim: 512
2024-05-20 09:06:14,922:WARNING: 	 image_resolution: 224
2024-05-20 09:06:14,922:WARNING: 	 vision_layers: 12
2024-05-20 09:06:14,922:WARNING: 	 vision_width: 768
2024-05-20 09:06:14,922:WARNING: 	 vision_patch_size: 32
2024-05-20 09:06:14,922:WARNING: 	 context_length: 77
2024-05-20 09:06:14,922:WARNING: 	 vocab_size: 49408
2024-05-20 09:06:14,922:WARNING: 	 transformer_width: 512
2024-05-20 09:06:14,922:WARNING: 	 transformer_heads: 8
2024-05-20 09:06:14,922:WARNING: 	 transformer_layers: 12
2024-05-20 09:06:14,922:WARNING: 	 cut_top_layer: 0
2024-05-20 09:06:15,914:WARNING: 	 sim_type: seqTransf
2024-05-20 09:06:20,410:INFO: --------------------
2024-05-20 09:06:20,410:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-20 09:06:52,751:INFO: device: cuda:0 n_gpu: 1
2024-05-20 09:06:52,752:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-20 09:06:52,984:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-20 09:06:52,985:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-20 09:06:52,985:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-20 09:06:52,986:WARNING: 	 embed_dim: 512
2024-05-20 09:06:52,986:WARNING: 	 image_resolution: 224
2024-05-20 09:06:52,986:WARNING: 	 vision_layers: 12
2024-05-20 09:06:52,986:WARNING: 	 vision_width: 768
2024-05-20 09:06:52,986:WARNING: 	 vision_patch_size: 32
2024-05-20 09:06:52,986:WARNING: 	 context_length: 77
2024-05-20 09:06:52,986:WARNING: 	 vocab_size: 49408
2024-05-20 09:06:52,986:WARNING: 	 transformer_width: 512
2024-05-20 09:06:52,986:WARNING: 	 transformer_heads: 8
2024-05-20 09:06:52,986:WARNING: 	 transformer_layers: 12
2024-05-20 09:06:52,986:WARNING: 	 cut_top_layer: 0
2024-05-20 09:06:54,933:WARNING: 	 sim_type: seqTransf
2024-05-20 09:06:59,416:INFO: --------------------
2024-05-20 09:06:59,416:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-20 09:07:43,600:INFO: device: cuda:0 n_gpu: 1
2024-05-20 09:07:43,600:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-20 09:07:43,823:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-20 09:07:43,823:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-20 09:07:43,823:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-20 09:07:43,824:WARNING: 	 embed_dim: 512
2024-05-20 09:07:43,824:WARNING: 	 image_resolution: 224
2024-05-20 09:07:43,824:WARNING: 	 vision_layers: 12
2024-05-20 09:07:43,824:WARNING: 	 vision_width: 768
2024-05-20 09:07:43,824:WARNING: 	 vision_patch_size: 32
2024-05-20 09:07:43,824:WARNING: 	 context_length: 77
2024-05-20 09:07:43,824:WARNING: 	 vocab_size: 49408
2024-05-20 09:07:43,824:WARNING: 	 transformer_width: 512
2024-05-20 09:07:43,824:WARNING: 	 transformer_heads: 8
2024-05-20 09:07:43,824:WARNING: 	 transformer_layers: 12
2024-05-20 09:07:43,824:WARNING: 	 cut_top_layer: 0
2024-05-20 09:07:44,800:WARNING: 	 sim_type: seqTransf
2024-05-20 09:07:49,284:INFO: --------------------
2024-05-20 09:07:49,284:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-20 09:08:47,923:INFO: device: cuda:0 n_gpu: 1
2024-05-20 09:08:47,923:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-20 09:08:48,156:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-20 09:08:48,157:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-20 09:08:48,157:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-20 09:08:48,158:WARNING: 	 embed_dim: 512
2024-05-20 09:08:48,158:WARNING: 	 image_resolution: 224
2024-05-20 09:08:48,158:WARNING: 	 vision_layers: 12
2024-05-20 09:08:48,159:WARNING: 	 vision_width: 768
2024-05-20 09:08:48,159:WARNING: 	 vision_patch_size: 32
2024-05-20 09:08:48,159:WARNING: 	 context_length: 77
2024-05-20 09:08:48,159:WARNING: 	 vocab_size: 49408
2024-05-20 09:08:48,159:WARNING: 	 transformer_width: 512
2024-05-20 09:08:48,159:WARNING: 	 transformer_heads: 8
2024-05-20 09:08:48,159:WARNING: 	 transformer_layers: 12
2024-05-20 09:08:48,159:WARNING: 	 cut_top_layer: 0
2024-05-20 09:08:49,137:WARNING: 	 sim_type: seqTransf
2024-05-20 09:08:53,624:INFO: --------------------
2024-05-20 09:08:53,624:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-20 09:18:09,237:INFO: device: cuda:0 n_gpu: 1
2024-05-20 09:18:09,237:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-20 09:18:09,463:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-20 09:18:09,464:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-20 09:18:09,464:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-20 09:18:09,464:WARNING: 	 embed_dim: 512
2024-05-20 09:18:09,464:WARNING: 	 image_resolution: 224
2024-05-20 09:18:09,464:WARNING: 	 vision_layers: 12
2024-05-20 09:18:09,464:WARNING: 	 vision_width: 768
2024-05-20 09:18:09,464:WARNING: 	 vision_patch_size: 32
2024-05-20 09:18:09,464:WARNING: 	 context_length: 77
2024-05-20 09:18:09,464:WARNING: 	 vocab_size: 49408
2024-05-20 09:18:09,464:WARNING: 	 transformer_width: 512
2024-05-20 09:18:09,464:WARNING: 	 transformer_heads: 8
2024-05-20 09:18:09,464:WARNING: 	 transformer_layers: 12
2024-05-20 09:18:09,464:WARNING: 	 cut_top_layer: 0
2024-05-20 09:18:10,421:WARNING: 	 sim_type: seqTransf
2024-05-20 09:18:14,895:INFO: --------------------
2024-05-20 09:18:14,895:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-20 09:18:34,879:INFO: device: cuda:0 n_gpu: 1
2024-05-20 09:18:34,879:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-20 09:18:35,117:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-20 09:18:35,118:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-20 09:18:35,118:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-20 09:18:35,119:WARNING: 	 embed_dim: 512
2024-05-20 09:18:35,119:WARNING: 	 image_resolution: 224
2024-05-20 09:18:35,120:WARNING: 	 vision_layers: 12
2024-05-20 09:18:35,120:WARNING: 	 vision_width: 768
2024-05-20 09:18:35,120:WARNING: 	 vision_patch_size: 32
2024-05-20 09:18:35,120:WARNING: 	 context_length: 77
2024-05-20 09:18:35,120:WARNING: 	 vocab_size: 49408
2024-05-20 09:18:35,120:WARNING: 	 transformer_width: 512
2024-05-20 09:18:35,120:WARNING: 	 transformer_heads: 8
2024-05-20 09:18:35,120:WARNING: 	 transformer_layers: 12
2024-05-20 09:18:35,120:WARNING: 	 cut_top_layer: 0
2024-05-20 09:18:36,119:WARNING: 	 sim_type: seqTransf
2024-05-20 09:18:40,627:INFO: --------------------
2024-05-20 09:18:40,627:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-20 09:22:41,488:INFO: device: cuda:0 n_gpu: 1
2024-05-20 09:22:41,489:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-20 09:22:41,725:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-20 09:22:41,726:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-20 09:22:41,726:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-20 09:22:41,727:WARNING: 	 embed_dim: 512
2024-05-20 09:22:41,727:WARNING: 	 image_resolution: 224
2024-05-20 09:22:41,727:WARNING: 	 vision_layers: 12
2024-05-20 09:22:41,727:WARNING: 	 vision_width: 768
2024-05-20 09:22:41,728:WARNING: 	 vision_patch_size: 32
2024-05-20 09:22:41,728:WARNING: 	 context_length: 77
2024-05-20 09:22:41,728:WARNING: 	 vocab_size: 49408
2024-05-20 09:22:41,728:WARNING: 	 transformer_width: 512
2024-05-20 09:22:41,728:WARNING: 	 transformer_heads: 8
2024-05-20 09:22:41,728:WARNING: 	 transformer_layers: 12
2024-05-20 09:22:41,728:WARNING: 	 cut_top_layer: 0
2024-05-20 09:22:42,718:WARNING: 	 sim_type: seqTransf
2024-05-20 09:22:47,200:INFO: --------------------
2024-05-20 09:22:47,200:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-20 09:24:09,011:INFO: device: cuda:0 n_gpu: 1
2024-05-20 09:24:09,078:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-20 09:24:09,319:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-20 09:24:09,320:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-20 09:24:09,320:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-20 09:24:09,321:WARNING: 	 embed_dim: 512
2024-05-20 09:24:09,321:WARNING: 	 image_resolution: 224
2024-05-20 09:24:09,321:WARNING: 	 vision_layers: 12
2024-05-20 09:24:09,321:WARNING: 	 vision_width: 768
2024-05-20 09:24:09,321:WARNING: 	 vision_patch_size: 32
2024-05-20 09:24:09,321:WARNING: 	 context_length: 77
2024-05-20 09:24:09,321:WARNING: 	 vocab_size: 49408
2024-05-20 09:24:09,322:WARNING: 	 transformer_width: 512
2024-05-20 09:24:09,322:WARNING: 	 transformer_heads: 8
2024-05-20 09:24:09,322:WARNING: 	 transformer_layers: 12
2024-05-20 09:24:09,322:WARNING: 	 cut_top_layer: 0
2024-05-20 09:24:10,302:WARNING: 	 sim_type: seqTransf
2024-05-20 09:24:14,787:INFO: --------------------
2024-05-20 09:24:14,787:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-20 09:24:16,528:INFO: ***** Running test *****
2024-05-20 09:24:16,528:INFO:   Num examples = 1
2024-05-20 09:24:16,528:INFO:   Batch size = 64
2024-05-20 09:24:16,528:INFO:   Num steps = 1
2024-05-20 09:24:48,525:INFO: device: cuda:0 n_gpu: 1
2024-05-20 09:24:48,593:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-20 09:24:48,830:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-20 09:24:48,832:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-20 09:24:48,832:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-20 09:24:48,833:WARNING: 	 embed_dim: 512
2024-05-20 09:24:48,833:WARNING: 	 image_resolution: 224
2024-05-20 09:24:48,833:WARNING: 	 vision_layers: 12
2024-05-20 09:24:48,833:WARNING: 	 vision_width: 768
2024-05-20 09:24:48,833:WARNING: 	 vision_patch_size: 32
2024-05-20 09:24:48,833:WARNING: 	 context_length: 77
2024-05-20 09:24:48,833:WARNING: 	 vocab_size: 49408
2024-05-20 09:24:48,833:WARNING: 	 transformer_width: 512
2024-05-20 09:24:48,833:WARNING: 	 transformer_heads: 8
2024-05-20 09:24:48,833:WARNING: 	 transformer_layers: 12
2024-05-20 09:24:48,833:WARNING: 	 cut_top_layer: 0
2024-05-20 09:24:49,830:WARNING: 	 sim_type: seqTransf
2024-05-20 09:24:54,327:INFO: --------------------
2024-05-20 09:24:54,327:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-20 09:24:56,078:INFO: ***** Running test *****
2024-05-20 09:24:56,078:INFO:   Num examples = 1
2024-05-20 09:24:56,078:INFO:   Batch size = 64
2024-05-20 09:24:56,078:INFO:   Num steps = 1
2024-05-20 09:25:12,086:INFO: device: cuda:0 n_gpu: 1
2024-05-20 09:25:12,153:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-20 09:25:12,390:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-20 09:25:12,391:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-20 09:25:12,392:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-20 09:25:12,393:WARNING: 	 embed_dim: 512
2024-05-20 09:25:12,393:WARNING: 	 image_resolution: 224
2024-05-20 09:25:12,393:WARNING: 	 vision_layers: 12
2024-05-20 09:25:12,393:WARNING: 	 vision_width: 768
2024-05-20 09:25:12,393:WARNING: 	 vision_patch_size: 32
2024-05-20 09:25:12,393:WARNING: 	 context_length: 77
2024-05-20 09:25:12,393:WARNING: 	 vocab_size: 49408
2024-05-20 09:25:12,393:WARNING: 	 transformer_width: 512
2024-05-20 09:25:12,393:WARNING: 	 transformer_heads: 8
2024-05-20 09:25:12,393:WARNING: 	 transformer_layers: 12
2024-05-20 09:25:12,393:WARNING: 	 cut_top_layer: 0
2024-05-20 09:25:13,372:WARNING: 	 sim_type: seqTransf
2024-05-20 09:25:17,856:INFO: --------------------
2024-05-20 09:25:17,857:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-20 09:25:19,649:INFO: ***** Running test *****
2024-05-20 09:25:19,649:INFO:   Num examples = 1
2024-05-20 09:25:19,649:INFO:   Batch size = 64
2024-05-20 09:25:19,649:INFO:   Num steps = 1
2024-05-20 09:29:10,815:INFO: device: cuda:0 n_gpu: 1
2024-05-20 09:29:10,815:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-20 09:29:11,045:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-20 09:29:11,045:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-20 09:29:11,046:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-20 09:29:11,046:WARNING: 	 embed_dim: 512
2024-05-20 09:29:11,046:WARNING: 	 image_resolution: 224
2024-05-20 09:29:11,046:WARNING: 	 vision_layers: 12
2024-05-20 09:29:11,046:WARNING: 	 vision_width: 768
2024-05-20 09:29:11,046:WARNING: 	 vision_patch_size: 32
2024-05-20 09:29:11,046:WARNING: 	 context_length: 77
2024-05-20 09:29:11,046:WARNING: 	 vocab_size: 49408
2024-05-20 09:29:11,046:WARNING: 	 transformer_width: 512
2024-05-20 09:29:11,046:WARNING: 	 transformer_heads: 8
2024-05-20 09:29:11,046:WARNING: 	 transformer_layers: 12
2024-05-20 09:29:11,046:WARNING: 	 cut_top_layer: 0
2024-05-20 09:29:12,019:WARNING: 	 sim_type: seqTransf
2024-05-20 09:29:16,501:INFO: --------------------
2024-05-20 09:29:16,501:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
