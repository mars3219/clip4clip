2024-05-17 07:46:26,292:INFO: device: cuda:0 n_gpu: 1
2024-05-17 07:46:26,359:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-17 07:46:26,652:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-17 07:46:26,652:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-17 07:46:26,652:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-17 07:46:26,653:WARNING: 	 embed_dim: 512
2024-05-17 07:46:26,653:WARNING: 	 image_resolution: 224
2024-05-17 07:46:26,654:WARNING: 	 vision_layers: 12
2024-05-17 07:46:26,654:WARNING: 	 vision_width: 768
2024-05-17 07:46:26,654:WARNING: 	 vision_patch_size: 32
2024-05-17 07:46:26,654:WARNING: 	 context_length: 77
2024-05-17 07:46:26,654:WARNING: 	 vocab_size: 49408
2024-05-17 07:46:26,654:WARNING: 	 transformer_width: 512
2024-05-17 07:46:26,654:WARNING: 	 transformer_heads: 8
2024-05-17 07:46:26,654:WARNING: 	 transformer_layers: 12
2024-05-17 07:46:26,654:WARNING: 	 cut_top_layer: 0
2024-05-17 07:46:27,668:WARNING: 	 sim_type: seqTransf
2024-05-17 07:46:32,164:INFO: --------------------
2024-05-17 07:46:32,165:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-17 07:46:34,386:INFO: ***** Running test *****
2024-05-17 07:46:34,386:INFO:   Num examples = 29
2024-05-17 07:46:34,386:INFO:   Batch size = 64
2024-05-17 07:46:34,386:INFO:   Num steps = 1
2024-05-17 07:47:40,111:INFO: device: cuda:0 n_gpu: 1
2024-05-17 07:47:40,180:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-17 07:47:40,402:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-17 07:47:40,402:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-17 07:47:40,403:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-17 07:47:40,403:WARNING: 	 embed_dim: 512
2024-05-17 07:47:40,403:WARNING: 	 image_resolution: 224
2024-05-17 07:47:40,403:WARNING: 	 vision_layers: 12
2024-05-17 07:47:40,403:WARNING: 	 vision_width: 768
2024-05-17 07:47:40,403:WARNING: 	 vision_patch_size: 32
2024-05-17 07:47:40,403:WARNING: 	 context_length: 77
2024-05-17 07:47:40,403:WARNING: 	 vocab_size: 49408
2024-05-17 07:47:40,403:WARNING: 	 transformer_width: 512
2024-05-17 07:47:40,403:WARNING: 	 transformer_heads: 8
2024-05-17 07:47:40,403:WARNING: 	 transformer_layers: 12
2024-05-17 07:47:40,403:WARNING: 	 cut_top_layer: 0
2024-05-17 07:47:41,369:WARNING: 	 sim_type: seqTransf
2024-05-17 07:47:45,847:INFO: --------------------
2024-05-17 07:47:45,847:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-17 07:47:47,607:INFO: ***** Running test *****
2024-05-17 07:47:47,607:INFO:   Num examples = 29
2024-05-17 07:47:47,607:INFO:   Batch size = 64
2024-05-17 07:47:47,607:INFO:   Num steps = 1
2024-05-17 08:05:24,743:INFO: device: cuda:0 n_gpu: 1
2024-05-17 08:05:24,813:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-17 08:05:25,024:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-17 08:05:25,024:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-17 08:05:25,024:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-17 08:05:25,024:WARNING: 	 embed_dim: 512
2024-05-17 08:05:25,024:WARNING: 	 image_resolution: 224
2024-05-17 08:05:25,024:WARNING: 	 vision_layers: 12
2024-05-17 08:05:25,024:WARNING: 	 vision_width: 768
2024-05-17 08:05:25,024:WARNING: 	 vision_patch_size: 32
2024-05-17 08:05:25,024:WARNING: 	 context_length: 77
2024-05-17 08:05:25,024:WARNING: 	 vocab_size: 49408
2024-05-17 08:05:25,025:WARNING: 	 transformer_width: 512
2024-05-17 08:05:25,025:WARNING: 	 transformer_heads: 8
2024-05-17 08:05:25,025:WARNING: 	 transformer_layers: 12
2024-05-17 08:05:25,025:WARNING: 	 cut_top_layer: 0
2024-05-17 08:05:25,977:WARNING: 	 sim_type: seqTransf
2024-05-17 08:05:30,439:INFO: --------------------
2024-05-17 08:05:30,439:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-17 08:05:32,164:INFO: ***** Running test *****
2024-05-17 08:05:32,164:INFO:   Num examples = 1
2024-05-17 08:05:32,164:INFO:   Batch size = 64
2024-05-17 08:05:32,164:INFO:   Num steps = 1
2024-05-17 08:05:32,974:INFO: sim matrix size: 1, 1
2024-05-17 08:05:32,974:INFO: 	 Length-T: 1, Length-V:1
2024-05-17 08:05:32,974:INFO: Text-to-Video:
2024-05-17 08:05:32,974:INFO: 	>>>  R@1: 100.0 - R@5: 100.0 - R@10: 100.0 - Median R: 1.0 - Mean R: 1.0
2024-05-17 08:05:32,974:INFO: Video-to-Text:
2024-05-17 08:05:32,974:INFO: 	>>>  V2T$R@1: 100.0 - V2T$R@5: 100.0 - V2T$R@10: 100.0 - V2T$Median R: 1.0 - V2T$Mean R: 1.0
2024-05-17 08:07:19,273:INFO: device: cuda:0 n_gpu: 1
2024-05-17 08:07:19,340:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-17 08:07:19,564:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-17 08:07:19,565:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-17 08:07:19,565:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-17 08:07:19,566:WARNING: 	 embed_dim: 512
2024-05-17 08:07:19,566:WARNING: 	 image_resolution: 224
2024-05-17 08:07:19,566:WARNING: 	 vision_layers: 12
2024-05-17 08:07:19,566:WARNING: 	 vision_width: 768
2024-05-17 08:07:19,566:WARNING: 	 vision_patch_size: 32
2024-05-17 08:07:19,566:WARNING: 	 context_length: 77
2024-05-17 08:07:19,566:WARNING: 	 vocab_size: 49408
2024-05-17 08:07:19,566:WARNING: 	 transformer_width: 512
2024-05-17 08:07:19,566:WARNING: 	 transformer_heads: 8
2024-05-17 08:07:19,567:WARNING: 	 transformer_layers: 12
2024-05-17 08:07:19,567:WARNING: 	 cut_top_layer: 0
2024-05-17 08:07:20,549:WARNING: 	 sim_type: seqTransf
2024-05-17 08:07:25,075:INFO: --------------------
2024-05-17 08:07:25,075:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-17 08:07:26,814:INFO: ***** Running test *****
2024-05-17 08:07:26,814:INFO:   Num examples = 1
2024-05-17 08:07:26,814:INFO:   Batch size = 64
2024-05-17 08:07:26,814:INFO:   Num steps = 1
2024-05-18 09:15:09,654:INFO: device: cuda:0 n_gpu: 1
2024-05-18 09:15:09,725:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-18 09:15:10,643:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-18 09:15:10,644:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-18 09:15:10,644:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-18 09:15:10,645:WARNING: 	 embed_dim: 512
2024-05-18 09:15:10,645:WARNING: 	 image_resolution: 224
2024-05-18 09:15:10,645:WARNING: 	 vision_layers: 12
2024-05-18 09:15:10,645:WARNING: 	 vision_width: 768
2024-05-18 09:15:10,645:WARNING: 	 vision_patch_size: 32
2024-05-18 09:15:10,645:WARNING: 	 context_length: 77
2024-05-18 09:15:10,645:WARNING: 	 vocab_size: 49408
2024-05-18 09:15:10,645:WARNING: 	 transformer_width: 512
2024-05-18 09:15:10,645:WARNING: 	 transformer_heads: 8
2024-05-18 09:15:10,645:WARNING: 	 transformer_layers: 12
2024-05-18 09:15:10,646:WARNING: 	 cut_top_layer: 0
2024-05-18 09:15:11,530:WARNING: 	 sim_type: seqTransf
2024-05-18 09:15:15,363:INFO: --------------------
2024-05-18 09:15:15,364:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-18 09:15:19,705:INFO: ***** Running test *****
2024-05-18 09:15:19,705:INFO:   Num examples = 1
2024-05-18 09:15:19,705:INFO:   Batch size = 64
2024-05-18 09:15:19,705:INFO:   Num steps = 1
2024-05-18 12:36:15,166:INFO: sim matrix size: 1, 1
2024-05-18 12:36:32,941:INFO: 	 Length-T: 1, Length-V:1
2024-05-18 12:36:34,610:INFO: Text-to-Video:
2024-05-18 12:36:36,084:INFO: 	>>>  R@1: 100.0 - R@5: 100.0 - R@10: 100.0 - Median R: 1.0 - Mean R: 1.0
2024-05-18 12:36:36,838:INFO: Video-to-Text:
2024-05-18 12:36:41,514:INFO: 	>>>  V2T$R@1: 100.0 - V2T$R@5: 100.0 - V2T$R@10: 100.0 - V2T$Median R: 1.0 - V2T$Mean R: 1.0
2024-05-19 04:47:46,567:INFO: device: cuda:0 n_gpu: 1
2024-05-19 04:47:46,634:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-19 04:47:47,553:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-19 04:47:47,554:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-19 04:47:47,554:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-19 04:47:47,555:WARNING: 	 embed_dim: 512
2024-05-19 04:47:47,555:WARNING: 	 image_resolution: 224
2024-05-19 04:47:47,555:WARNING: 	 vision_layers: 12
2024-05-19 04:47:47,555:WARNING: 	 vision_width: 768
2024-05-19 04:47:47,555:WARNING: 	 vision_patch_size: 32
2024-05-19 04:47:47,555:WARNING: 	 context_length: 77
2024-05-19 04:47:47,555:WARNING: 	 vocab_size: 49408
2024-05-19 04:47:47,555:WARNING: 	 transformer_width: 512
2024-05-19 04:47:47,555:WARNING: 	 transformer_heads: 8
2024-05-19 04:47:47,555:WARNING: 	 transformer_layers: 12
2024-05-19 04:47:47,555:WARNING: 	 cut_top_layer: 0
2024-05-19 04:47:48,437:WARNING: 	 sim_type: seqTransf
2024-05-19 04:47:52,270:INFO: --------------------
2024-05-19 04:47:52,270:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-19 04:47:56,610:INFO: ***** Running test *****
2024-05-19 04:47:56,610:INFO:   Num examples = 1
2024-05-19 04:47:56,610:INFO:   Batch size = 64
2024-05-19 04:47:56,611:INFO:   Num steps = 1
2024-05-19 05:48:39,127:INFO: device: cuda:0 n_gpu: 1
2024-05-19 05:48:39,128:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-19 05:48:39,360:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-19 05:48:39,360:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-19 05:48:39,360:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-19 05:48:39,361:WARNING: 	 embed_dim: 512
2024-05-19 05:48:39,361:WARNING: 	 image_resolution: 224
2024-05-19 05:48:39,362:WARNING: 	 vision_layers: 12
2024-05-19 05:48:39,362:WARNING: 	 vision_width: 768
2024-05-19 05:48:39,362:WARNING: 	 vision_patch_size: 32
2024-05-19 05:48:39,362:WARNING: 	 context_length: 77
2024-05-19 05:48:39,362:WARNING: 	 vocab_size: 49408
2024-05-19 05:48:39,362:WARNING: 	 transformer_width: 512
2024-05-19 05:48:39,362:WARNING: 	 transformer_heads: 8
2024-05-19 05:48:39,362:WARNING: 	 transformer_layers: 12
2024-05-19 05:48:39,362:WARNING: 	 cut_top_layer: 0
2024-05-19 05:48:40,235:WARNING: 	 sim_type: seqTransf
2024-05-19 05:48:44,007:INFO: --------------------
2024-05-19 05:48:44,007:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-19 05:49:50,608:INFO: device: cuda:0 n_gpu: 1
2024-05-19 05:49:50,609:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-19 05:49:50,838:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-19 05:49:50,839:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-19 05:49:50,839:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-19 05:49:50,840:WARNING: 	 embed_dim: 512
2024-05-19 05:49:50,840:WARNING: 	 image_resolution: 224
2024-05-19 05:49:50,840:WARNING: 	 vision_layers: 12
2024-05-19 05:49:50,840:WARNING: 	 vision_width: 768
2024-05-19 05:49:50,840:WARNING: 	 vision_patch_size: 32
2024-05-19 05:49:50,840:WARNING: 	 context_length: 77
2024-05-19 05:49:50,840:WARNING: 	 vocab_size: 49408
2024-05-19 05:49:50,840:WARNING: 	 transformer_width: 512
2024-05-19 05:49:50,840:WARNING: 	 transformer_heads: 8
2024-05-19 05:49:50,840:WARNING: 	 transformer_layers: 12
2024-05-19 05:49:50,840:WARNING: 	 cut_top_layer: 0
2024-05-19 05:49:51,696:WARNING: 	 sim_type: seqTransf
2024-05-19 05:49:55,498:INFO: --------------------
2024-05-19 05:49:55,498:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-19 05:50:28,644:INFO: device: cuda:0 n_gpu: 1
2024-05-19 05:50:28,644:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-19 05:50:28,869:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-19 05:50:28,869:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-19 05:50:28,869:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-19 05:50:28,870:WARNING: 	 embed_dim: 512
2024-05-19 05:50:28,870:WARNING: 	 image_resolution: 224
2024-05-19 05:50:28,870:WARNING: 	 vision_layers: 12
2024-05-19 05:50:28,871:WARNING: 	 vision_width: 768
2024-05-19 05:50:28,871:WARNING: 	 vision_patch_size: 32
2024-05-19 05:50:28,871:WARNING: 	 context_length: 77
2024-05-19 05:50:28,871:WARNING: 	 vocab_size: 49408
2024-05-19 05:50:28,871:WARNING: 	 transformer_width: 512
2024-05-19 05:50:28,871:WARNING: 	 transformer_heads: 8
2024-05-19 05:50:28,871:WARNING: 	 transformer_layers: 12
2024-05-19 05:50:28,871:WARNING: 	 cut_top_layer: 0
2024-05-19 05:50:29,720:WARNING: 	 sim_type: seqTransf
2024-05-19 05:50:33,517:INFO: --------------------
2024-05-19 05:50:33,517:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-19 05:51:07,401:INFO: device: cuda:0 n_gpu: 1
2024-05-19 05:51:07,402:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-19 05:51:07,626:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-19 05:51:07,627:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-19 05:51:07,627:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-19 05:51:07,628:WARNING: 	 embed_dim: 512
2024-05-19 05:51:07,628:WARNING: 	 image_resolution: 224
2024-05-19 05:51:07,628:WARNING: 	 vision_layers: 12
2024-05-19 05:51:07,628:WARNING: 	 vision_width: 768
2024-05-19 05:51:07,628:WARNING: 	 vision_patch_size: 32
2024-05-19 05:51:07,628:WARNING: 	 context_length: 77
2024-05-19 05:51:07,628:WARNING: 	 vocab_size: 49408
2024-05-19 05:51:07,628:WARNING: 	 transformer_width: 512
2024-05-19 05:51:07,628:WARNING: 	 transformer_heads: 8
2024-05-19 05:51:07,628:WARNING: 	 transformer_layers: 12
2024-05-19 05:51:07,628:WARNING: 	 cut_top_layer: 0
2024-05-19 05:51:08,526:WARNING: 	 sim_type: seqTransf
2024-05-19 05:51:12,317:INFO: --------------------
2024-05-19 05:51:12,317:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-19 05:53:21,796:INFO: device: cuda:0 n_gpu: 1
2024-05-19 05:53:21,796:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-19 05:53:22,023:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-19 05:53:22,024:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-19 05:53:22,024:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-19 05:53:22,025:WARNING: 	 embed_dim: 512
2024-05-19 05:53:22,025:WARNING: 	 image_resolution: 224
2024-05-19 05:53:22,025:WARNING: 	 vision_layers: 12
2024-05-19 05:53:22,025:WARNING: 	 vision_width: 768
2024-05-19 05:53:22,025:WARNING: 	 vision_patch_size: 32
2024-05-19 05:53:22,025:WARNING: 	 context_length: 77
2024-05-19 05:53:22,025:WARNING: 	 vocab_size: 49408
2024-05-19 05:53:22,026:WARNING: 	 transformer_width: 512
2024-05-19 05:53:22,026:WARNING: 	 transformer_heads: 8
2024-05-19 05:53:22,026:WARNING: 	 transformer_layers: 12
2024-05-19 05:53:22,026:WARNING: 	 cut_top_layer: 0
2024-05-19 05:53:22,903:WARNING: 	 sim_type: seqTransf
2024-05-19 05:53:26,695:INFO: --------------------
2024-05-19 05:53:26,695:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-19 06:01:24,512:INFO: device: cuda:0 n_gpu: 1
2024-05-19 06:01:24,512:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-19 06:01:24,742:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-19 06:01:24,743:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-19 06:01:24,743:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-19 06:01:24,744:WARNING: 	 embed_dim: 512
2024-05-19 06:01:24,744:WARNING: 	 image_resolution: 224
2024-05-19 06:01:24,744:WARNING: 	 vision_layers: 12
2024-05-19 06:01:24,744:WARNING: 	 vision_width: 768
2024-05-19 06:01:24,744:WARNING: 	 vision_patch_size: 32
2024-05-19 06:01:24,744:WARNING: 	 context_length: 77
2024-05-19 06:01:24,744:WARNING: 	 vocab_size: 49408
2024-05-19 06:01:24,744:WARNING: 	 transformer_width: 512
2024-05-19 06:01:24,744:WARNING: 	 transformer_heads: 8
2024-05-19 06:01:24,744:WARNING: 	 transformer_layers: 12
2024-05-19 06:01:24,744:WARNING: 	 cut_top_layer: 0
2024-05-19 06:01:25,594:WARNING: 	 sim_type: seqTransf
2024-05-19 06:01:29,371:INFO: --------------------
2024-05-19 06:01:29,371:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-19 06:05:03,280:INFO: device: cuda:0 n_gpu: 1
2024-05-19 06:05:03,280:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-19 06:05:03,510:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-19 06:05:03,512:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-19 06:05:03,512:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-19 06:05:03,512:WARNING: 	 embed_dim: 512
2024-05-19 06:05:03,512:WARNING: 	 image_resolution: 224
2024-05-19 06:05:03,513:WARNING: 	 vision_layers: 12
2024-05-19 06:05:03,513:WARNING: 	 vision_width: 768
2024-05-19 06:05:03,513:WARNING: 	 vision_patch_size: 32
2024-05-19 06:05:03,513:WARNING: 	 context_length: 77
2024-05-19 06:05:03,513:WARNING: 	 vocab_size: 49408
2024-05-19 06:05:03,513:WARNING: 	 transformer_width: 512
2024-05-19 06:05:03,513:WARNING: 	 transformer_heads: 8
2024-05-19 06:05:03,513:WARNING: 	 transformer_layers: 12
2024-05-19 06:05:03,513:WARNING: 	 cut_top_layer: 0
2024-05-19 06:05:04,394:WARNING: 	 sim_type: seqTransf
2024-05-19 06:05:08,215:INFO: --------------------
2024-05-19 06:05:08,215:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-19 06:09:06,444:INFO: device: cuda:0 n_gpu: 1
2024-05-19 06:09:06,514:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-19 06:09:06,744:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-19 06:09:06,746:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-19 06:09:06,746:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-19 06:09:06,746:WARNING: 	 embed_dim: 512
2024-05-19 06:09:06,747:WARNING: 	 image_resolution: 224
2024-05-19 06:09:06,747:WARNING: 	 vision_layers: 12
2024-05-19 06:09:06,747:WARNING: 	 vision_width: 768
2024-05-19 06:09:06,747:WARNING: 	 vision_patch_size: 32
2024-05-19 06:09:06,747:WARNING: 	 context_length: 77
2024-05-19 06:09:06,747:WARNING: 	 vocab_size: 49408
2024-05-19 06:09:06,747:WARNING: 	 transformer_width: 512
2024-05-19 06:09:06,747:WARNING: 	 transformer_heads: 8
2024-05-19 06:09:06,747:WARNING: 	 transformer_layers: 12
2024-05-19 06:09:06,747:WARNING: 	 cut_top_layer: 0
2024-05-19 06:09:07,602:WARNING: 	 sim_type: seqTransf
2024-05-19 06:09:11,392:INFO: --------------------
2024-05-19 06:09:11,392:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-19 06:09:13,520:INFO: ***** Running test *****
2024-05-19 06:09:13,521:INFO:   Num examples = 1
2024-05-19 06:09:13,521:INFO:   Batch size = 64
2024-05-19 06:09:13,521:INFO:   Num steps = 1
2024-05-19 06:10:07,169:INFO: device: cuda:0 n_gpu: 1
2024-05-19 06:10:07,238:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-19 06:10:07,469:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-19 06:10:07,470:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-19 06:10:07,470:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-19 06:10:07,471:WARNING: 	 embed_dim: 512
2024-05-19 06:10:07,471:WARNING: 	 image_resolution: 224
2024-05-19 06:10:07,471:WARNING: 	 vision_layers: 12
2024-05-19 06:10:07,471:WARNING: 	 vision_width: 768
2024-05-19 06:10:07,471:WARNING: 	 vision_patch_size: 32
2024-05-19 06:10:07,471:WARNING: 	 context_length: 77
2024-05-19 06:10:07,471:WARNING: 	 vocab_size: 49408
2024-05-19 06:10:07,471:WARNING: 	 transformer_width: 512
2024-05-19 06:10:07,471:WARNING: 	 transformer_heads: 8
2024-05-19 06:10:07,472:WARNING: 	 transformer_layers: 12
2024-05-19 06:10:07,472:WARNING: 	 cut_top_layer: 0
2024-05-19 06:10:08,323:WARNING: 	 sim_type: seqTransf
2024-05-19 06:10:12,120:INFO: --------------------
2024-05-19 06:10:12,121:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-19 06:10:14,212:INFO: ***** Running test *****
2024-05-19 06:10:14,212:INFO:   Num examples = 1
2024-05-19 06:10:14,212:INFO:   Batch size = 64
2024-05-19 06:10:14,212:INFO:   Num steps = 1
2024-05-19 06:11:18,641:INFO: device: cuda:0 n_gpu: 1
2024-05-19 06:11:18,711:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-19 06:11:18,948:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-19 06:11:18,949:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-19 06:11:18,949:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-19 06:11:18,950:WARNING: 	 embed_dim: 512
2024-05-19 06:11:18,950:WARNING: 	 image_resolution: 224
2024-05-19 06:11:18,950:WARNING: 	 vision_layers: 12
2024-05-19 06:11:18,950:WARNING: 	 vision_width: 768
2024-05-19 06:11:18,950:WARNING: 	 vision_patch_size: 32
2024-05-19 06:11:18,950:WARNING: 	 context_length: 77
2024-05-19 06:11:18,950:WARNING: 	 vocab_size: 49408
2024-05-19 06:11:18,950:WARNING: 	 transformer_width: 512
2024-05-19 06:11:18,950:WARNING: 	 transformer_heads: 8
2024-05-19 06:11:18,951:WARNING: 	 transformer_layers: 12
2024-05-19 06:11:18,951:WARNING: 	 cut_top_layer: 0
2024-05-19 06:11:19,824:WARNING: 	 sim_type: seqTransf
2024-05-19 06:11:23,657:INFO: --------------------
2024-05-19 06:11:23,657:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-19 06:11:25,781:INFO: ***** Running test *****
2024-05-19 06:11:25,781:INFO:   Num examples = 1
2024-05-19 06:11:25,781:INFO:   Batch size = 64
2024-05-19 06:11:25,781:INFO:   Num steps = 1
2024-05-19 06:12:13,949:INFO: device: cuda:0 n_gpu: 1
2024-05-19 06:12:14,018:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-19 06:12:14,257:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-19 06:12:14,259:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-19 06:12:14,259:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-19 06:12:14,260:WARNING: 	 embed_dim: 512
2024-05-19 06:12:14,260:WARNING: 	 image_resolution: 224
2024-05-19 06:12:14,260:WARNING: 	 vision_layers: 12
2024-05-19 06:12:14,260:WARNING: 	 vision_width: 768
2024-05-19 06:12:14,260:WARNING: 	 vision_patch_size: 32
2024-05-19 06:12:14,260:WARNING: 	 context_length: 77
2024-05-19 06:12:14,260:WARNING: 	 vocab_size: 49408
2024-05-19 06:12:14,260:WARNING: 	 transformer_width: 512
2024-05-19 06:12:14,260:WARNING: 	 transformer_heads: 8
2024-05-19 06:12:14,260:WARNING: 	 transformer_layers: 12
2024-05-19 06:12:14,260:WARNING: 	 cut_top_layer: 0
2024-05-19 06:12:15,121:WARNING: 	 sim_type: seqTransf
2024-05-19 06:12:18,899:INFO: --------------------
2024-05-19 06:12:18,899:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-19 06:12:20,984:INFO: ***** Running test *****
2024-05-19 06:12:20,984:INFO:   Num examples = 1
2024-05-19 06:12:20,984:INFO:   Batch size = 64
2024-05-19 06:12:20,984:INFO:   Num steps = 1
2024-05-19 06:14:24,249:INFO: device: cuda:0 n_gpu: 1
2024-05-19 06:14:24,249:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-19 06:14:24,482:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-19 06:14:24,483:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-19 06:14:24,483:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-19 06:14:24,484:WARNING: 	 embed_dim: 512
2024-05-19 06:14:24,484:WARNING: 	 image_resolution: 224
2024-05-19 06:14:24,484:WARNING: 	 vision_layers: 12
2024-05-19 06:14:24,484:WARNING: 	 vision_width: 768
2024-05-19 06:14:24,484:WARNING: 	 vision_patch_size: 32
2024-05-19 06:14:24,484:WARNING: 	 context_length: 77
2024-05-19 06:14:24,484:WARNING: 	 vocab_size: 49408
2024-05-19 06:14:24,484:WARNING: 	 transformer_width: 512
2024-05-19 06:14:24,485:WARNING: 	 transformer_heads: 8
2024-05-19 06:14:24,485:WARNING: 	 transformer_layers: 12
2024-05-19 06:14:24,485:WARNING: 	 cut_top_layer: 0
2024-05-19 06:14:25,351:WARNING: 	 sim_type: seqTransf
2024-05-19 06:14:29,172:INFO: --------------------
2024-05-19 06:14:29,172:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-19 06:17:55,708:INFO: device: cuda:0 n_gpu: 1
2024-05-19 06:17:55,709:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-19 06:17:55,938:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-19 06:17:55,939:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-19 06:17:55,940:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-19 06:17:55,940:WARNING: 	 embed_dim: 512
2024-05-19 06:17:55,940:WARNING: 	 image_resolution: 224
2024-05-19 06:17:55,941:WARNING: 	 vision_layers: 12
2024-05-19 06:17:55,941:WARNING: 	 vision_width: 768
2024-05-19 06:17:55,941:WARNING: 	 vision_patch_size: 32
2024-05-19 06:17:55,941:WARNING: 	 context_length: 77
2024-05-19 06:17:55,941:WARNING: 	 vocab_size: 49408
2024-05-19 06:17:55,941:WARNING: 	 transformer_width: 512
2024-05-19 06:17:55,941:WARNING: 	 transformer_heads: 8
2024-05-19 06:17:55,941:WARNING: 	 transformer_layers: 12
2024-05-19 06:17:55,941:WARNING: 	 cut_top_layer: 0
2024-05-19 06:17:56,801:WARNING: 	 sim_type: seqTransf
2024-05-19 06:18:00,622:INFO: --------------------
2024-05-19 06:18:00,622:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-19 06:19:28,437:INFO: device: cuda:0 n_gpu: 1
2024-05-19 06:19:28,438:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-19 06:19:28,675:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-19 06:19:28,676:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-19 06:19:28,676:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-19 06:19:28,677:WARNING: 	 embed_dim: 512
2024-05-19 06:19:28,677:WARNING: 	 image_resolution: 224
2024-05-19 06:19:28,677:WARNING: 	 vision_layers: 12
2024-05-19 06:19:28,677:WARNING: 	 vision_width: 768
2024-05-19 06:19:28,678:WARNING: 	 vision_patch_size: 32
2024-05-19 06:19:28,678:WARNING: 	 context_length: 77
2024-05-19 06:19:28,678:WARNING: 	 vocab_size: 49408
2024-05-19 06:19:28,678:WARNING: 	 transformer_width: 512
2024-05-19 06:19:28,678:WARNING: 	 transformer_heads: 8
2024-05-19 06:19:28,678:WARNING: 	 transformer_layers: 12
2024-05-19 06:19:28,678:WARNING: 	 cut_top_layer: 0
2024-05-19 06:19:29,570:WARNING: 	 sim_type: seqTransf
2024-05-19 06:19:33,380:INFO: --------------------
2024-05-19 06:19:33,381:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-19 06:20:34,412:INFO: device: cuda:0 n_gpu: 1
2024-05-19 06:20:34,412:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-19 06:20:34,643:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-19 06:20:34,644:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-19 06:20:34,644:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-19 06:20:34,645:WARNING: 	 embed_dim: 512
2024-05-19 06:20:34,645:WARNING: 	 image_resolution: 224
2024-05-19 06:20:34,645:WARNING: 	 vision_layers: 12
2024-05-19 06:20:34,645:WARNING: 	 vision_width: 768
2024-05-19 06:20:34,645:WARNING: 	 vision_patch_size: 32
2024-05-19 06:20:34,646:WARNING: 	 context_length: 77
2024-05-19 06:20:34,646:WARNING: 	 vocab_size: 49408
2024-05-19 06:20:34,646:WARNING: 	 transformer_width: 512
2024-05-19 06:20:34,646:WARNING: 	 transformer_heads: 8
2024-05-19 06:20:34,646:WARNING: 	 transformer_layers: 12
2024-05-19 06:20:34,646:WARNING: 	 cut_top_layer: 0
2024-05-19 06:20:35,536:WARNING: 	 sim_type: seqTransf
2024-05-19 06:20:39,321:INFO: --------------------
2024-05-19 06:20:39,321:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-19 06:21:20,037:INFO: device: cuda:0 n_gpu: 1
2024-05-19 06:21:20,037:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-19 06:21:20,277:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-19 06:21:20,278:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-19 06:21:20,278:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-19 06:21:20,279:WARNING: 	 embed_dim: 512
2024-05-19 06:21:20,279:WARNING: 	 image_resolution: 224
2024-05-19 06:21:20,279:WARNING: 	 vision_layers: 12
2024-05-19 06:21:20,279:WARNING: 	 vision_width: 768
2024-05-19 06:21:20,279:WARNING: 	 vision_patch_size: 32
2024-05-19 06:21:20,279:WARNING: 	 context_length: 77
2024-05-19 06:21:20,280:WARNING: 	 vocab_size: 49408
2024-05-19 06:21:20,280:WARNING: 	 transformer_width: 512
2024-05-19 06:21:20,280:WARNING: 	 transformer_heads: 8
2024-05-19 06:21:20,280:WARNING: 	 transformer_layers: 12
2024-05-19 06:21:20,280:WARNING: 	 cut_top_layer: 0
2024-05-19 06:21:21,169:WARNING: 	 sim_type: seqTransf
2024-05-19 06:21:24,987:INFO: --------------------
2024-05-19 06:21:24,987:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-19 06:30:52,080:INFO: device: cuda:0 n_gpu: 1
2024-05-19 06:30:52,081:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-19 06:30:52,319:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-19 06:30:52,320:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-19 06:30:52,320:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-19 06:30:52,321:WARNING: 	 embed_dim: 512
2024-05-19 06:30:52,321:WARNING: 	 image_resolution: 224
2024-05-19 06:30:52,321:WARNING: 	 vision_layers: 12
2024-05-19 06:30:52,321:WARNING: 	 vision_width: 768
2024-05-19 06:30:52,321:WARNING: 	 vision_patch_size: 32
2024-05-19 06:30:52,321:WARNING: 	 context_length: 77
2024-05-19 06:30:52,321:WARNING: 	 vocab_size: 49408
2024-05-19 06:30:52,321:WARNING: 	 transformer_width: 512
2024-05-19 06:30:52,321:WARNING: 	 transformer_heads: 8
2024-05-19 06:30:52,321:WARNING: 	 transformer_layers: 12
2024-05-19 06:30:52,321:WARNING: 	 cut_top_layer: 0
2024-05-19 06:30:53,225:WARNING: 	 sim_type: seqTransf
2024-05-19 06:30:57,024:INFO: --------------------
2024-05-19 06:30:57,025:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-19 06:32:35,016:INFO: device: cuda:0 n_gpu: 1
2024-05-19 06:32:35,016:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-19 06:32:35,247:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-19 06:32:35,248:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-19 06:32:35,248:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-19 06:32:35,249:WARNING: 	 embed_dim: 512
2024-05-19 06:32:35,249:WARNING: 	 image_resolution: 224
2024-05-19 06:32:35,249:WARNING: 	 vision_layers: 12
2024-05-19 06:32:35,249:WARNING: 	 vision_width: 768
2024-05-19 06:32:35,250:WARNING: 	 vision_patch_size: 32
2024-05-19 06:32:35,250:WARNING: 	 context_length: 77
2024-05-19 06:32:35,250:WARNING: 	 vocab_size: 49408
2024-05-19 06:32:35,250:WARNING: 	 transformer_width: 512
2024-05-19 06:32:35,250:WARNING: 	 transformer_heads: 8
2024-05-19 06:32:35,250:WARNING: 	 transformer_layers: 12
2024-05-19 06:32:35,250:WARNING: 	 cut_top_layer: 0
2024-05-19 06:32:36,136:WARNING: 	 sim_type: seqTransf
2024-05-19 06:32:39,975:INFO: --------------------
2024-05-19 06:32:39,975:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-19 06:33:46,036:INFO: device: cuda:0 n_gpu: 1
2024-05-19 06:33:46,037:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-19 06:33:46,267:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-19 06:33:46,268:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-19 06:33:46,269:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-19 06:33:46,269:WARNING: 	 embed_dim: 512
2024-05-19 06:33:46,269:WARNING: 	 image_resolution: 224
2024-05-19 06:33:46,270:WARNING: 	 vision_layers: 12
2024-05-19 06:33:46,270:WARNING: 	 vision_width: 768
2024-05-19 06:33:46,270:WARNING: 	 vision_patch_size: 32
2024-05-19 06:33:46,270:WARNING: 	 context_length: 77
2024-05-19 06:33:46,270:WARNING: 	 vocab_size: 49408
2024-05-19 06:33:46,270:WARNING: 	 transformer_width: 512
2024-05-19 06:33:46,270:WARNING: 	 transformer_heads: 8
2024-05-19 06:33:46,270:WARNING: 	 transformer_layers: 12
2024-05-19 06:33:46,270:WARNING: 	 cut_top_layer: 0
2024-05-19 06:33:47,158:WARNING: 	 sim_type: seqTransf
2024-05-19 06:33:50,960:INFO: --------------------
2024-05-19 06:33:50,960:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-19 06:34:34,496:INFO: device: cuda:0 n_gpu: 1
2024-05-19 06:34:34,564:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-19 06:34:34,797:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-19 06:34:34,798:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-19 06:34:34,798:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-19 06:34:34,799:WARNING: 	 embed_dim: 512
2024-05-19 06:34:34,799:WARNING: 	 image_resolution: 224
2024-05-19 06:34:34,799:WARNING: 	 vision_layers: 12
2024-05-19 06:34:34,799:WARNING: 	 vision_width: 768
2024-05-19 06:34:34,799:WARNING: 	 vision_patch_size: 32
2024-05-19 06:34:34,799:WARNING: 	 context_length: 77
2024-05-19 06:34:34,799:WARNING: 	 vocab_size: 49408
2024-05-19 06:34:34,799:WARNING: 	 transformer_width: 512
2024-05-19 06:34:34,799:WARNING: 	 transformer_heads: 8
2024-05-19 06:34:34,799:WARNING: 	 transformer_layers: 12
2024-05-19 06:34:34,799:WARNING: 	 cut_top_layer: 0
2024-05-19 06:34:35,664:WARNING: 	 sim_type: seqTransf
2024-05-19 06:34:39,465:INFO: --------------------
2024-05-19 06:34:39,465:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-19 06:34:41,575:INFO: ***** Running test *****
2024-05-19 06:34:41,576:INFO:   Num examples = 1
2024-05-19 06:34:41,576:INFO:   Batch size = 64
2024-05-19 06:34:41,576:INFO:   Num steps = 1
2024-05-19 06:36:42,691:INFO: device: cuda:0 n_gpu: 1
2024-05-19 06:36:42,692:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-19 06:36:42,925:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-19 06:36:42,926:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-19 06:36:42,926:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-19 06:36:42,927:WARNING: 	 embed_dim: 512
2024-05-19 06:36:42,927:WARNING: 	 image_resolution: 224
2024-05-19 06:36:42,927:WARNING: 	 vision_layers: 12
2024-05-19 06:36:42,928:WARNING: 	 vision_width: 768
2024-05-19 06:36:42,928:WARNING: 	 vision_patch_size: 32
2024-05-19 06:36:42,928:WARNING: 	 context_length: 77
2024-05-19 06:36:42,928:WARNING: 	 vocab_size: 49408
2024-05-19 06:36:42,928:WARNING: 	 transformer_width: 512
2024-05-19 06:36:42,928:WARNING: 	 transformer_heads: 8
2024-05-19 06:36:42,928:WARNING: 	 transformer_layers: 12
2024-05-19 06:36:42,928:WARNING: 	 cut_top_layer: 0
2024-05-19 06:36:43,804:WARNING: 	 sim_type: seqTransf
2024-05-19 06:36:47,606:INFO: --------------------
2024-05-19 06:36:47,606:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-19 06:43:56,800:INFO: device: cuda:0 n_gpu: 1
2024-05-19 06:43:56,801:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-19 06:43:57,039:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-19 06:43:57,040:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-19 06:43:57,040:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-19 06:43:57,041:WARNING: 	 embed_dim: 512
2024-05-19 06:43:57,041:WARNING: 	 image_resolution: 224
2024-05-19 06:43:57,041:WARNING: 	 vision_layers: 12
2024-05-19 06:43:57,041:WARNING: 	 vision_width: 768
2024-05-19 06:43:57,041:WARNING: 	 vision_patch_size: 32
2024-05-19 06:43:57,041:WARNING: 	 context_length: 77
2024-05-19 06:43:57,041:WARNING: 	 vocab_size: 49408
2024-05-19 06:43:57,041:WARNING: 	 transformer_width: 512
2024-05-19 06:43:57,041:WARNING: 	 transformer_heads: 8
2024-05-19 06:43:57,041:WARNING: 	 transformer_layers: 12
2024-05-19 06:43:57,042:WARNING: 	 cut_top_layer: 0
2024-05-19 06:43:57,922:WARNING: 	 sim_type: seqTransf
2024-05-19 06:44:01,701:INFO: --------------------
2024-05-19 06:44:01,701:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-19 06:51:09,092:INFO: device: cuda:0 n_gpu: 1
2024-05-19 06:51:09,092:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-19 06:51:09,323:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-19 06:51:09,324:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-19 06:51:09,324:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-19 06:51:09,325:WARNING: 	 embed_dim: 512
2024-05-19 06:51:09,325:WARNING: 	 image_resolution: 224
2024-05-19 06:51:09,325:WARNING: 	 vision_layers: 12
2024-05-19 06:51:09,325:WARNING: 	 vision_width: 768
2024-05-19 06:51:09,325:WARNING: 	 vision_patch_size: 32
2024-05-19 06:51:09,325:WARNING: 	 context_length: 77
2024-05-19 06:51:09,325:WARNING: 	 vocab_size: 49408
2024-05-19 06:51:09,325:WARNING: 	 transformer_width: 512
2024-05-19 06:51:09,325:WARNING: 	 transformer_heads: 8
2024-05-19 06:51:09,325:WARNING: 	 transformer_layers: 12
2024-05-19 06:51:09,325:WARNING: 	 cut_top_layer: 0
2024-05-19 06:51:10,205:WARNING: 	 sim_type: seqTransf
2024-05-19 06:51:14,063:INFO: --------------------
2024-05-19 06:51:14,063:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-19 06:54:09,044:INFO: device: cuda:0 n_gpu: 1
2024-05-19 06:54:09,044:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-19 06:54:09,276:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-19 06:54:09,278:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-19 06:54:09,278:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-19 06:54:09,278:WARNING: 	 embed_dim: 512
2024-05-19 06:54:09,279:WARNING: 	 image_resolution: 224
2024-05-19 06:54:09,279:WARNING: 	 vision_layers: 12
2024-05-19 06:54:09,279:WARNING: 	 vision_width: 768
2024-05-19 06:54:09,279:WARNING: 	 vision_patch_size: 32
2024-05-19 06:54:09,279:WARNING: 	 context_length: 77
2024-05-19 06:54:09,279:WARNING: 	 vocab_size: 49408
2024-05-19 06:54:09,279:WARNING: 	 transformer_width: 512
2024-05-19 06:54:09,279:WARNING: 	 transformer_heads: 8
2024-05-19 06:54:09,279:WARNING: 	 transformer_layers: 12
2024-05-19 06:54:09,279:WARNING: 	 cut_top_layer: 0
2024-05-19 06:54:10,170:WARNING: 	 sim_type: seqTransf
2024-05-19 06:54:13,983:INFO: --------------------
2024-05-19 06:54:13,984:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-19 06:55:40,331:INFO: device: cuda:0 n_gpu: 1
2024-05-19 06:55:40,400:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-19 06:55:40,630:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-19 06:55:40,631:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-19 06:55:40,631:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-19 06:55:40,632:WARNING: 	 embed_dim: 512
2024-05-19 06:55:40,632:WARNING: 	 image_resolution: 224
2024-05-19 06:55:40,632:WARNING: 	 vision_layers: 12
2024-05-19 06:55:40,633:WARNING: 	 vision_width: 768
2024-05-19 06:55:40,633:WARNING: 	 vision_patch_size: 32
2024-05-19 06:55:40,633:WARNING: 	 context_length: 77
2024-05-19 06:55:40,633:WARNING: 	 vocab_size: 49408
2024-05-19 06:55:40,633:WARNING: 	 transformer_width: 512
2024-05-19 06:55:40,633:WARNING: 	 transformer_heads: 8
2024-05-19 06:55:40,633:WARNING: 	 transformer_layers: 12
2024-05-19 06:55:40,633:WARNING: 	 cut_top_layer: 0
2024-05-19 06:55:41,506:WARNING: 	 sim_type: seqTransf
2024-05-19 06:55:45,292:INFO: --------------------
2024-05-19 06:55:45,293:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-19 06:55:47,388:INFO: ***** Running test *****
2024-05-19 06:55:47,388:INFO:   Num examples = 1
2024-05-19 06:55:47,388:INFO:   Batch size = 64
2024-05-19 06:55:47,389:INFO:   Num steps = 1
2024-05-19 10:29:28,156:INFO: device: cuda:0 n_gpu: 1
2024-05-19 10:29:28,156:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-19 10:29:29,076:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-19 10:29:29,077:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-19 10:29:29,077:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-19 10:29:29,078:WARNING: 	 embed_dim: 512
2024-05-19 10:29:29,078:WARNING: 	 image_resolution: 224
2024-05-19 10:29:29,079:WARNING: 	 vision_layers: 12
2024-05-19 10:29:29,079:WARNING: 	 vision_width: 768
2024-05-19 10:29:29,079:WARNING: 	 vision_patch_size: 32
2024-05-19 10:29:29,079:WARNING: 	 context_length: 77
2024-05-19 10:29:29,079:WARNING: 	 vocab_size: 49408
2024-05-19 10:29:29,079:WARNING: 	 transformer_width: 512
2024-05-19 10:29:29,079:WARNING: 	 transformer_heads: 8
2024-05-19 10:29:29,079:WARNING: 	 transformer_layers: 12
2024-05-19 10:29:29,079:WARNING: 	 cut_top_layer: 0
2024-05-19 10:29:29,970:WARNING: 	 sim_type: seqTransf
2024-05-19 10:29:33,799:INFO: --------------------
2024-05-19 10:29:33,799:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-19 10:30:49,422:INFO: device: cuda:0 n_gpu: 1
2024-05-19 10:30:49,423:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-19 10:30:49,660:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-19 10:30:49,662:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-19 10:30:49,662:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-19 10:30:49,663:WARNING: 	 embed_dim: 512
2024-05-19 10:30:49,663:WARNING: 	 image_resolution: 224
2024-05-19 10:30:49,663:WARNING: 	 vision_layers: 12
2024-05-19 10:30:49,663:WARNING: 	 vision_width: 768
2024-05-19 10:30:49,663:WARNING: 	 vision_patch_size: 32
2024-05-19 10:30:49,663:WARNING: 	 context_length: 77
2024-05-19 10:30:49,663:WARNING: 	 vocab_size: 49408
2024-05-19 10:30:49,663:WARNING: 	 transformer_width: 512
2024-05-19 10:30:49,663:WARNING: 	 transformer_heads: 8
2024-05-19 10:30:49,663:WARNING: 	 transformer_layers: 12
2024-05-19 10:30:49,663:WARNING: 	 cut_top_layer: 0
2024-05-19 10:30:50,539:WARNING: 	 sim_type: seqTransf
2024-05-19 10:30:54,341:INFO: --------------------
2024-05-19 10:30:54,342:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-19 10:50:55,593:INFO: device: cuda:0 n_gpu: 1
2024-05-19 10:50:55,661:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-19 10:50:55,886:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-19 10:50:55,887:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-19 10:50:55,887:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-19 10:50:55,888:WARNING: 	 embed_dim: 512
2024-05-19 10:50:55,888:WARNING: 	 image_resolution: 224
2024-05-19 10:50:55,888:WARNING: 	 vision_layers: 12
2024-05-19 10:50:55,888:WARNING: 	 vision_width: 768
2024-05-19 10:50:55,888:WARNING: 	 vision_patch_size: 32
2024-05-19 10:50:55,888:WARNING: 	 context_length: 77
2024-05-19 10:50:55,888:WARNING: 	 vocab_size: 49408
2024-05-19 10:50:55,888:WARNING: 	 transformer_width: 512
2024-05-19 10:50:55,888:WARNING: 	 transformer_heads: 8
2024-05-19 10:50:55,888:WARNING: 	 transformer_layers: 12
2024-05-19 10:50:55,888:WARNING: 	 cut_top_layer: 0
2024-05-19 10:50:56,734:WARNING: 	 sim_type: seqTransf
2024-05-19 10:51:00,512:INFO: --------------------
2024-05-19 10:51:00,512:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-19 10:51:02,597:INFO: ***** Running test *****
2024-05-19 10:51:02,597:INFO:   Num examples = 1
2024-05-19 10:51:02,598:INFO:   Batch size = 64
2024-05-19 10:51:02,598:INFO:   Num steps = 1
2024-05-19 10:52:26,562:INFO: device: cuda:0 n_gpu: 1
2024-05-19 10:52:26,634:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-19 10:52:26,869:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-19 10:52:26,870:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-19 10:52:26,870:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-19 10:52:26,871:WARNING: 	 embed_dim: 512
2024-05-19 10:52:26,871:WARNING: 	 image_resolution: 224
2024-05-19 10:52:26,871:WARNING: 	 vision_layers: 12
2024-05-19 10:52:26,871:WARNING: 	 vision_width: 768
2024-05-19 10:52:26,871:WARNING: 	 vision_patch_size: 32
2024-05-19 10:52:26,871:WARNING: 	 context_length: 77
2024-05-19 10:52:26,871:WARNING: 	 vocab_size: 49408
2024-05-19 10:52:26,872:WARNING: 	 transformer_width: 512
2024-05-19 10:52:26,872:WARNING: 	 transformer_heads: 8
2024-05-19 10:52:26,872:WARNING: 	 transformer_layers: 12
2024-05-19 10:52:26,872:WARNING: 	 cut_top_layer: 0
2024-05-19 10:52:27,731:WARNING: 	 sim_type: seqTransf
2024-05-19 10:52:31,515:INFO: --------------------
2024-05-19 10:52:31,515:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-19 10:52:33,595:INFO: ***** Running test *****
2024-05-19 10:52:33,595:INFO:   Num examples = 1
2024-05-19 10:52:33,595:INFO:   Batch size = 64
2024-05-19 10:52:33,595:INFO:   Num steps = 1
2024-05-19 10:52:59,142:INFO: device: cuda:0 n_gpu: 1
2024-05-19 10:52:59,211:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-19 10:52:59,438:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-19 10:52:59,439:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-19 10:52:59,440:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-19 10:52:59,440:WARNING: 	 embed_dim: 512
2024-05-19 10:52:59,441:WARNING: 	 image_resolution: 224
2024-05-19 10:52:59,441:WARNING: 	 vision_layers: 12
2024-05-19 10:52:59,441:WARNING: 	 vision_width: 768
2024-05-19 10:52:59,441:WARNING: 	 vision_patch_size: 32
2024-05-19 10:52:59,441:WARNING: 	 context_length: 77
2024-05-19 10:52:59,441:WARNING: 	 vocab_size: 49408
2024-05-19 10:52:59,441:WARNING: 	 transformer_width: 512
2024-05-19 10:52:59,441:WARNING: 	 transformer_heads: 8
2024-05-19 10:52:59,441:WARNING: 	 transformer_layers: 12
2024-05-19 10:52:59,441:WARNING: 	 cut_top_layer: 0
2024-05-19 10:53:00,303:WARNING: 	 sim_type: seqTransf
2024-05-19 10:53:04,088:INFO: --------------------
2024-05-19 10:53:04,088:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-19 10:53:06,178:INFO: ***** Running test *****
2024-05-19 10:53:06,178:INFO:   Num examples = 1
2024-05-19 10:53:06,178:INFO:   Batch size = 64
2024-05-19 10:53:06,178:INFO:   Num steps = 1
2024-05-19 10:54:15,414:INFO: device: cuda:0 n_gpu: 1
2024-05-19 10:54:15,483:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-19 10:54:15,732:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-19 10:54:15,733:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-19 10:54:15,733:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-19 10:54:15,734:WARNING: 	 embed_dim: 512
2024-05-19 10:54:15,734:WARNING: 	 image_resolution: 224
2024-05-19 10:54:15,734:WARNING: 	 vision_layers: 12
2024-05-19 10:54:15,734:WARNING: 	 vision_width: 768
2024-05-19 10:54:15,734:WARNING: 	 vision_patch_size: 32
2024-05-19 10:54:15,734:WARNING: 	 context_length: 77
2024-05-19 10:54:15,734:WARNING: 	 vocab_size: 49408
2024-05-19 10:54:15,734:WARNING: 	 transformer_width: 512
2024-05-19 10:54:15,735:WARNING: 	 transformer_heads: 8
2024-05-19 10:54:15,735:WARNING: 	 transformer_layers: 12
2024-05-19 10:54:15,735:WARNING: 	 cut_top_layer: 0
2024-05-19 10:54:16,597:WARNING: 	 sim_type: seqTransf
2024-05-19 10:54:20,419:INFO: --------------------
2024-05-19 10:54:20,419:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-19 10:54:22,541:INFO: ***** Running test *****
2024-05-19 10:54:22,541:INFO:   Num examples = 1
2024-05-19 10:54:22,541:INFO:   Batch size = 64
2024-05-19 10:54:22,541:INFO:   Num steps = 1
2024-05-20 05:51:26,797:INFO: device: cuda:0 n_gpu: 1
2024-05-20 05:51:26,864:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-20 05:51:27,151:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-20 05:51:27,152:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-20 05:51:27,152:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-20 05:51:27,153:WARNING: 	 embed_dim: 512
2024-05-20 05:51:27,153:WARNING: 	 image_resolution: 224
2024-05-20 05:51:27,153:WARNING: 	 vision_layers: 12
2024-05-20 05:51:27,153:WARNING: 	 vision_width: 768
2024-05-20 05:51:27,153:WARNING: 	 vision_patch_size: 32
2024-05-20 05:51:27,153:WARNING: 	 context_length: 77
2024-05-20 05:51:27,153:WARNING: 	 vocab_size: 49408
2024-05-20 05:51:27,153:WARNING: 	 transformer_width: 512
2024-05-20 05:51:27,153:WARNING: 	 transformer_heads: 8
2024-05-20 05:51:27,153:WARNING: 	 transformer_layers: 12
2024-05-20 05:51:27,153:WARNING: 	 cut_top_layer: 0
2024-05-20 05:51:28,166:WARNING: 	 sim_type: seqTransf
2024-05-20 05:51:32,662:INFO: --------------------
2024-05-20 05:51:32,662:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-20 05:51:34,893:INFO: ***** Running test *****
2024-05-20 05:51:34,893:INFO:   Num examples = 1
2024-05-20 05:51:34,893:INFO:   Batch size = 64
2024-05-20 05:51:34,893:INFO:   Num steps = 1
2024-05-20 05:52:00,449:INFO: sim matrix size: 1, 1
2024-05-20 05:52:00,450:INFO: 	 Length-T: 1, Length-V:1
2024-05-20 05:52:00,450:INFO: Text-to-Video:
2024-05-20 05:52:00,450:INFO: 	>>>  R@1: 100.0 - R@5: 100.0 - R@10: 100.0 - Median R: 1.0 - Mean R: 1.0
2024-05-20 05:52:00,450:INFO: Video-to-Text:
2024-05-20 05:52:00,451:INFO: 	>>>  V2T$R@1: 100.0 - V2T$R@5: 100.0 - V2T$R@10: 100.0 - V2T$Median R: 1.0 - V2T$Mean R: 1.0
2024-05-20 05:52:46,219:INFO: device: cuda:0 n_gpu: 1
2024-05-20 05:52:46,287:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-20 05:52:46,534:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-20 05:52:46,535:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-20 05:52:46,535:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-20 05:52:46,536:WARNING: 	 embed_dim: 512
2024-05-20 05:52:46,536:WARNING: 	 image_resolution: 224
2024-05-20 05:52:46,536:WARNING: 	 vision_layers: 12
2024-05-20 05:52:46,536:WARNING: 	 vision_width: 768
2024-05-20 05:52:46,536:WARNING: 	 vision_patch_size: 32
2024-05-20 05:52:46,536:WARNING: 	 context_length: 77
2024-05-20 05:52:46,536:WARNING: 	 vocab_size: 49408
2024-05-20 05:52:46,536:WARNING: 	 transformer_width: 512
2024-05-20 05:52:46,536:WARNING: 	 transformer_heads: 8
2024-05-20 05:52:46,536:WARNING: 	 transformer_layers: 12
2024-05-20 05:52:46,536:WARNING: 	 cut_top_layer: 0
2024-05-20 05:52:47,510:WARNING: 	 sim_type: seqTransf
2024-05-20 05:52:51,987:INFO: --------------------
2024-05-20 05:52:51,987:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-20 05:52:53,728:INFO: ***** Running test *****
2024-05-20 05:52:53,728:INFO:   Num examples = 1
2024-05-20 05:52:53,728:INFO:   Batch size = 64
2024-05-20 05:52:53,728:INFO:   Num steps = 1
2024-05-20 05:57:37,063:INFO: device: cuda:0 n_gpu: 1
2024-05-20 05:57:37,133:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-20 05:57:37,370:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-20 05:57:37,371:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-20 05:57:37,371:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-20 05:57:37,372:WARNING: 	 embed_dim: 512
2024-05-20 05:57:37,372:WARNING: 	 image_resolution: 224
2024-05-20 05:57:37,372:WARNING: 	 vision_layers: 12
2024-05-20 05:57:37,372:WARNING: 	 vision_width: 768
2024-05-20 05:57:37,372:WARNING: 	 vision_patch_size: 32
2024-05-20 05:57:37,373:WARNING: 	 context_length: 77
2024-05-20 05:57:37,373:WARNING: 	 vocab_size: 49408
2024-05-20 05:57:37,373:WARNING: 	 transformer_width: 512
2024-05-20 05:57:37,373:WARNING: 	 transformer_heads: 8
2024-05-20 05:57:37,373:WARNING: 	 transformer_layers: 12
2024-05-20 05:57:37,373:WARNING: 	 cut_top_layer: 0
2024-05-20 05:57:38,366:WARNING: 	 sim_type: seqTransf
2024-05-20 05:57:42,855:INFO: --------------------
2024-05-20 05:57:42,856:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-20 05:57:44,630:INFO: ***** Running test *****
2024-05-20 05:57:44,630:INFO:   Num examples = 1
2024-05-20 05:57:44,630:INFO:   Batch size = 64
2024-05-20 05:57:44,630:INFO:   Num steps = 1
2024-05-20 06:26:08,346:INFO: device: cuda:0 n_gpu: 1
2024-05-20 06:26:08,346:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-20 06:26:08,570:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-20 06:26:08,570:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-20 06:26:08,570:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-20 06:26:08,570:WARNING: 	 embed_dim: 512
2024-05-20 06:26:08,570:WARNING: 	 image_resolution: 224
2024-05-20 06:26:08,570:WARNING: 	 vision_layers: 12
2024-05-20 06:26:08,570:WARNING: 	 vision_width: 768
2024-05-20 06:26:08,570:WARNING: 	 vision_patch_size: 32
2024-05-20 06:26:08,570:WARNING: 	 context_length: 77
2024-05-20 06:26:08,570:WARNING: 	 vocab_size: 49408
2024-05-20 06:26:08,570:WARNING: 	 transformer_width: 512
2024-05-20 06:26:08,570:WARNING: 	 transformer_heads: 8
2024-05-20 06:26:08,570:WARNING: 	 transformer_layers: 12
2024-05-20 06:26:08,570:WARNING: 	 cut_top_layer: 0
2024-05-20 06:26:09,538:WARNING: 	 sim_type: seqTransf
2024-05-20 06:26:14,011:INFO: --------------------
2024-05-20 06:26:14,011:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-20 06:29:27,030:INFO: device: cuda:0 n_gpu: 1
2024-05-20 06:29:27,030:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-20 06:29:27,254:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-20 06:29:27,254:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-20 06:29:27,255:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-20 06:29:27,255:WARNING: 	 embed_dim: 512
2024-05-20 06:29:27,255:WARNING: 	 image_resolution: 224
2024-05-20 06:29:27,255:WARNING: 	 vision_layers: 12
2024-05-20 06:29:27,255:WARNING: 	 vision_width: 768
2024-05-20 06:29:27,255:WARNING: 	 vision_patch_size: 32
2024-05-20 06:29:27,255:WARNING: 	 context_length: 77
2024-05-20 06:29:27,255:WARNING: 	 vocab_size: 49408
2024-05-20 06:29:27,255:WARNING: 	 transformer_width: 512
2024-05-20 06:29:27,255:WARNING: 	 transformer_heads: 8
2024-05-20 06:29:27,255:WARNING: 	 transformer_layers: 12
2024-05-20 06:29:27,255:WARNING: 	 cut_top_layer: 0
2024-05-20 06:29:28,228:WARNING: 	 sim_type: seqTransf
2024-05-20 06:29:32,709:INFO: --------------------
2024-05-20 06:29:32,709:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-20 06:31:46,711:INFO: device: cuda:0 n_gpu: 1
2024-05-20 06:31:46,711:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-20 06:31:46,944:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-20 06:31:46,946:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-20 06:31:46,946:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-20 06:31:46,947:WARNING: 	 embed_dim: 512
2024-05-20 06:31:46,947:WARNING: 	 image_resolution: 224
2024-05-20 06:31:46,947:WARNING: 	 vision_layers: 12
2024-05-20 06:31:46,947:WARNING: 	 vision_width: 768
2024-05-20 06:31:46,947:WARNING: 	 vision_patch_size: 32
2024-05-20 06:31:46,947:WARNING: 	 context_length: 77
2024-05-20 06:31:46,947:WARNING: 	 vocab_size: 49408
2024-05-20 06:31:46,947:WARNING: 	 transformer_width: 512
2024-05-20 06:31:46,947:WARNING: 	 transformer_heads: 8
2024-05-20 06:31:46,947:WARNING: 	 transformer_layers: 12
2024-05-20 06:31:46,947:WARNING: 	 cut_top_layer: 0
2024-05-20 06:31:47,932:WARNING: 	 sim_type: seqTransf
2024-05-20 06:31:52,420:INFO: --------------------
2024-05-20 06:31:52,420:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-20 06:32:45,612:INFO: device: cuda:0 n_gpu: 1
2024-05-20 06:32:45,612:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-20 06:32:45,840:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-20 06:32:45,841:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-20 06:32:45,841:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-20 06:32:45,841:WARNING: 	 embed_dim: 512
2024-05-20 06:32:45,841:WARNING: 	 image_resolution: 224
2024-05-20 06:32:45,841:WARNING: 	 vision_layers: 12
2024-05-20 06:32:45,841:WARNING: 	 vision_width: 768
2024-05-20 06:32:45,841:WARNING: 	 vision_patch_size: 32
2024-05-20 06:32:45,841:WARNING: 	 context_length: 77
2024-05-20 06:32:45,841:WARNING: 	 vocab_size: 49408
2024-05-20 06:32:45,841:WARNING: 	 transformer_width: 512
2024-05-20 06:32:45,841:WARNING: 	 transformer_heads: 8
2024-05-20 06:32:45,841:WARNING: 	 transformer_layers: 12
2024-05-20 06:32:45,841:WARNING: 	 cut_top_layer: 0
2024-05-20 06:32:46,819:WARNING: 	 sim_type: seqTransf
2024-05-20 06:32:51,309:INFO: --------------------
2024-05-20 06:32:51,309:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-20 06:33:59,032:INFO: device: cuda:0 n_gpu: 1
2024-05-20 06:33:59,032:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-20 06:33:59,257:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-20 06:33:59,257:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-20 06:33:59,257:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-20 06:33:59,258:WARNING: 	 embed_dim: 512
2024-05-20 06:33:59,258:WARNING: 	 image_resolution: 224
2024-05-20 06:33:59,258:WARNING: 	 vision_layers: 12
2024-05-20 06:33:59,258:WARNING: 	 vision_width: 768
2024-05-20 06:33:59,258:WARNING: 	 vision_patch_size: 32
2024-05-20 06:33:59,258:WARNING: 	 context_length: 77
2024-05-20 06:33:59,258:WARNING: 	 vocab_size: 49408
2024-05-20 06:33:59,258:WARNING: 	 transformer_width: 512
2024-05-20 06:33:59,258:WARNING: 	 transformer_heads: 8
2024-05-20 06:33:59,258:WARNING: 	 transformer_layers: 12
2024-05-20 06:33:59,258:WARNING: 	 cut_top_layer: 0
2024-05-20 06:34:00,237:WARNING: 	 sim_type: seqTransf
2024-05-20 06:34:04,732:INFO: --------------------
2024-05-20 06:34:04,733:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-20 06:34:40,152:INFO: device: cuda:0 n_gpu: 1
2024-05-20 06:34:40,152:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-20 06:34:40,385:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-20 06:34:40,386:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-20 06:34:40,386:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-20 06:34:40,387:WARNING: 	 embed_dim: 512
2024-05-20 06:34:40,387:WARNING: 	 image_resolution: 224
2024-05-20 06:34:40,387:WARNING: 	 vision_layers: 12
2024-05-20 06:34:40,387:WARNING: 	 vision_width: 768
2024-05-20 06:34:40,387:WARNING: 	 vision_patch_size: 32
2024-05-20 06:34:40,388:WARNING: 	 context_length: 77
2024-05-20 06:34:40,388:WARNING: 	 vocab_size: 49408
2024-05-20 06:34:40,388:WARNING: 	 transformer_width: 512
2024-05-20 06:34:40,388:WARNING: 	 transformer_heads: 8
2024-05-20 06:34:40,388:WARNING: 	 transformer_layers: 12
2024-05-20 06:34:40,388:WARNING: 	 cut_top_layer: 0
2024-05-20 06:34:41,388:WARNING: 	 sim_type: seqTransf
2024-05-20 06:34:45,888:INFO: --------------------
2024-05-20 06:34:45,889:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-20 06:35:26,543:INFO: device: cuda:0 n_gpu: 1
2024-05-20 06:35:26,543:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-20 06:35:26,777:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-20 06:35:26,778:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-20 06:35:26,778:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-20 06:35:26,779:WARNING: 	 embed_dim: 512
2024-05-20 06:35:26,779:WARNING: 	 image_resolution: 224
2024-05-20 06:35:26,779:WARNING: 	 vision_layers: 12
2024-05-20 06:35:26,779:WARNING: 	 vision_width: 768
2024-05-20 06:35:26,779:WARNING: 	 vision_patch_size: 32
2024-05-20 06:35:26,779:WARNING: 	 context_length: 77
2024-05-20 06:35:26,779:WARNING: 	 vocab_size: 49408
2024-05-20 06:35:26,779:WARNING: 	 transformer_width: 512
2024-05-20 06:35:26,779:WARNING: 	 transformer_heads: 8
2024-05-20 06:35:26,779:WARNING: 	 transformer_layers: 12
2024-05-20 06:35:26,779:WARNING: 	 cut_top_layer: 0
2024-05-20 06:35:27,768:WARNING: 	 sim_type: seqTransf
2024-05-20 06:35:32,254:INFO: --------------------
2024-05-20 06:35:32,254:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-20 06:56:55,119:INFO: device: cuda:0 n_gpu: 1
2024-05-20 06:56:55,120:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-20 06:56:55,346:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-20 06:56:55,346:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-20 06:56:55,346:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-20 06:56:55,347:WARNING: 	 embed_dim: 512
2024-05-20 06:56:55,347:WARNING: 	 image_resolution: 224
2024-05-20 06:56:55,347:WARNING: 	 vision_layers: 12
2024-05-20 06:56:55,347:WARNING: 	 vision_width: 768
2024-05-20 06:56:55,347:WARNING: 	 vision_patch_size: 32
2024-05-20 06:56:55,347:WARNING: 	 context_length: 77
2024-05-20 06:56:55,347:WARNING: 	 vocab_size: 49408
2024-05-20 06:56:55,347:WARNING: 	 transformer_width: 512
2024-05-20 06:56:55,347:WARNING: 	 transformer_heads: 8
2024-05-20 06:56:55,347:WARNING: 	 transformer_layers: 12
2024-05-20 06:56:55,347:WARNING: 	 cut_top_layer: 0
2024-05-20 06:56:56,315:WARNING: 	 sim_type: seqTransf
2024-05-20 06:57:00,800:INFO: --------------------
2024-05-20 06:57:00,800:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-20 07:23:18,561:INFO: device: cuda:0 n_gpu: 1
2024-05-20 07:23:18,561:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-20 07:23:18,794:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-20 07:23:18,795:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-20 07:23:18,795:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-20 07:23:18,796:WARNING: 	 embed_dim: 512
2024-05-20 07:23:18,796:WARNING: 	 image_resolution: 224
2024-05-20 07:23:18,796:WARNING: 	 vision_layers: 12
2024-05-20 07:23:18,796:WARNING: 	 vision_width: 768
2024-05-20 07:23:18,796:WARNING: 	 vision_patch_size: 32
2024-05-20 07:23:18,796:WARNING: 	 context_length: 77
2024-05-20 07:23:18,796:WARNING: 	 vocab_size: 49408
2024-05-20 07:23:18,796:WARNING: 	 transformer_width: 512
2024-05-20 07:23:18,796:WARNING: 	 transformer_heads: 8
2024-05-20 07:23:18,796:WARNING: 	 transformer_layers: 12
2024-05-20 07:23:18,796:WARNING: 	 cut_top_layer: 0
2024-05-20 07:23:19,792:WARNING: 	 sim_type: seqTransf
2024-05-20 07:23:24,287:INFO: --------------------
2024-05-20 07:23:24,287:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-20 07:24:50,226:INFO: device: cuda:0 n_gpu: 1
2024-05-20 07:24:50,226:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-20 07:24:50,460:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-20 07:24:50,461:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-20 07:24:50,461:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-20 07:24:50,462:WARNING: 	 embed_dim: 512
2024-05-20 07:24:50,462:WARNING: 	 image_resolution: 224
2024-05-20 07:24:50,462:WARNING: 	 vision_layers: 12
2024-05-20 07:24:50,462:WARNING: 	 vision_width: 768
2024-05-20 07:24:50,462:WARNING: 	 vision_patch_size: 32
2024-05-20 07:24:50,462:WARNING: 	 context_length: 77
2024-05-20 07:24:50,462:WARNING: 	 vocab_size: 49408
2024-05-20 07:24:50,462:WARNING: 	 transformer_width: 512
2024-05-20 07:24:50,462:WARNING: 	 transformer_heads: 8
2024-05-20 07:24:50,463:WARNING: 	 transformer_layers: 12
2024-05-20 07:24:50,463:WARNING: 	 cut_top_layer: 0
2024-05-20 07:24:51,464:WARNING: 	 sim_type: seqTransf
2024-05-20 07:24:55,974:INFO: --------------------
2024-05-20 07:24:55,975:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-20 07:25:55,221:INFO: device: cuda:0 n_gpu: 1
2024-05-20 07:25:55,222:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-20 07:25:55,455:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-20 07:25:55,456:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-20 07:25:55,456:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-20 07:25:55,457:WARNING: 	 embed_dim: 512
2024-05-20 07:25:55,457:WARNING: 	 image_resolution: 224
2024-05-20 07:25:55,457:WARNING: 	 vision_layers: 12
2024-05-20 07:25:55,457:WARNING: 	 vision_width: 768
2024-05-20 07:25:55,457:WARNING: 	 vision_patch_size: 32
2024-05-20 07:25:55,458:WARNING: 	 context_length: 77
2024-05-20 07:25:55,458:WARNING: 	 vocab_size: 49408
2024-05-20 07:25:55,458:WARNING: 	 transformer_width: 512
2024-05-20 07:25:55,458:WARNING: 	 transformer_heads: 8
2024-05-20 07:25:55,458:WARNING: 	 transformer_layers: 12
2024-05-20 07:25:55,458:WARNING: 	 cut_top_layer: 0
2024-05-20 07:25:56,451:WARNING: 	 sim_type: seqTransf
2024-05-20 07:26:00,950:INFO: --------------------
2024-05-20 07:26:00,950:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-20 07:33:59,545:INFO: device: cuda:0 n_gpu: 1
2024-05-20 07:33:59,546:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-20 07:33:59,779:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-20 07:33:59,780:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-20 07:33:59,781:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-20 07:33:59,781:WARNING: 	 embed_dim: 512
2024-05-20 07:33:59,781:WARNING: 	 image_resolution: 224
2024-05-20 07:33:59,781:WARNING: 	 vision_layers: 12
2024-05-20 07:33:59,782:WARNING: 	 vision_width: 768
2024-05-20 07:33:59,782:WARNING: 	 vision_patch_size: 32
2024-05-20 07:33:59,782:WARNING: 	 context_length: 77
2024-05-20 07:33:59,782:WARNING: 	 vocab_size: 49408
2024-05-20 07:33:59,782:WARNING: 	 transformer_width: 512
2024-05-20 07:33:59,782:WARNING: 	 transformer_heads: 8
2024-05-20 07:33:59,782:WARNING: 	 transformer_layers: 12
2024-05-20 07:33:59,782:WARNING: 	 cut_top_layer: 0
2024-05-20 07:34:00,780:WARNING: 	 sim_type: seqTransf
2024-05-20 07:34:05,280:INFO: --------------------
2024-05-20 07:34:05,280:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-20 07:53:04,268:INFO: device: cuda:0 n_gpu: 1
2024-05-20 07:53:04,268:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-20 07:53:04,502:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-20 07:53:04,504:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-20 07:53:04,504:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-20 07:53:04,505:WARNING: 	 embed_dim: 512
2024-05-20 07:53:04,505:WARNING: 	 image_resolution: 224
2024-05-20 07:53:04,505:WARNING: 	 vision_layers: 12
2024-05-20 07:53:04,505:WARNING: 	 vision_width: 768
2024-05-20 07:53:04,505:WARNING: 	 vision_patch_size: 32
2024-05-20 07:53:04,505:WARNING: 	 context_length: 77
2024-05-20 07:53:04,505:WARNING: 	 vocab_size: 49408
2024-05-20 07:53:04,505:WARNING: 	 transformer_width: 512
2024-05-20 07:53:04,505:WARNING: 	 transformer_heads: 8
2024-05-20 07:53:04,505:WARNING: 	 transformer_layers: 12
2024-05-20 07:53:04,505:WARNING: 	 cut_top_layer: 0
2024-05-20 07:53:05,520:WARNING: 	 sim_type: seqTransf
2024-05-20 07:53:10,005:INFO: --------------------
2024-05-20 07:53:10,005:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-20 07:53:43,855:INFO: device: cuda:0 n_gpu: 1
2024-05-20 07:53:43,855:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-20 07:53:44,092:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-20 07:53:44,093:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-20 07:53:44,093:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-20 07:53:44,094:WARNING: 	 embed_dim: 512
2024-05-20 07:53:44,094:WARNING: 	 image_resolution: 224
2024-05-20 07:53:44,094:WARNING: 	 vision_layers: 12
2024-05-20 07:53:44,094:WARNING: 	 vision_width: 768
2024-05-20 07:53:44,094:WARNING: 	 vision_patch_size: 32
2024-05-20 07:53:44,094:WARNING: 	 context_length: 77
2024-05-20 07:53:44,094:WARNING: 	 vocab_size: 49408
2024-05-20 07:53:44,094:WARNING: 	 transformer_width: 512
2024-05-20 07:53:44,094:WARNING: 	 transformer_heads: 8
2024-05-20 07:53:44,094:WARNING: 	 transformer_layers: 12
2024-05-20 07:53:44,094:WARNING: 	 cut_top_layer: 0
2024-05-20 07:53:45,096:WARNING: 	 sim_type: seqTransf
2024-05-20 07:53:49,599:INFO: --------------------
2024-05-20 07:53:49,600:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-20 07:54:05,709:INFO: device: cuda:0 n_gpu: 1
2024-05-20 07:54:05,709:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-20 07:54:05,947:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-20 07:54:05,948:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-20 07:54:05,948:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-20 07:54:05,949:WARNING: 	 embed_dim: 512
2024-05-20 07:54:05,949:WARNING: 	 image_resolution: 224
2024-05-20 07:54:05,949:WARNING: 	 vision_layers: 12
2024-05-20 07:54:05,950:WARNING: 	 vision_width: 768
2024-05-20 07:54:05,950:WARNING: 	 vision_patch_size: 32
2024-05-20 07:54:05,950:WARNING: 	 context_length: 77
2024-05-20 07:54:05,950:WARNING: 	 vocab_size: 49408
2024-05-20 07:54:05,950:WARNING: 	 transformer_width: 512
2024-05-20 07:54:05,950:WARNING: 	 transformer_heads: 8
2024-05-20 07:54:05,950:WARNING: 	 transformer_layers: 12
2024-05-20 07:54:05,950:WARNING: 	 cut_top_layer: 0
2024-05-20 07:54:06,938:WARNING: 	 sim_type: seqTransf
2024-05-20 07:54:11,432:INFO: --------------------
2024-05-20 07:54:11,432:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-20 07:54:51,055:INFO: device: cuda:0 n_gpu: 1
2024-05-20 07:54:51,055:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-20 07:54:51,293:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-20 07:54:51,294:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-20 07:54:51,294:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-20 07:54:51,295:WARNING: 	 embed_dim: 512
2024-05-20 07:54:51,295:WARNING: 	 image_resolution: 224
2024-05-20 07:54:51,295:WARNING: 	 vision_layers: 12
2024-05-20 07:54:51,295:WARNING: 	 vision_width: 768
2024-05-20 07:54:51,295:WARNING: 	 vision_patch_size: 32
2024-05-20 07:54:51,295:WARNING: 	 context_length: 77
2024-05-20 07:54:51,296:WARNING: 	 vocab_size: 49408
2024-05-20 07:54:51,296:WARNING: 	 transformer_width: 512
2024-05-20 07:54:51,296:WARNING: 	 transformer_heads: 8
2024-05-20 07:54:51,296:WARNING: 	 transformer_layers: 12
2024-05-20 07:54:51,296:WARNING: 	 cut_top_layer: 0
2024-05-20 07:54:52,296:WARNING: 	 sim_type: seqTransf
2024-05-20 07:54:56,793:INFO: --------------------
2024-05-20 07:54:56,794:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-20 07:55:52,986:INFO: device: cuda:0 n_gpu: 1
2024-05-20 07:55:52,987:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-20 07:55:53,226:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-20 07:55:53,227:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-20 07:55:53,227:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-20 07:55:53,228:WARNING: 	 embed_dim: 512
2024-05-20 07:55:53,228:WARNING: 	 image_resolution: 224
2024-05-20 07:55:53,228:WARNING: 	 vision_layers: 12
2024-05-20 07:55:53,228:WARNING: 	 vision_width: 768
2024-05-20 07:55:53,229:WARNING: 	 vision_patch_size: 32
2024-05-20 07:55:53,229:WARNING: 	 context_length: 77
2024-05-20 07:55:53,229:WARNING: 	 vocab_size: 49408
2024-05-20 07:55:53,229:WARNING: 	 transformer_width: 512
2024-05-20 07:55:53,229:WARNING: 	 transformer_heads: 8
2024-05-20 07:55:53,229:WARNING: 	 transformer_layers: 12
2024-05-20 07:55:53,229:WARNING: 	 cut_top_layer: 0
2024-05-20 07:55:54,220:WARNING: 	 sim_type: seqTransf
2024-05-20 07:55:58,713:INFO: --------------------
2024-05-20 07:55:58,713:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-20 07:57:24,727:INFO: device: cuda:0 n_gpu: 1
2024-05-20 07:57:24,727:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-20 07:57:24,961:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-20 07:57:24,962:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-20 07:57:24,962:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-20 07:57:24,963:WARNING: 	 embed_dim: 512
2024-05-20 07:57:24,963:WARNING: 	 image_resolution: 224
2024-05-20 07:57:24,963:WARNING: 	 vision_layers: 12
2024-05-20 07:57:24,963:WARNING: 	 vision_width: 768
2024-05-20 07:57:24,963:WARNING: 	 vision_patch_size: 32
2024-05-20 07:57:24,964:WARNING: 	 context_length: 77
2024-05-20 07:57:24,964:WARNING: 	 vocab_size: 49408
2024-05-20 07:57:24,964:WARNING: 	 transformer_width: 512
2024-05-20 07:57:24,964:WARNING: 	 transformer_heads: 8
2024-05-20 07:57:24,964:WARNING: 	 transformer_layers: 12
2024-05-20 07:57:24,964:WARNING: 	 cut_top_layer: 0
2024-05-20 07:57:25,957:WARNING: 	 sim_type: seqTransf
2024-05-20 07:57:30,439:INFO: --------------------
2024-05-20 07:57:30,439:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-20 08:02:12,558:INFO: device: cuda:0 n_gpu: 1
2024-05-20 08:02:12,626:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-20 08:02:12,861:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-20 08:02:12,862:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-20 08:02:12,862:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-20 08:02:12,863:WARNING: 	 embed_dim: 512
2024-05-20 08:02:12,863:WARNING: 	 image_resolution: 224
2024-05-20 08:02:12,863:WARNING: 	 vision_layers: 12
2024-05-20 08:02:12,863:WARNING: 	 vision_width: 768
2024-05-20 08:02:12,863:WARNING: 	 vision_patch_size: 32
2024-05-20 08:02:12,863:WARNING: 	 context_length: 77
2024-05-20 08:02:12,863:WARNING: 	 vocab_size: 49408
2024-05-20 08:02:12,863:WARNING: 	 transformer_width: 512
2024-05-20 08:02:12,863:WARNING: 	 transformer_heads: 8
2024-05-20 08:02:12,863:WARNING: 	 transformer_layers: 12
2024-05-20 08:02:12,864:WARNING: 	 cut_top_layer: 0
2024-05-20 08:02:13,859:WARNING: 	 sim_type: seqTransf
2024-05-20 08:02:18,363:INFO: --------------------
2024-05-20 08:02:18,363:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-20 08:02:20,138:INFO: ***** Running test *****
2024-05-20 08:02:20,138:INFO:   Num examples = 2
2024-05-20 08:02:20,138:INFO:   Batch size = 64
2024-05-20 08:02:20,139:INFO:   Num steps = 1
2024-05-20 08:09:15,431:INFO: device: cuda:0 n_gpu: 1
2024-05-20 08:09:15,498:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-20 08:09:15,734:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-20 08:09:15,735:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-20 08:09:15,735:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-20 08:09:15,736:WARNING: 	 embed_dim: 512
2024-05-20 08:09:15,736:WARNING: 	 image_resolution: 224
2024-05-20 08:09:15,736:WARNING: 	 vision_layers: 12
2024-05-20 08:09:15,736:WARNING: 	 vision_width: 768
2024-05-20 08:09:15,736:WARNING: 	 vision_patch_size: 32
2024-05-20 08:09:15,736:WARNING: 	 context_length: 77
2024-05-20 08:09:15,736:WARNING: 	 vocab_size: 49408
2024-05-20 08:09:15,736:WARNING: 	 transformer_width: 512
2024-05-20 08:09:15,736:WARNING: 	 transformer_heads: 8
2024-05-20 08:09:15,736:WARNING: 	 transformer_layers: 12
2024-05-20 08:09:15,736:WARNING: 	 cut_top_layer: 0
2024-05-20 08:09:16,715:WARNING: 	 sim_type: seqTransf
2024-05-20 08:09:21,202:INFO: --------------------
2024-05-20 08:09:21,203:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-20 08:09:22,945:INFO: ***** Running test *****
2024-05-20 08:09:22,946:INFO:   Num examples = 2
2024-05-20 08:09:22,946:INFO:   Batch size = 64
2024-05-20 08:09:22,946:INFO:   Num steps = 1
2024-05-20 08:13:45,084:INFO: device: cuda:0 n_gpu: 1
2024-05-20 08:13:45,084:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-20 08:13:45,319:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-20 08:13:45,320:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-20 08:13:45,320:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-20 08:13:45,321:WARNING: 	 embed_dim: 512
2024-05-20 08:13:45,321:WARNING: 	 image_resolution: 224
2024-05-20 08:13:45,321:WARNING: 	 vision_layers: 12
2024-05-20 08:13:45,322:WARNING: 	 vision_width: 768
2024-05-20 08:13:45,322:WARNING: 	 vision_patch_size: 32
2024-05-20 08:13:45,322:WARNING: 	 context_length: 77
2024-05-20 08:13:45,322:WARNING: 	 vocab_size: 49408
2024-05-20 08:13:45,322:WARNING: 	 transformer_width: 512
2024-05-20 08:13:45,322:WARNING: 	 transformer_heads: 8
2024-05-20 08:13:45,322:WARNING: 	 transformer_layers: 12
2024-05-20 08:13:45,322:WARNING: 	 cut_top_layer: 0
2024-05-20 08:13:46,305:WARNING: 	 sim_type: seqTransf
2024-05-20 08:13:50,811:INFO: --------------------
2024-05-20 08:13:50,811:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-20 08:14:09,666:INFO: device: cuda:0 n_gpu: 1
2024-05-20 08:14:09,667:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-20 08:14:09,898:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-20 08:14:09,899:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-20 08:14:09,899:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-20 08:14:09,900:WARNING: 	 embed_dim: 512
2024-05-20 08:14:09,900:WARNING: 	 image_resolution: 224
2024-05-20 08:14:09,900:WARNING: 	 vision_layers: 12
2024-05-20 08:14:09,900:WARNING: 	 vision_width: 768
2024-05-20 08:14:09,900:WARNING: 	 vision_patch_size: 32
2024-05-20 08:14:09,900:WARNING: 	 context_length: 77
2024-05-20 08:14:09,900:WARNING: 	 vocab_size: 49408
2024-05-20 08:14:09,900:WARNING: 	 transformer_width: 512
2024-05-20 08:14:09,901:WARNING: 	 transformer_heads: 8
2024-05-20 08:14:09,901:WARNING: 	 transformer_layers: 12
2024-05-20 08:14:09,901:WARNING: 	 cut_top_layer: 0
2024-05-20 08:14:10,889:WARNING: 	 sim_type: seqTransf
2024-05-20 08:14:15,382:INFO: --------------------
2024-05-20 08:14:15,382:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-20 08:15:31,269:INFO: device: cuda:0 n_gpu: 1
2024-05-20 08:15:31,270:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-20 08:15:31,504:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-20 08:15:31,506:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-20 08:15:31,506:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-20 08:15:31,506:WARNING: 	 embed_dim: 512
2024-05-20 08:15:31,507:WARNING: 	 image_resolution: 224
2024-05-20 08:15:31,507:WARNING: 	 vision_layers: 12
2024-05-20 08:15:31,507:WARNING: 	 vision_width: 768
2024-05-20 08:15:31,507:WARNING: 	 vision_patch_size: 32
2024-05-20 08:15:31,507:WARNING: 	 context_length: 77
2024-05-20 08:15:31,507:WARNING: 	 vocab_size: 49408
2024-05-20 08:15:31,507:WARNING: 	 transformer_width: 512
2024-05-20 08:15:31,507:WARNING: 	 transformer_heads: 8
2024-05-20 08:15:31,507:WARNING: 	 transformer_layers: 12
2024-05-20 08:15:31,507:WARNING: 	 cut_top_layer: 0
2024-05-20 08:15:32,499:WARNING: 	 sim_type: seqTransf
2024-05-20 08:15:36,998:INFO: --------------------
2024-05-20 08:15:36,998:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-20 08:16:48,967:INFO: device: cuda:0 n_gpu: 1
2024-05-20 08:16:48,967:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-20 08:16:49,199:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-20 08:16:49,201:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-20 08:16:49,201:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-20 08:16:49,201:WARNING: 	 embed_dim: 512
2024-05-20 08:16:49,202:WARNING: 	 image_resolution: 224
2024-05-20 08:16:49,202:WARNING: 	 vision_layers: 12
2024-05-20 08:16:49,202:WARNING: 	 vision_width: 768
2024-05-20 08:16:49,202:WARNING: 	 vision_patch_size: 32
2024-05-20 08:16:49,202:WARNING: 	 context_length: 77
2024-05-20 08:16:49,202:WARNING: 	 vocab_size: 49408
2024-05-20 08:16:49,202:WARNING: 	 transformer_width: 512
2024-05-20 08:16:49,202:WARNING: 	 transformer_heads: 8
2024-05-20 08:16:49,202:WARNING: 	 transformer_layers: 12
2024-05-20 08:16:49,202:WARNING: 	 cut_top_layer: 0
2024-05-20 08:16:50,175:WARNING: 	 sim_type: seqTransf
2024-05-20 08:16:54,657:INFO: --------------------
2024-05-20 08:16:54,657:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-20 08:35:04,219:INFO: device: cuda:0 n_gpu: 1
2024-05-20 08:35:04,219:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-20 08:35:04,460:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-20 08:35:04,461:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-20 08:35:04,461:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-20 08:35:04,462:WARNING: 	 embed_dim: 512
2024-05-20 08:35:04,462:WARNING: 	 image_resolution: 224
2024-05-20 08:35:04,462:WARNING: 	 vision_layers: 12
2024-05-20 08:35:04,462:WARNING: 	 vision_width: 768
2024-05-20 08:35:04,462:WARNING: 	 vision_patch_size: 32
2024-05-20 08:35:04,462:WARNING: 	 context_length: 77
2024-05-20 08:35:04,462:WARNING: 	 vocab_size: 49408
2024-05-20 08:35:04,462:WARNING: 	 transformer_width: 512
2024-05-20 08:35:04,462:WARNING: 	 transformer_heads: 8
2024-05-20 08:35:04,462:WARNING: 	 transformer_layers: 12
2024-05-20 08:35:04,462:WARNING: 	 cut_top_layer: 0
2024-05-20 08:35:05,447:WARNING: 	 sim_type: seqTransf
2024-05-20 08:35:09,947:INFO: --------------------
2024-05-20 08:35:09,947:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-20 08:44:51,392:INFO: device: cuda:0 n_gpu: 1
2024-05-20 08:44:51,459:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-20 08:44:51,697:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-20 08:44:51,698:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-20 08:44:51,698:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-20 08:44:51,699:WARNING: 	 embed_dim: 512
2024-05-20 08:44:51,699:WARNING: 	 image_resolution: 224
2024-05-20 08:44:51,699:WARNING: 	 vision_layers: 12
2024-05-20 08:44:51,699:WARNING: 	 vision_width: 768
2024-05-20 08:44:51,699:WARNING: 	 vision_patch_size: 32
2024-05-20 08:44:51,699:WARNING: 	 context_length: 77
2024-05-20 08:44:51,700:WARNING: 	 vocab_size: 49408
2024-05-20 08:44:51,700:WARNING: 	 transformer_width: 512
2024-05-20 08:44:51,700:WARNING: 	 transformer_heads: 8
2024-05-20 08:44:51,700:WARNING: 	 transformer_layers: 12
2024-05-20 08:44:51,700:WARNING: 	 cut_top_layer: 0
2024-05-20 08:44:52,686:WARNING: 	 sim_type: seqTransf
2024-05-20 08:44:57,176:INFO: --------------------
2024-05-20 08:44:57,176:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-20 08:44:58,930:INFO: ***** Running test *****
2024-05-20 08:44:58,930:INFO:   Num examples = 1
2024-05-20 08:44:58,930:INFO:   Batch size = 64
2024-05-20 08:44:58,930:INFO:   Num steps = 1
2024-05-20 08:54:24,651:INFO: device: cuda:0 n_gpu: 1
2024-05-20 08:54:24,651:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-20 08:54:24,873:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-20 08:54:24,874:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-20 08:54:24,874:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-20 08:54:24,874:WARNING: 	 embed_dim: 512
2024-05-20 08:54:24,874:WARNING: 	 image_resolution: 224
2024-05-20 08:54:24,874:WARNING: 	 vision_layers: 12
2024-05-20 08:54:24,874:WARNING: 	 vision_width: 768
2024-05-20 08:54:24,874:WARNING: 	 vision_patch_size: 32
2024-05-20 08:54:24,874:WARNING: 	 context_length: 77
2024-05-20 08:54:24,874:WARNING: 	 vocab_size: 49408
2024-05-20 08:54:24,874:WARNING: 	 transformer_width: 512
2024-05-20 08:54:24,874:WARNING: 	 transformer_heads: 8
2024-05-20 08:54:24,874:WARNING: 	 transformer_layers: 12
2024-05-20 08:54:24,874:WARNING: 	 cut_top_layer: 0
2024-05-20 08:54:25,846:WARNING: 	 sim_type: seqTransf
2024-05-20 08:54:30,392:INFO: --------------------
2024-05-20 08:54:30,392:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-20 08:55:13,739:INFO: device: cuda:0 n_gpu: 1
2024-05-20 08:55:13,740:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-20 08:55:13,972:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-20 08:55:13,973:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-20 08:55:13,973:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-20 08:55:13,974:WARNING: 	 embed_dim: 512
2024-05-20 08:55:13,974:WARNING: 	 image_resolution: 224
2024-05-20 08:55:13,974:WARNING: 	 vision_layers: 12
2024-05-20 08:55:13,974:WARNING: 	 vision_width: 768
2024-05-20 08:55:13,974:WARNING: 	 vision_patch_size: 32
2024-05-20 08:55:13,974:WARNING: 	 context_length: 77
2024-05-20 08:55:13,974:WARNING: 	 vocab_size: 49408
2024-05-20 08:55:13,974:WARNING: 	 transformer_width: 512
2024-05-20 08:55:13,975:WARNING: 	 transformer_heads: 8
2024-05-20 08:55:13,975:WARNING: 	 transformer_layers: 12
2024-05-20 08:55:13,975:WARNING: 	 cut_top_layer: 0
2024-05-20 08:55:14,963:WARNING: 	 sim_type: seqTransf
2024-05-20 08:55:19,455:INFO: --------------------
2024-05-20 08:55:19,455:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-20 08:58:45,315:INFO: device: cuda:0 n_gpu: 1
2024-05-20 08:58:45,315:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-20 08:58:45,539:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-20 08:58:45,539:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-20 08:58:45,539:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-20 08:58:45,539:WARNING: 	 embed_dim: 512
2024-05-20 08:58:45,539:WARNING: 	 image_resolution: 224
2024-05-20 08:58:45,539:WARNING: 	 vision_layers: 12
2024-05-20 08:58:45,539:WARNING: 	 vision_width: 768
2024-05-20 08:58:45,539:WARNING: 	 vision_patch_size: 32
2024-05-20 08:58:45,539:WARNING: 	 context_length: 77
2024-05-20 08:58:45,539:WARNING: 	 vocab_size: 49408
2024-05-20 08:58:45,539:WARNING: 	 transformer_width: 512
2024-05-20 08:58:45,539:WARNING: 	 transformer_heads: 8
2024-05-20 08:58:45,539:WARNING: 	 transformer_layers: 12
2024-05-20 08:58:45,539:WARNING: 	 cut_top_layer: 0
2024-05-20 08:58:46,509:WARNING: 	 sim_type: seqTransf
2024-05-20 08:58:50,999:INFO: --------------------
2024-05-20 08:58:50,999:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-20 09:01:35,242:INFO: device: cuda:0 n_gpu: 1
2024-05-20 09:01:35,310:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-20 09:01:35,541:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-20 09:01:35,542:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-20 09:01:35,542:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-20 09:01:35,543:WARNING: 	 embed_dim: 512
2024-05-20 09:01:35,543:WARNING: 	 image_resolution: 224
2024-05-20 09:01:35,543:WARNING: 	 vision_layers: 12
2024-05-20 09:01:35,543:WARNING: 	 vision_width: 768
2024-05-20 09:01:35,543:WARNING: 	 vision_patch_size: 32
2024-05-20 09:01:35,544:WARNING: 	 context_length: 77
2024-05-20 09:01:35,544:WARNING: 	 vocab_size: 49408
2024-05-20 09:01:35,544:WARNING: 	 transformer_width: 512
2024-05-20 09:01:35,544:WARNING: 	 transformer_heads: 8
2024-05-20 09:01:35,544:WARNING: 	 transformer_layers: 12
2024-05-20 09:01:35,544:WARNING: 	 cut_top_layer: 0
2024-05-20 09:01:36,532:WARNING: 	 sim_type: seqTransf
2024-05-20 09:01:41,030:INFO: --------------------
2024-05-20 09:01:41,031:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-20 09:01:42,767:INFO: ***** Running test *****
2024-05-20 09:01:42,767:INFO:   Num examples = 1
2024-05-20 09:01:42,767:INFO:   Batch size = 64
2024-05-20 09:01:42,767:INFO:   Num steps = 1
2024-05-20 09:04:59,624:INFO: device: cuda:0 n_gpu: 1
2024-05-20 09:04:59,624:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-20 09:04:59,855:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-20 09:04:59,856:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-20 09:04:59,856:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-20 09:04:59,857:WARNING: 	 embed_dim: 512
2024-05-20 09:04:59,857:WARNING: 	 image_resolution: 224
2024-05-20 09:04:59,857:WARNING: 	 vision_layers: 12
2024-05-20 09:04:59,857:WARNING: 	 vision_width: 768
2024-05-20 09:04:59,857:WARNING: 	 vision_patch_size: 32
2024-05-20 09:04:59,858:WARNING: 	 context_length: 77
2024-05-20 09:04:59,858:WARNING: 	 vocab_size: 49408
2024-05-20 09:04:59,858:WARNING: 	 transformer_width: 512
2024-05-20 09:04:59,858:WARNING: 	 transformer_heads: 8
2024-05-20 09:04:59,858:WARNING: 	 transformer_layers: 12
2024-05-20 09:04:59,858:WARNING: 	 cut_top_layer: 0
2024-05-20 09:05:00,836:WARNING: 	 sim_type: seqTransf
2024-05-20 09:05:05,342:INFO: --------------------
2024-05-20 09:05:05,342:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-20 09:06:14,687:INFO: device: cuda:0 n_gpu: 1
2024-05-20 09:06:14,687:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-20 09:06:14,920:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-20 09:06:14,921:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-20 09:06:14,921:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-20 09:06:14,922:WARNING: 	 embed_dim: 512
2024-05-20 09:06:14,922:WARNING: 	 image_resolution: 224
2024-05-20 09:06:14,922:WARNING: 	 vision_layers: 12
2024-05-20 09:06:14,922:WARNING: 	 vision_width: 768
2024-05-20 09:06:14,922:WARNING: 	 vision_patch_size: 32
2024-05-20 09:06:14,922:WARNING: 	 context_length: 77
2024-05-20 09:06:14,922:WARNING: 	 vocab_size: 49408
2024-05-20 09:06:14,922:WARNING: 	 transformer_width: 512
2024-05-20 09:06:14,922:WARNING: 	 transformer_heads: 8
2024-05-20 09:06:14,922:WARNING: 	 transformer_layers: 12
2024-05-20 09:06:14,922:WARNING: 	 cut_top_layer: 0
2024-05-20 09:06:15,914:WARNING: 	 sim_type: seqTransf
2024-05-20 09:06:20,410:INFO: --------------------
2024-05-20 09:06:20,410:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-20 09:06:52,751:INFO: device: cuda:0 n_gpu: 1
2024-05-20 09:06:52,752:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-20 09:06:52,984:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-20 09:06:52,985:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-20 09:06:52,985:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-20 09:06:52,986:WARNING: 	 embed_dim: 512
2024-05-20 09:06:52,986:WARNING: 	 image_resolution: 224
2024-05-20 09:06:52,986:WARNING: 	 vision_layers: 12
2024-05-20 09:06:52,986:WARNING: 	 vision_width: 768
2024-05-20 09:06:52,986:WARNING: 	 vision_patch_size: 32
2024-05-20 09:06:52,986:WARNING: 	 context_length: 77
2024-05-20 09:06:52,986:WARNING: 	 vocab_size: 49408
2024-05-20 09:06:52,986:WARNING: 	 transformer_width: 512
2024-05-20 09:06:52,986:WARNING: 	 transformer_heads: 8
2024-05-20 09:06:52,986:WARNING: 	 transformer_layers: 12
2024-05-20 09:06:52,986:WARNING: 	 cut_top_layer: 0
2024-05-20 09:06:54,933:WARNING: 	 sim_type: seqTransf
2024-05-20 09:06:59,416:INFO: --------------------
2024-05-20 09:06:59,416:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-20 09:07:43,600:INFO: device: cuda:0 n_gpu: 1
2024-05-20 09:07:43,600:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-20 09:07:43,823:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-20 09:07:43,823:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-20 09:07:43,823:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-20 09:07:43,824:WARNING: 	 embed_dim: 512
2024-05-20 09:07:43,824:WARNING: 	 image_resolution: 224
2024-05-20 09:07:43,824:WARNING: 	 vision_layers: 12
2024-05-20 09:07:43,824:WARNING: 	 vision_width: 768
2024-05-20 09:07:43,824:WARNING: 	 vision_patch_size: 32
2024-05-20 09:07:43,824:WARNING: 	 context_length: 77
2024-05-20 09:07:43,824:WARNING: 	 vocab_size: 49408
2024-05-20 09:07:43,824:WARNING: 	 transformer_width: 512
2024-05-20 09:07:43,824:WARNING: 	 transformer_heads: 8
2024-05-20 09:07:43,824:WARNING: 	 transformer_layers: 12
2024-05-20 09:07:43,824:WARNING: 	 cut_top_layer: 0
2024-05-20 09:07:44,800:WARNING: 	 sim_type: seqTransf
2024-05-20 09:07:49,284:INFO: --------------------
2024-05-20 09:07:49,284:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-20 09:08:47,923:INFO: device: cuda:0 n_gpu: 1
2024-05-20 09:08:47,923:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-20 09:08:48,156:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-20 09:08:48,157:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-20 09:08:48,157:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-20 09:08:48,158:WARNING: 	 embed_dim: 512
2024-05-20 09:08:48,158:WARNING: 	 image_resolution: 224
2024-05-20 09:08:48,158:WARNING: 	 vision_layers: 12
2024-05-20 09:08:48,159:WARNING: 	 vision_width: 768
2024-05-20 09:08:48,159:WARNING: 	 vision_patch_size: 32
2024-05-20 09:08:48,159:WARNING: 	 context_length: 77
2024-05-20 09:08:48,159:WARNING: 	 vocab_size: 49408
2024-05-20 09:08:48,159:WARNING: 	 transformer_width: 512
2024-05-20 09:08:48,159:WARNING: 	 transformer_heads: 8
2024-05-20 09:08:48,159:WARNING: 	 transformer_layers: 12
2024-05-20 09:08:48,159:WARNING: 	 cut_top_layer: 0
2024-05-20 09:08:49,137:WARNING: 	 sim_type: seqTransf
2024-05-20 09:08:53,624:INFO: --------------------
2024-05-20 09:08:53,624:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-20 09:18:09,237:INFO: device: cuda:0 n_gpu: 1
2024-05-20 09:18:09,237:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-20 09:18:09,463:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-20 09:18:09,464:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-20 09:18:09,464:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-20 09:18:09,464:WARNING: 	 embed_dim: 512
2024-05-20 09:18:09,464:WARNING: 	 image_resolution: 224
2024-05-20 09:18:09,464:WARNING: 	 vision_layers: 12
2024-05-20 09:18:09,464:WARNING: 	 vision_width: 768
2024-05-20 09:18:09,464:WARNING: 	 vision_patch_size: 32
2024-05-20 09:18:09,464:WARNING: 	 context_length: 77
2024-05-20 09:18:09,464:WARNING: 	 vocab_size: 49408
2024-05-20 09:18:09,464:WARNING: 	 transformer_width: 512
2024-05-20 09:18:09,464:WARNING: 	 transformer_heads: 8
2024-05-20 09:18:09,464:WARNING: 	 transformer_layers: 12
2024-05-20 09:18:09,464:WARNING: 	 cut_top_layer: 0
2024-05-20 09:18:10,421:WARNING: 	 sim_type: seqTransf
2024-05-20 09:18:14,895:INFO: --------------------
2024-05-20 09:18:14,895:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-20 09:18:34,879:INFO: device: cuda:0 n_gpu: 1
2024-05-20 09:18:34,879:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-20 09:18:35,117:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-20 09:18:35,118:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-20 09:18:35,118:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-20 09:18:35,119:WARNING: 	 embed_dim: 512
2024-05-20 09:18:35,119:WARNING: 	 image_resolution: 224
2024-05-20 09:18:35,120:WARNING: 	 vision_layers: 12
2024-05-20 09:18:35,120:WARNING: 	 vision_width: 768
2024-05-20 09:18:35,120:WARNING: 	 vision_patch_size: 32
2024-05-20 09:18:35,120:WARNING: 	 context_length: 77
2024-05-20 09:18:35,120:WARNING: 	 vocab_size: 49408
2024-05-20 09:18:35,120:WARNING: 	 transformer_width: 512
2024-05-20 09:18:35,120:WARNING: 	 transformer_heads: 8
2024-05-20 09:18:35,120:WARNING: 	 transformer_layers: 12
2024-05-20 09:18:35,120:WARNING: 	 cut_top_layer: 0
2024-05-20 09:18:36,119:WARNING: 	 sim_type: seqTransf
2024-05-20 09:18:40,627:INFO: --------------------
2024-05-20 09:18:40,627:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-20 09:22:41,488:INFO: device: cuda:0 n_gpu: 1
2024-05-20 09:22:41,489:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-20 09:22:41,725:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-20 09:22:41,726:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-20 09:22:41,726:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-20 09:22:41,727:WARNING: 	 embed_dim: 512
2024-05-20 09:22:41,727:WARNING: 	 image_resolution: 224
2024-05-20 09:22:41,727:WARNING: 	 vision_layers: 12
2024-05-20 09:22:41,727:WARNING: 	 vision_width: 768
2024-05-20 09:22:41,728:WARNING: 	 vision_patch_size: 32
2024-05-20 09:22:41,728:WARNING: 	 context_length: 77
2024-05-20 09:22:41,728:WARNING: 	 vocab_size: 49408
2024-05-20 09:22:41,728:WARNING: 	 transformer_width: 512
2024-05-20 09:22:41,728:WARNING: 	 transformer_heads: 8
2024-05-20 09:22:41,728:WARNING: 	 transformer_layers: 12
2024-05-20 09:22:41,728:WARNING: 	 cut_top_layer: 0
2024-05-20 09:22:42,718:WARNING: 	 sim_type: seqTransf
2024-05-20 09:22:47,200:INFO: --------------------
2024-05-20 09:22:47,200:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-20 09:24:09,011:INFO: device: cuda:0 n_gpu: 1
2024-05-20 09:24:09,078:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-20 09:24:09,319:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-20 09:24:09,320:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-20 09:24:09,320:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-20 09:24:09,321:WARNING: 	 embed_dim: 512
2024-05-20 09:24:09,321:WARNING: 	 image_resolution: 224
2024-05-20 09:24:09,321:WARNING: 	 vision_layers: 12
2024-05-20 09:24:09,321:WARNING: 	 vision_width: 768
2024-05-20 09:24:09,321:WARNING: 	 vision_patch_size: 32
2024-05-20 09:24:09,321:WARNING: 	 context_length: 77
2024-05-20 09:24:09,321:WARNING: 	 vocab_size: 49408
2024-05-20 09:24:09,322:WARNING: 	 transformer_width: 512
2024-05-20 09:24:09,322:WARNING: 	 transformer_heads: 8
2024-05-20 09:24:09,322:WARNING: 	 transformer_layers: 12
2024-05-20 09:24:09,322:WARNING: 	 cut_top_layer: 0
2024-05-20 09:24:10,302:WARNING: 	 sim_type: seqTransf
2024-05-20 09:24:14,787:INFO: --------------------
2024-05-20 09:24:14,787:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-20 09:24:16,528:INFO: ***** Running test *****
2024-05-20 09:24:16,528:INFO:   Num examples = 1
2024-05-20 09:24:16,528:INFO:   Batch size = 64
2024-05-20 09:24:16,528:INFO:   Num steps = 1
2024-05-20 09:24:48,525:INFO: device: cuda:0 n_gpu: 1
2024-05-20 09:24:48,593:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-20 09:24:48,830:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-20 09:24:48,832:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-20 09:24:48,832:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-20 09:24:48,833:WARNING: 	 embed_dim: 512
2024-05-20 09:24:48,833:WARNING: 	 image_resolution: 224
2024-05-20 09:24:48,833:WARNING: 	 vision_layers: 12
2024-05-20 09:24:48,833:WARNING: 	 vision_width: 768
2024-05-20 09:24:48,833:WARNING: 	 vision_patch_size: 32
2024-05-20 09:24:48,833:WARNING: 	 context_length: 77
2024-05-20 09:24:48,833:WARNING: 	 vocab_size: 49408
2024-05-20 09:24:48,833:WARNING: 	 transformer_width: 512
2024-05-20 09:24:48,833:WARNING: 	 transformer_heads: 8
2024-05-20 09:24:48,833:WARNING: 	 transformer_layers: 12
2024-05-20 09:24:48,833:WARNING: 	 cut_top_layer: 0
2024-05-20 09:24:49,830:WARNING: 	 sim_type: seqTransf
2024-05-20 09:24:54,327:INFO: --------------------
2024-05-20 09:24:54,327:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-20 09:24:56,078:INFO: ***** Running test *****
2024-05-20 09:24:56,078:INFO:   Num examples = 1
2024-05-20 09:24:56,078:INFO:   Batch size = 64
2024-05-20 09:24:56,078:INFO:   Num steps = 1
2024-05-20 09:25:12,086:INFO: device: cuda:0 n_gpu: 1
2024-05-20 09:25:12,153:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-20 09:25:12,390:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-20 09:25:12,391:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-20 09:25:12,392:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-20 09:25:12,393:WARNING: 	 embed_dim: 512
2024-05-20 09:25:12,393:WARNING: 	 image_resolution: 224
2024-05-20 09:25:12,393:WARNING: 	 vision_layers: 12
2024-05-20 09:25:12,393:WARNING: 	 vision_width: 768
2024-05-20 09:25:12,393:WARNING: 	 vision_patch_size: 32
2024-05-20 09:25:12,393:WARNING: 	 context_length: 77
2024-05-20 09:25:12,393:WARNING: 	 vocab_size: 49408
2024-05-20 09:25:12,393:WARNING: 	 transformer_width: 512
2024-05-20 09:25:12,393:WARNING: 	 transformer_heads: 8
2024-05-20 09:25:12,393:WARNING: 	 transformer_layers: 12
2024-05-20 09:25:12,393:WARNING: 	 cut_top_layer: 0
2024-05-20 09:25:13,372:WARNING: 	 sim_type: seqTransf
2024-05-20 09:25:17,856:INFO: --------------------
2024-05-20 09:25:17,857:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-20 09:25:19,649:INFO: ***** Running test *****
2024-05-20 09:25:19,649:INFO:   Num examples = 1
2024-05-20 09:25:19,649:INFO:   Batch size = 64
2024-05-20 09:25:19,649:INFO:   Num steps = 1
2024-05-20 09:29:10,815:INFO: device: cuda:0 n_gpu: 1
2024-05-20 09:29:10,815:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-20 09:29:11,045:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-20 09:29:11,045:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-20 09:29:11,046:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-20 09:29:11,046:WARNING: 	 embed_dim: 512
2024-05-20 09:29:11,046:WARNING: 	 image_resolution: 224
2024-05-20 09:29:11,046:WARNING: 	 vision_layers: 12
2024-05-20 09:29:11,046:WARNING: 	 vision_width: 768
2024-05-20 09:29:11,046:WARNING: 	 vision_patch_size: 32
2024-05-20 09:29:11,046:WARNING: 	 context_length: 77
2024-05-20 09:29:11,046:WARNING: 	 vocab_size: 49408
2024-05-20 09:29:11,046:WARNING: 	 transformer_width: 512
2024-05-20 09:29:11,046:WARNING: 	 transformer_heads: 8
2024-05-20 09:29:11,046:WARNING: 	 transformer_layers: 12
2024-05-20 09:29:11,046:WARNING: 	 cut_top_layer: 0
2024-05-20 09:29:12,019:WARNING: 	 sim_type: seqTransf
2024-05-20 09:29:16,501:INFO: --------------------
2024-05-20 09:29:16,501:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-21 00:02:55,705:INFO: device: cuda:0 n_gpu: 1
2024-05-21 00:02:55,705:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-21 00:02:55,978:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-21 00:02:55,978:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-21 00:02:55,978:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-21 00:02:55,979:WARNING: 	 embed_dim: 512
2024-05-21 00:02:55,979:WARNING: 	 image_resolution: 224
2024-05-21 00:02:55,979:WARNING: 	 vision_layers: 12
2024-05-21 00:02:55,979:WARNING: 	 vision_width: 768
2024-05-21 00:02:55,979:WARNING: 	 vision_patch_size: 32
2024-05-21 00:02:55,979:WARNING: 	 context_length: 77
2024-05-21 00:02:55,979:WARNING: 	 vocab_size: 49408
2024-05-21 00:02:55,979:WARNING: 	 transformer_width: 512
2024-05-21 00:02:55,979:WARNING: 	 transformer_heads: 8
2024-05-21 00:02:55,979:WARNING: 	 transformer_layers: 12
2024-05-21 00:02:55,979:WARNING: 	 cut_top_layer: 0
2024-05-21 00:02:56,971:WARNING: 	 sim_type: seqTransf
2024-05-21 00:03:01,488:INFO: --------------------
2024-05-21 00:03:01,488:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-21 00:04:20,314:INFO: device: cuda:0 n_gpu: 1
2024-05-21 00:04:20,315:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-21 00:04:20,561:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-21 00:04:20,562:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-21 00:04:20,562:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-21 00:04:20,563:WARNING: 	 embed_dim: 512
2024-05-21 00:04:20,563:WARNING: 	 image_resolution: 224
2024-05-21 00:04:20,563:WARNING: 	 vision_layers: 12
2024-05-21 00:04:20,563:WARNING: 	 vision_width: 768
2024-05-21 00:04:20,563:WARNING: 	 vision_patch_size: 32
2024-05-21 00:04:20,563:WARNING: 	 context_length: 77
2024-05-21 00:04:20,563:WARNING: 	 vocab_size: 49408
2024-05-21 00:04:20,563:WARNING: 	 transformer_width: 512
2024-05-21 00:04:20,564:WARNING: 	 transformer_heads: 8
2024-05-21 00:04:20,564:WARNING: 	 transformer_layers: 12
2024-05-21 00:04:20,564:WARNING: 	 cut_top_layer: 0
2024-05-21 00:04:21,553:WARNING: 	 sim_type: seqTransf
2024-05-21 00:04:26,026:INFO: --------------------
2024-05-21 00:04:26,026:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-21 01:16:25,855:INFO: device: cuda:0 n_gpu: 1
2024-05-21 01:16:25,856:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-21 01:16:26,088:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-21 01:16:26,089:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-21 01:16:26,090:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-21 01:16:26,090:WARNING: 	 embed_dim: 512
2024-05-21 01:16:26,091:WARNING: 	 image_resolution: 224
2024-05-21 01:16:26,091:WARNING: 	 vision_layers: 12
2024-05-21 01:16:26,091:WARNING: 	 vision_width: 768
2024-05-21 01:16:26,091:WARNING: 	 vision_patch_size: 32
2024-05-21 01:16:26,091:WARNING: 	 context_length: 77
2024-05-21 01:16:26,091:WARNING: 	 vocab_size: 49408
2024-05-21 01:16:26,091:WARNING: 	 transformer_width: 512
2024-05-21 01:16:26,091:WARNING: 	 transformer_heads: 8
2024-05-21 01:16:26,091:WARNING: 	 transformer_layers: 12
2024-05-21 01:16:26,091:WARNING: 	 cut_top_layer: 0
2024-05-21 01:16:27,075:WARNING: 	 sim_type: seqTransf
2024-05-21 01:16:31,566:INFO: --------------------
2024-05-21 01:16:31,566:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-21 02:05:37,369:INFO: device: cuda:0 n_gpu: 1
2024-05-21 02:05:37,369:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-21 02:05:37,669:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-21 02:05:37,670:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-21 02:05:37,670:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-21 02:05:37,671:WARNING: 	 embed_dim: 512
2024-05-21 02:05:37,671:WARNING: 	 image_resolution: 224
2024-05-21 02:05:37,671:WARNING: 	 vision_layers: 12
2024-05-21 02:05:37,671:WARNING: 	 vision_width: 768
2024-05-21 02:05:37,671:WARNING: 	 vision_patch_size: 32
2024-05-21 02:05:37,671:WARNING: 	 context_length: 77
2024-05-21 02:05:37,671:WARNING: 	 vocab_size: 49408
2024-05-21 02:05:37,672:WARNING: 	 transformer_width: 512
2024-05-21 02:05:37,672:WARNING: 	 transformer_heads: 8
2024-05-21 02:05:37,672:WARNING: 	 transformer_layers: 12
2024-05-21 02:05:37,672:WARNING: 	 cut_top_layer: 0
2024-05-21 02:05:38,694:WARNING: 	 sim_type: seqTransf
2024-05-21 02:05:43,186:INFO: --------------------
2024-05-21 02:05:43,186:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-21 02:14:38,385:INFO: device: cuda:0 n_gpu: 1
2024-05-21 02:14:38,385:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-21 02:14:38,633:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-21 02:14:38,635:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-21 02:14:38,635:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-21 02:14:38,636:WARNING: 	 embed_dim: 512
2024-05-21 02:14:38,636:WARNING: 	 image_resolution: 224
2024-05-21 02:14:38,636:WARNING: 	 vision_layers: 12
2024-05-21 02:14:38,636:WARNING: 	 vision_width: 768
2024-05-21 02:14:38,636:WARNING: 	 vision_patch_size: 32
2024-05-21 02:14:38,636:WARNING: 	 context_length: 77
2024-05-21 02:14:38,636:WARNING: 	 vocab_size: 49408
2024-05-21 02:14:38,636:WARNING: 	 transformer_width: 512
2024-05-21 02:14:38,636:WARNING: 	 transformer_heads: 8
2024-05-21 02:14:38,636:WARNING: 	 transformer_layers: 12
2024-05-21 02:14:38,636:WARNING: 	 cut_top_layer: 0
2024-05-21 02:14:39,640:WARNING: 	 sim_type: seqTransf
2024-05-21 02:14:44,140:INFO: --------------------
2024-05-21 02:14:44,140:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-21 02:15:27,499:INFO: device: cuda:0 n_gpu: 1
2024-05-21 02:15:27,500:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-21 02:15:27,738:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-21 02:15:27,739:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-21 02:15:27,739:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-21 02:15:27,740:WARNING: 	 embed_dim: 512
2024-05-21 02:15:27,740:WARNING: 	 image_resolution: 224
2024-05-21 02:15:27,740:WARNING: 	 vision_layers: 12
2024-05-21 02:15:27,740:WARNING: 	 vision_width: 768
2024-05-21 02:15:27,740:WARNING: 	 vision_patch_size: 32
2024-05-21 02:15:27,740:WARNING: 	 context_length: 77
2024-05-21 02:15:27,740:WARNING: 	 vocab_size: 49408
2024-05-21 02:15:27,741:WARNING: 	 transformer_width: 512
2024-05-21 02:15:27,741:WARNING: 	 transformer_heads: 8
2024-05-21 02:15:27,741:WARNING: 	 transformer_layers: 12
2024-05-21 02:15:27,741:WARNING: 	 cut_top_layer: 0
2024-05-21 02:15:28,745:WARNING: 	 sim_type: seqTransf
2024-05-21 02:15:33,244:INFO: --------------------
2024-05-21 02:15:33,244:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-21 02:16:49,698:INFO: device: cuda:0 n_gpu: 1
2024-05-21 02:16:49,698:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-21 02:16:49,936:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-21 02:16:49,937:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-21 02:16:49,937:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-21 02:16:49,938:WARNING: 	 embed_dim: 512
2024-05-21 02:16:49,938:WARNING: 	 image_resolution: 224
2024-05-21 02:16:49,938:WARNING: 	 vision_layers: 12
2024-05-21 02:16:49,938:WARNING: 	 vision_width: 768
2024-05-21 02:16:49,938:WARNING: 	 vision_patch_size: 32
2024-05-21 02:16:49,938:WARNING: 	 context_length: 77
2024-05-21 02:16:49,938:WARNING: 	 vocab_size: 49408
2024-05-21 02:16:49,938:WARNING: 	 transformer_width: 512
2024-05-21 02:16:49,938:WARNING: 	 transformer_heads: 8
2024-05-21 02:16:49,938:WARNING: 	 transformer_layers: 12
2024-05-21 02:16:49,938:WARNING: 	 cut_top_layer: 0
2024-05-21 02:16:50,930:WARNING: 	 sim_type: seqTransf
2024-05-21 02:16:55,412:INFO: --------------------
2024-05-21 02:16:55,412:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-21 02:21:02,828:INFO: device: cuda:0 n_gpu: 1
2024-05-21 02:21:02,828:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-21 02:21:03,070:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-21 02:21:03,071:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-21 02:21:03,071:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-21 02:21:03,072:WARNING: 	 embed_dim: 512
2024-05-21 02:21:03,072:WARNING: 	 image_resolution: 224
2024-05-21 02:21:03,072:WARNING: 	 vision_layers: 12
2024-05-21 02:21:03,072:WARNING: 	 vision_width: 768
2024-05-21 02:21:03,072:WARNING: 	 vision_patch_size: 32
2024-05-21 02:21:03,072:WARNING: 	 context_length: 77
2024-05-21 02:21:03,072:WARNING: 	 vocab_size: 49408
2024-05-21 02:21:03,072:WARNING: 	 transformer_width: 512
2024-05-21 02:21:03,072:WARNING: 	 transformer_heads: 8
2024-05-21 02:21:03,072:WARNING: 	 transformer_layers: 12
2024-05-21 02:21:03,072:WARNING: 	 cut_top_layer: 0
2024-05-21 02:21:04,089:WARNING: 	 sim_type: seqTransf
2024-05-21 02:21:08,600:INFO: --------------------
2024-05-21 02:21:08,600:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-21 02:22:12,906:INFO: device: cuda:0 n_gpu: 1
2024-05-21 02:22:12,907:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-21 02:22:13,143:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-21 02:22:13,144:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-21 02:22:13,145:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-21 02:22:13,146:WARNING: 	 embed_dim: 512
2024-05-21 02:22:13,146:WARNING: 	 image_resolution: 224
2024-05-21 02:22:13,146:WARNING: 	 vision_layers: 12
2024-05-21 02:22:13,146:WARNING: 	 vision_width: 768
2024-05-21 02:22:13,146:WARNING: 	 vision_patch_size: 32
2024-05-21 02:22:13,146:WARNING: 	 context_length: 77
2024-05-21 02:22:13,146:WARNING: 	 vocab_size: 49408
2024-05-21 02:22:13,146:WARNING: 	 transformer_width: 512
2024-05-21 02:22:13,146:WARNING: 	 transformer_heads: 8
2024-05-21 02:22:13,146:WARNING: 	 transformer_layers: 12
2024-05-21 02:22:13,146:WARNING: 	 cut_top_layer: 0
2024-05-21 02:22:14,161:WARNING: 	 sim_type: seqTransf
2024-05-21 02:22:18,661:INFO: --------------------
2024-05-21 02:22:18,661:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-21 02:25:53,586:INFO: device: cuda:0 n_gpu: 1
2024-05-21 02:25:53,587:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-21 02:25:53,825:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-21 02:25:53,826:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-21 02:25:53,826:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-21 02:25:53,827:WARNING: 	 embed_dim: 512
2024-05-21 02:25:53,827:WARNING: 	 image_resolution: 224
2024-05-21 02:25:53,827:WARNING: 	 vision_layers: 12
2024-05-21 02:25:53,827:WARNING: 	 vision_width: 768
2024-05-21 02:25:53,827:WARNING: 	 vision_patch_size: 32
2024-05-21 02:25:53,827:WARNING: 	 context_length: 77
2024-05-21 02:25:53,827:WARNING: 	 vocab_size: 49408
2024-05-21 02:25:53,827:WARNING: 	 transformer_width: 512
2024-05-21 02:25:53,827:WARNING: 	 transformer_heads: 8
2024-05-21 02:25:53,827:WARNING: 	 transformer_layers: 12
2024-05-21 02:25:53,827:WARNING: 	 cut_top_layer: 0
2024-05-21 02:25:54,818:WARNING: 	 sim_type: seqTransf
2024-05-21 02:25:59,299:INFO: --------------------
2024-05-21 02:25:59,300:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-21 02:30:10,489:INFO: device: cuda:0 n_gpu: 1
2024-05-21 02:30:10,490:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-21 02:30:10,728:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-21 02:30:10,729:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-21 02:30:10,729:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-21 02:30:10,730:WARNING: 	 embed_dim: 512
2024-05-21 02:30:10,730:WARNING: 	 image_resolution: 224
2024-05-21 02:30:10,730:WARNING: 	 vision_layers: 12
2024-05-21 02:30:10,730:WARNING: 	 vision_width: 768
2024-05-21 02:30:10,730:WARNING: 	 vision_patch_size: 32
2024-05-21 02:30:10,731:WARNING: 	 context_length: 77
2024-05-21 02:30:10,731:WARNING: 	 vocab_size: 49408
2024-05-21 02:30:10,731:WARNING: 	 transformer_width: 512
2024-05-21 02:30:10,731:WARNING: 	 transformer_heads: 8
2024-05-21 02:30:10,731:WARNING: 	 transformer_layers: 12
2024-05-21 02:30:10,731:WARNING: 	 cut_top_layer: 0
2024-05-21 02:30:11,734:WARNING: 	 sim_type: seqTransf
2024-05-21 02:30:16,231:INFO: --------------------
2024-05-21 02:30:16,231:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-21 02:32:29,414:INFO: device: cuda:0 n_gpu: 1
2024-05-21 02:32:29,414:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-21 02:32:29,656:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-21 02:32:29,657:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-21 02:32:29,658:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-21 02:32:29,658:WARNING: 	 embed_dim: 512
2024-05-21 02:32:29,658:WARNING: 	 image_resolution: 224
2024-05-21 02:32:29,659:WARNING: 	 vision_layers: 12
2024-05-21 02:32:29,659:WARNING: 	 vision_width: 768
2024-05-21 02:32:29,659:WARNING: 	 vision_patch_size: 32
2024-05-21 02:32:29,659:WARNING: 	 context_length: 77
2024-05-21 02:32:29,659:WARNING: 	 vocab_size: 49408
2024-05-21 02:32:29,659:WARNING: 	 transformer_width: 512
2024-05-21 02:32:29,659:WARNING: 	 transformer_heads: 8
2024-05-21 02:32:29,659:WARNING: 	 transformer_layers: 12
2024-05-21 02:32:29,659:WARNING: 	 cut_top_layer: 0
2024-05-21 02:32:30,670:WARNING: 	 sim_type: seqTransf
2024-05-21 02:32:35,182:INFO: --------------------
2024-05-21 02:32:35,182:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-21 02:50:52,449:INFO: device: cuda:0 n_gpu: 1
2024-05-21 02:50:52,450:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-21 02:50:52,693:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-21 02:50:52,695:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-21 02:50:52,695:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-21 02:50:52,696:WARNING: 	 embed_dim: 512
2024-05-21 02:50:52,696:WARNING: 	 image_resolution: 224
2024-05-21 02:50:52,696:WARNING: 	 vision_layers: 12
2024-05-21 02:50:52,696:WARNING: 	 vision_width: 768
2024-05-21 02:50:52,696:WARNING: 	 vision_patch_size: 32
2024-05-21 02:50:52,696:WARNING: 	 context_length: 77
2024-05-21 02:50:52,696:WARNING: 	 vocab_size: 49408
2024-05-21 02:50:52,696:WARNING: 	 transformer_width: 512
2024-05-21 02:50:52,696:WARNING: 	 transformer_heads: 8
2024-05-21 02:50:52,696:WARNING: 	 transformer_layers: 12
2024-05-21 02:50:52,696:WARNING: 	 cut_top_layer: 0
2024-05-21 02:50:53,700:WARNING: 	 sim_type: seqTransf
2024-05-21 02:50:58,200:INFO: --------------------
2024-05-21 02:50:58,200:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-21 02:51:22,202:INFO: device: cuda:0 n_gpu: 1
2024-05-21 02:51:22,202:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-21 02:51:22,447:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-21 02:51:22,448:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-21 02:51:22,448:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-21 02:51:22,449:WARNING: 	 embed_dim: 512
2024-05-21 02:51:22,449:WARNING: 	 image_resolution: 224
2024-05-21 02:51:22,449:WARNING: 	 vision_layers: 12
2024-05-21 02:51:22,449:WARNING: 	 vision_width: 768
2024-05-21 02:51:22,449:WARNING: 	 vision_patch_size: 32
2024-05-21 02:51:22,449:WARNING: 	 context_length: 77
2024-05-21 02:51:22,449:WARNING: 	 vocab_size: 49408
2024-05-21 02:51:22,449:WARNING: 	 transformer_width: 512
2024-05-21 02:51:22,449:WARNING: 	 transformer_heads: 8
2024-05-21 02:51:22,449:WARNING: 	 transformer_layers: 12
2024-05-21 02:51:22,449:WARNING: 	 cut_top_layer: 0
2024-05-21 02:51:23,454:WARNING: 	 sim_type: seqTransf
2024-05-21 02:51:27,959:INFO: --------------------
2024-05-21 02:51:27,959:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-21 02:53:31,831:INFO: device: cuda:0 n_gpu: 1
2024-05-21 02:53:31,831:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-21 02:53:32,072:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-21 02:53:32,073:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-21 02:53:32,073:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-21 02:53:32,074:WARNING: 	 embed_dim: 512
2024-05-21 02:53:32,074:WARNING: 	 image_resolution: 224
2024-05-21 02:53:32,074:WARNING: 	 vision_layers: 12
2024-05-21 02:53:32,074:WARNING: 	 vision_width: 768
2024-05-21 02:53:32,074:WARNING: 	 vision_patch_size: 32
2024-05-21 02:53:32,074:WARNING: 	 context_length: 77
2024-05-21 02:53:32,074:WARNING: 	 vocab_size: 49408
2024-05-21 02:53:32,074:WARNING: 	 transformer_width: 512
2024-05-21 02:53:32,074:WARNING: 	 transformer_heads: 8
2024-05-21 02:53:32,074:WARNING: 	 transformer_layers: 12
2024-05-21 02:53:32,075:WARNING: 	 cut_top_layer: 0
2024-05-21 02:53:33,066:WARNING: 	 sim_type: seqTransf
2024-05-21 02:53:37,574:INFO: --------------------
2024-05-21 02:53:37,574:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-21 02:59:41,144:INFO: device: cuda:0 n_gpu: 1
2024-05-21 02:59:41,144:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-21 02:59:41,389:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-21 02:59:41,390:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-21 02:59:41,390:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-21 02:59:41,391:WARNING: 	 embed_dim: 512
2024-05-21 02:59:41,391:WARNING: 	 image_resolution: 224
2024-05-21 02:59:41,391:WARNING: 	 vision_layers: 12
2024-05-21 02:59:41,391:WARNING: 	 vision_width: 768
2024-05-21 02:59:41,391:WARNING: 	 vision_patch_size: 32
2024-05-21 02:59:41,391:WARNING: 	 context_length: 77
2024-05-21 02:59:41,391:WARNING: 	 vocab_size: 49408
2024-05-21 02:59:41,391:WARNING: 	 transformer_width: 512
2024-05-21 02:59:41,391:WARNING: 	 transformer_heads: 8
2024-05-21 02:59:41,391:WARNING: 	 transformer_layers: 12
2024-05-21 02:59:41,391:WARNING: 	 cut_top_layer: 0
2024-05-21 02:59:42,402:WARNING: 	 sim_type: seqTransf
2024-05-21 02:59:46,905:INFO: --------------------
2024-05-21 02:59:46,905:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-21 03:09:14,924:INFO: device: cuda:0 n_gpu: 1
2024-05-21 03:09:14,994:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-21 03:09:15,234:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-21 03:09:15,235:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-21 03:09:15,235:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-21 03:09:15,236:WARNING: 	 embed_dim: 512
2024-05-21 03:09:15,236:WARNING: 	 image_resolution: 224
2024-05-21 03:09:15,236:WARNING: 	 vision_layers: 12
2024-05-21 03:09:15,236:WARNING: 	 vision_width: 768
2024-05-21 03:09:15,236:WARNING: 	 vision_patch_size: 32
2024-05-21 03:09:15,236:WARNING: 	 context_length: 77
2024-05-21 03:09:15,236:WARNING: 	 vocab_size: 49408
2024-05-21 03:09:15,236:WARNING: 	 transformer_width: 512
2024-05-21 03:09:15,236:WARNING: 	 transformer_heads: 8
2024-05-21 03:09:15,237:WARNING: 	 transformer_layers: 12
2024-05-21 03:09:15,237:WARNING: 	 cut_top_layer: 0
2024-05-21 03:09:16,223:WARNING: 	 sim_type: seqTransf
2024-05-21 03:09:20,702:INFO: --------------------
2024-05-21 03:09:20,702:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-21 03:09:22,479:INFO: ***** Running test *****
2024-05-21 03:09:22,479:INFO:   Num examples = 1
2024-05-21 03:09:22,479:INFO:   Batch size = 64
2024-05-21 03:09:22,479:INFO:   Num steps = 1
2024-05-21 03:13:09,158:INFO: device: cuda:0 n_gpu: 1
2024-05-21 03:13:09,226:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-21 03:13:09,471:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-21 03:13:09,472:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-21 03:13:09,472:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-21 03:13:09,473:WARNING: 	 embed_dim: 512
2024-05-21 03:13:09,473:WARNING: 	 image_resolution: 224
2024-05-21 03:13:09,473:WARNING: 	 vision_layers: 12
2024-05-21 03:13:09,473:WARNING: 	 vision_width: 768
2024-05-21 03:13:09,473:WARNING: 	 vision_patch_size: 32
2024-05-21 03:13:09,473:WARNING: 	 context_length: 77
2024-05-21 03:13:09,473:WARNING: 	 vocab_size: 49408
2024-05-21 03:13:09,473:WARNING: 	 transformer_width: 512
2024-05-21 03:13:09,473:WARNING: 	 transformer_heads: 8
2024-05-21 03:13:09,473:WARNING: 	 transformer_layers: 12
2024-05-21 03:13:09,473:WARNING: 	 cut_top_layer: 0
2024-05-21 03:13:10,470:WARNING: 	 sim_type: seqTransf
2024-05-21 03:13:14,967:INFO: --------------------
2024-05-21 03:13:14,967:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-21 03:13:16,757:INFO: ***** Running test *****
2024-05-21 03:13:16,757:INFO:   Num examples = 1
2024-05-21 03:13:16,757:INFO:   Batch size = 64
2024-05-21 03:13:16,757:INFO:   Num steps = 1
2024-05-21 03:13:33,282:INFO: device: cuda:0 n_gpu: 1
2024-05-21 03:13:33,349:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-21 03:13:33,592:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-21 03:13:33,593:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-21 03:13:33,593:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-21 03:13:33,594:WARNING: 	 embed_dim: 512
2024-05-21 03:13:33,594:WARNING: 	 image_resolution: 224
2024-05-21 03:13:33,594:WARNING: 	 vision_layers: 12
2024-05-21 03:13:33,594:WARNING: 	 vision_width: 768
2024-05-21 03:13:33,594:WARNING: 	 vision_patch_size: 32
2024-05-21 03:13:33,594:WARNING: 	 context_length: 77
2024-05-21 03:13:33,594:WARNING: 	 vocab_size: 49408
2024-05-21 03:13:33,594:WARNING: 	 transformer_width: 512
2024-05-21 03:13:33,594:WARNING: 	 transformer_heads: 8
2024-05-21 03:13:33,595:WARNING: 	 transformer_layers: 12
2024-05-21 03:13:33,595:WARNING: 	 cut_top_layer: 0
2024-05-21 03:13:34,596:WARNING: 	 sim_type: seqTransf
2024-05-21 03:13:39,105:INFO: --------------------
2024-05-21 03:13:39,105:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-21 03:13:40,881:INFO: ***** Running test *****
2024-05-21 03:13:40,881:INFO:   Num examples = 1
2024-05-21 03:13:40,881:INFO:   Batch size = 64
2024-05-21 03:13:40,881:INFO:   Num steps = 1
2024-05-21 03:14:45,734:INFO: device: cuda:0 n_gpu: 1
2024-05-21 03:14:45,803:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-21 03:14:46,045:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-21 03:14:46,046:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-21 03:14:46,046:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-21 03:14:46,047:WARNING: 	 embed_dim: 512
2024-05-21 03:14:46,047:WARNING: 	 image_resolution: 224
2024-05-21 03:14:46,047:WARNING: 	 vision_layers: 12
2024-05-21 03:14:46,047:WARNING: 	 vision_width: 768
2024-05-21 03:14:46,047:WARNING: 	 vision_patch_size: 32
2024-05-21 03:14:46,048:WARNING: 	 context_length: 77
2024-05-21 03:14:46,048:WARNING: 	 vocab_size: 49408
2024-05-21 03:14:46,048:WARNING: 	 transformer_width: 512
2024-05-21 03:14:46,048:WARNING: 	 transformer_heads: 8
2024-05-21 03:14:46,048:WARNING: 	 transformer_layers: 12
2024-05-21 03:14:46,048:WARNING: 	 cut_top_layer: 0
2024-05-21 03:14:47,048:WARNING: 	 sim_type: seqTransf
2024-05-21 03:14:51,542:INFO: --------------------
2024-05-21 03:14:51,542:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-21 03:14:53,320:INFO: ***** Running test *****
2024-05-21 03:14:53,320:INFO:   Num examples = 1
2024-05-21 03:14:53,320:INFO:   Batch size = 64
2024-05-21 03:14:53,320:INFO:   Num steps = 1
2024-05-21 03:19:21,461:INFO: device: cuda:0 n_gpu: 1
2024-05-21 03:19:21,530:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-21 03:19:21,773:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-21 03:19:21,775:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-21 03:19:21,775:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-21 03:19:21,776:WARNING: 	 embed_dim: 512
2024-05-21 03:19:21,776:WARNING: 	 image_resolution: 224
2024-05-21 03:19:21,776:WARNING: 	 vision_layers: 12
2024-05-21 03:19:21,776:WARNING: 	 vision_width: 768
2024-05-21 03:19:21,776:WARNING: 	 vision_patch_size: 32
2024-05-21 03:19:21,776:WARNING: 	 context_length: 77
2024-05-21 03:19:21,776:WARNING: 	 vocab_size: 49408
2024-05-21 03:19:21,776:WARNING: 	 transformer_width: 512
2024-05-21 03:19:21,776:WARNING: 	 transformer_heads: 8
2024-05-21 03:19:21,776:WARNING: 	 transformer_layers: 12
2024-05-21 03:19:21,776:WARNING: 	 cut_top_layer: 0
2024-05-21 03:19:22,773:WARNING: 	 sim_type: seqTransf
2024-05-21 03:19:27,267:INFO: --------------------
2024-05-21 03:19:27,268:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-21 03:19:29,053:INFO: ***** Running test *****
2024-05-21 03:19:29,053:INFO:   Num examples = 1
2024-05-21 03:19:29,054:INFO:   Batch size = 64
2024-05-21 03:19:29,054:INFO:   Num steps = 1
2024-05-21 03:19:59,810:INFO: device: cuda:0 n_gpu: 1
2024-05-21 03:19:59,878:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-21 03:20:00,122:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-21 03:20:00,123:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-21 03:20:00,123:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-21 03:20:00,124:WARNING: 	 embed_dim: 512
2024-05-21 03:20:00,124:WARNING: 	 image_resolution: 224
2024-05-21 03:20:00,124:WARNING: 	 vision_layers: 12
2024-05-21 03:20:00,124:WARNING: 	 vision_width: 768
2024-05-21 03:20:00,124:WARNING: 	 vision_patch_size: 32
2024-05-21 03:20:00,124:WARNING: 	 context_length: 77
2024-05-21 03:20:00,124:WARNING: 	 vocab_size: 49408
2024-05-21 03:20:00,124:WARNING: 	 transformer_width: 512
2024-05-21 03:20:00,124:WARNING: 	 transformer_heads: 8
2024-05-21 03:20:00,124:WARNING: 	 transformer_layers: 12
2024-05-21 03:20:00,125:WARNING: 	 cut_top_layer: 0
2024-05-21 03:20:01,123:WARNING: 	 sim_type: seqTransf
2024-05-21 03:20:05,622:INFO: --------------------
2024-05-21 03:20:05,622:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-21 03:20:07,415:INFO: ***** Running test *****
2024-05-21 03:20:07,415:INFO:   Num examples = 1
2024-05-21 03:20:07,415:INFO:   Batch size = 64
2024-05-21 03:20:07,415:INFO:   Num steps = 1
2024-05-21 03:21:18,287:INFO: device: cuda:0 n_gpu: 1
2024-05-21 03:21:18,288:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-21 03:21:18,534:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-21 03:21:18,535:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-21 03:21:18,535:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-21 03:21:18,536:WARNING: 	 embed_dim: 512
2024-05-21 03:21:18,536:WARNING: 	 image_resolution: 224
2024-05-21 03:21:18,537:WARNING: 	 vision_layers: 12
2024-05-21 03:21:18,537:WARNING: 	 vision_width: 768
2024-05-21 03:21:18,537:WARNING: 	 vision_patch_size: 32
2024-05-21 03:21:18,537:WARNING: 	 context_length: 77
2024-05-21 03:21:18,537:WARNING: 	 vocab_size: 49408
2024-05-21 03:21:18,537:WARNING: 	 transformer_width: 512
2024-05-21 03:21:18,537:WARNING: 	 transformer_heads: 8
2024-05-21 03:21:18,537:WARNING: 	 transformer_layers: 12
2024-05-21 03:21:18,537:WARNING: 	 cut_top_layer: 0
2024-05-21 03:21:19,548:WARNING: 	 sim_type: seqTransf
2024-05-21 03:21:33,523:INFO: device: cuda:0 n_gpu: 1
2024-05-21 03:21:33,523:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-21 03:21:33,768:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-21 03:21:33,769:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-21 03:21:33,770:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-21 03:21:33,770:WARNING: 	 embed_dim: 512
2024-05-21 03:21:33,771:WARNING: 	 image_resolution: 224
2024-05-21 03:21:33,771:WARNING: 	 vision_layers: 12
2024-05-21 03:21:33,771:WARNING: 	 vision_width: 768
2024-05-21 03:21:33,771:WARNING: 	 vision_patch_size: 32
2024-05-21 03:21:33,771:WARNING: 	 context_length: 77
2024-05-21 03:21:33,771:WARNING: 	 vocab_size: 49408
2024-05-21 03:21:33,771:WARNING: 	 transformer_width: 512
2024-05-21 03:21:33,771:WARNING: 	 transformer_heads: 8
2024-05-21 03:21:33,771:WARNING: 	 transformer_layers: 12
2024-05-21 03:21:33,771:WARNING: 	 cut_top_layer: 0
2024-05-21 03:21:34,764:WARNING: 	 sim_type: seqTransf
2024-05-21 03:21:39,247:INFO: --------------------
2024-05-21 03:21:39,248:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-21 03:22:19,507:INFO: device: cuda:0 n_gpu: 1
2024-05-21 03:22:19,507:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-21 03:22:19,753:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-21 03:22:19,754:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-21 03:22:19,754:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-21 03:22:19,755:WARNING: 	 embed_dim: 512
2024-05-21 03:22:19,755:WARNING: 	 image_resolution: 224
2024-05-21 03:22:19,755:WARNING: 	 vision_layers: 12
2024-05-21 03:22:19,755:WARNING: 	 vision_width: 768
2024-05-21 03:22:19,755:WARNING: 	 vision_patch_size: 32
2024-05-21 03:22:19,755:WARNING: 	 context_length: 77
2024-05-21 03:22:19,755:WARNING: 	 vocab_size: 49408
2024-05-21 03:22:19,755:WARNING: 	 transformer_width: 512
2024-05-21 03:22:19,755:WARNING: 	 transformer_heads: 8
2024-05-21 03:22:19,755:WARNING: 	 transformer_layers: 12
2024-05-21 03:22:19,755:WARNING: 	 cut_top_layer: 0
2024-05-21 03:22:20,777:WARNING: 	 sim_type: seqTransf
2024-05-21 03:22:33,155:INFO: device: cuda:0 n_gpu: 1
2024-05-21 03:22:33,155:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-21 03:22:33,398:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-21 03:22:33,399:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-21 03:22:33,399:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-21 03:22:33,400:WARNING: 	 embed_dim: 512
2024-05-21 03:22:33,400:WARNING: 	 image_resolution: 224
2024-05-21 03:22:33,400:WARNING: 	 vision_layers: 12
2024-05-21 03:22:33,400:WARNING: 	 vision_width: 768
2024-05-21 03:22:33,400:WARNING: 	 vision_patch_size: 32
2024-05-21 03:22:33,400:WARNING: 	 context_length: 77
2024-05-21 03:22:33,400:WARNING: 	 vocab_size: 49408
2024-05-21 03:22:33,400:WARNING: 	 transformer_width: 512
2024-05-21 03:22:33,400:WARNING: 	 transformer_heads: 8
2024-05-21 03:22:33,400:WARNING: 	 transformer_layers: 12
2024-05-21 03:22:33,400:WARNING: 	 cut_top_layer: 0
2024-05-21 03:22:34,390:WARNING: 	 sim_type: seqTransf
2024-05-21 03:22:38,885:INFO: --------------------
2024-05-21 03:22:38,885:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-21 03:23:39,929:INFO: device: cuda:0 n_gpu: 1
2024-05-21 03:23:39,929:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-21 03:23:40,162:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-21 03:23:40,162:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-21 03:23:40,162:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-21 03:23:40,162:WARNING: 	 embed_dim: 512
2024-05-21 03:23:40,162:WARNING: 	 image_resolution: 224
2024-05-21 03:23:40,162:WARNING: 	 vision_layers: 12
2024-05-21 03:23:40,162:WARNING: 	 vision_width: 768
2024-05-21 03:23:40,162:WARNING: 	 vision_patch_size: 32
2024-05-21 03:23:40,162:WARNING: 	 context_length: 77
2024-05-21 03:23:40,162:WARNING: 	 vocab_size: 49408
2024-05-21 03:23:40,162:WARNING: 	 transformer_width: 512
2024-05-21 03:23:40,162:WARNING: 	 transformer_heads: 8
2024-05-21 03:23:40,162:WARNING: 	 transformer_layers: 12
2024-05-21 03:23:40,162:WARNING: 	 cut_top_layer: 0
2024-05-21 03:23:41,135:WARNING: 	 sim_type: seqTransf
2024-05-21 03:23:45,609:INFO: --------------------
2024-05-21 03:23:45,610:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-21 04:29:01,851:INFO: device: cuda:0 n_gpu: 1
2024-05-21 04:29:01,851:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-21 04:29:02,098:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-21 04:29:02,099:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-21 04:29:02,099:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-21 04:29:02,100:WARNING: 	 embed_dim: 512
2024-05-21 04:29:02,100:WARNING: 	 image_resolution: 224
2024-05-21 04:29:02,100:WARNING: 	 vision_layers: 12
2024-05-21 04:29:02,100:WARNING: 	 vision_width: 768
2024-05-21 04:29:02,100:WARNING: 	 vision_patch_size: 32
2024-05-21 04:29:02,100:WARNING: 	 context_length: 77
2024-05-21 04:29:02,100:WARNING: 	 vocab_size: 49408
2024-05-21 04:29:02,101:WARNING: 	 transformer_width: 512
2024-05-21 04:29:02,101:WARNING: 	 transformer_heads: 8
2024-05-21 04:29:02,101:WARNING: 	 transformer_layers: 12
2024-05-21 04:29:02,101:WARNING: 	 cut_top_layer: 0
2024-05-21 04:29:03,122:WARNING: 	 sim_type: seqTransf
2024-05-21 04:29:07,633:INFO: --------------------
2024-05-21 04:29:07,633:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-21 04:30:16,746:INFO: device: cuda:0 n_gpu: 1
2024-05-21 04:30:16,747:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-21 04:30:16,993:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-21 04:30:16,994:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-21 04:30:16,994:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-21 04:30:16,995:WARNING: 	 embed_dim: 512
2024-05-21 04:30:16,995:WARNING: 	 image_resolution: 224
2024-05-21 04:30:16,995:WARNING: 	 vision_layers: 12
2024-05-21 04:30:16,995:WARNING: 	 vision_width: 768
2024-05-21 04:30:16,995:WARNING: 	 vision_patch_size: 32
2024-05-21 04:30:16,995:WARNING: 	 context_length: 77
2024-05-21 04:30:16,996:WARNING: 	 vocab_size: 49408
2024-05-21 04:30:16,996:WARNING: 	 transformer_width: 512
2024-05-21 04:30:16,996:WARNING: 	 transformer_heads: 8
2024-05-21 04:30:16,996:WARNING: 	 transformer_layers: 12
2024-05-21 04:30:16,996:WARNING: 	 cut_top_layer: 0
2024-05-21 04:30:18,004:WARNING: 	 sim_type: seqTransf
2024-05-21 04:30:22,495:INFO: --------------------
2024-05-21 04:30:22,495:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-21 05:23:51,934:INFO: device: cuda:0 n_gpu: 1
2024-05-21 05:23:51,934:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-21 05:23:52,179:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-21 05:23:52,180:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-21 05:23:52,180:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-21 05:23:52,181:WARNING: 	 embed_dim: 512
2024-05-21 05:23:52,181:WARNING: 	 image_resolution: 224
2024-05-21 05:23:52,181:WARNING: 	 vision_layers: 12
2024-05-21 05:23:52,181:WARNING: 	 vision_width: 768
2024-05-21 05:23:52,181:WARNING: 	 vision_patch_size: 32
2024-05-21 05:23:52,181:WARNING: 	 context_length: 77
2024-05-21 05:23:52,181:WARNING: 	 vocab_size: 49408
2024-05-21 05:23:52,181:WARNING: 	 transformer_width: 512
2024-05-21 05:23:52,181:WARNING: 	 transformer_heads: 8
2024-05-21 05:23:52,181:WARNING: 	 transformer_layers: 12
2024-05-21 05:23:52,181:WARNING: 	 cut_top_layer: 0
2024-05-21 05:23:53,192:WARNING: 	 sim_type: seqTransf
2024-05-21 05:23:57,698:INFO: --------------------
2024-05-21 05:23:57,698:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-21 05:25:38,478:INFO: device: cuda:0 n_gpu: 1
2024-05-21 05:25:38,479:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-21 05:25:38,727:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-21 05:25:38,728:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-21 05:25:38,728:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-21 05:25:38,729:WARNING: 	 embed_dim: 512
2024-05-21 05:25:38,729:WARNING: 	 image_resolution: 224
2024-05-21 05:25:38,729:WARNING: 	 vision_layers: 12
2024-05-21 05:25:38,729:WARNING: 	 vision_width: 768
2024-05-21 05:25:38,729:WARNING: 	 vision_patch_size: 32
2024-05-21 05:25:38,729:WARNING: 	 context_length: 77
2024-05-21 05:25:38,729:WARNING: 	 vocab_size: 49408
2024-05-21 05:25:38,729:WARNING: 	 transformer_width: 512
2024-05-21 05:25:38,730:WARNING: 	 transformer_heads: 8
2024-05-21 05:25:38,730:WARNING: 	 transformer_layers: 12
2024-05-21 05:25:38,730:WARNING: 	 cut_top_layer: 0
2024-05-21 05:25:39,738:WARNING: 	 sim_type: seqTransf
2024-05-21 05:25:44,242:INFO: --------------------
2024-05-21 05:25:44,243:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-21 05:26:54,882:INFO: device: cuda:0 n_gpu: 1
2024-05-21 05:26:54,882:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-21 05:26:55,128:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-21 05:26:55,130:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-21 05:26:55,130:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-21 05:26:55,131:WARNING: 	 embed_dim: 512
2024-05-21 05:26:55,131:WARNING: 	 image_resolution: 224
2024-05-21 05:26:55,131:WARNING: 	 vision_layers: 12
2024-05-21 05:26:55,131:WARNING: 	 vision_width: 768
2024-05-21 05:26:55,131:WARNING: 	 vision_patch_size: 32
2024-05-21 05:26:55,131:WARNING: 	 context_length: 77
2024-05-21 05:26:55,131:WARNING: 	 vocab_size: 49408
2024-05-21 05:26:55,131:WARNING: 	 transformer_width: 512
2024-05-21 05:26:55,131:WARNING: 	 transformer_heads: 8
2024-05-21 05:26:55,131:WARNING: 	 transformer_layers: 12
2024-05-21 05:26:55,131:WARNING: 	 cut_top_layer: 0
2024-05-21 05:26:56,139:WARNING: 	 sim_type: seqTransf
2024-05-21 05:27:00,681:INFO: --------------------
2024-05-21 05:27:00,681:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-21 05:28:05,418:INFO: device: cuda:0 n_gpu: 1
2024-05-21 05:28:05,418:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-21 05:28:05,659:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-21 05:28:05,660:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-21 05:28:05,660:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-21 05:28:05,661:WARNING: 	 embed_dim: 512
2024-05-21 05:28:05,661:WARNING: 	 image_resolution: 224
2024-05-21 05:28:05,661:WARNING: 	 vision_layers: 12
2024-05-21 05:28:05,661:WARNING: 	 vision_width: 768
2024-05-21 05:28:05,661:WARNING: 	 vision_patch_size: 32
2024-05-21 05:28:05,661:WARNING: 	 context_length: 77
2024-05-21 05:28:05,661:WARNING: 	 vocab_size: 49408
2024-05-21 05:28:05,661:WARNING: 	 transformer_width: 512
2024-05-21 05:28:05,661:WARNING: 	 transformer_heads: 8
2024-05-21 05:28:05,661:WARNING: 	 transformer_layers: 12
2024-05-21 05:28:05,662:WARNING: 	 cut_top_layer: 0
2024-05-21 05:28:06,659:WARNING: 	 sim_type: seqTransf
2024-05-21 05:28:11,148:INFO: --------------------
2024-05-21 05:28:11,148:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-21 05:28:54,040:INFO: device: cuda:0 n_gpu: 1
2024-05-21 05:28:54,040:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-21 05:28:54,286:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-21 05:28:54,287:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-21 05:28:54,287:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-21 05:28:54,288:WARNING: 	 embed_dim: 512
2024-05-21 05:28:54,288:WARNING: 	 image_resolution: 224
2024-05-21 05:28:54,288:WARNING: 	 vision_layers: 12
2024-05-21 05:28:54,289:WARNING: 	 vision_width: 768
2024-05-21 05:28:54,289:WARNING: 	 vision_patch_size: 32
2024-05-21 05:28:54,289:WARNING: 	 context_length: 77
2024-05-21 05:28:54,289:WARNING: 	 vocab_size: 49408
2024-05-21 05:28:54,289:WARNING: 	 transformer_width: 512
2024-05-21 05:28:54,289:WARNING: 	 transformer_heads: 8
2024-05-21 05:28:54,289:WARNING: 	 transformer_layers: 12
2024-05-21 05:28:54,289:WARNING: 	 cut_top_layer: 0
2024-05-21 05:28:55,301:WARNING: 	 sim_type: seqTransf
2024-05-21 05:28:59,782:INFO: --------------------
2024-05-21 05:28:59,783:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-21 05:34:55,751:INFO: device: cuda:0 n_gpu: 1
2024-05-21 05:34:55,751:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-21 05:34:55,997:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-21 05:34:55,998:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-21 05:34:55,998:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-21 05:34:55,999:WARNING: 	 embed_dim: 512
2024-05-21 05:34:55,999:WARNING: 	 image_resolution: 224
2024-05-21 05:34:55,999:WARNING: 	 vision_layers: 12
2024-05-21 05:34:55,999:WARNING: 	 vision_width: 768
2024-05-21 05:34:55,999:WARNING: 	 vision_patch_size: 32
2024-05-21 05:34:55,999:WARNING: 	 context_length: 77
2024-05-21 05:34:55,999:WARNING: 	 vocab_size: 49408
2024-05-21 05:34:55,999:WARNING: 	 transformer_width: 512
2024-05-21 05:34:55,999:WARNING: 	 transformer_heads: 8
2024-05-21 05:34:55,999:WARNING: 	 transformer_layers: 12
2024-05-21 05:34:55,999:WARNING: 	 cut_top_layer: 0
2024-05-21 05:34:57,007:WARNING: 	 sim_type: seqTransf
2024-05-21 05:35:08,334:INFO: device: cuda:0 n_gpu: 1
2024-05-21 05:35:08,334:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-21 05:35:08,579:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-21 05:35:08,580:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-21 05:35:08,580:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-21 05:35:08,581:WARNING: 	 embed_dim: 512
2024-05-21 05:35:08,581:WARNING: 	 image_resolution: 224
2024-05-21 05:35:08,581:WARNING: 	 vision_layers: 12
2024-05-21 05:35:08,581:WARNING: 	 vision_width: 768
2024-05-21 05:35:08,581:WARNING: 	 vision_patch_size: 32
2024-05-21 05:35:08,581:WARNING: 	 context_length: 77
2024-05-21 05:35:08,581:WARNING: 	 vocab_size: 49408
2024-05-21 05:35:08,581:WARNING: 	 transformer_width: 512
2024-05-21 05:35:08,581:WARNING: 	 transformer_heads: 8
2024-05-21 05:35:08,582:WARNING: 	 transformer_layers: 12
2024-05-21 05:35:08,582:WARNING: 	 cut_top_layer: 0
2024-05-21 05:35:09,588:WARNING: 	 sim_type: seqTransf
2024-05-21 05:35:14,084:INFO: --------------------
2024-05-21 05:35:14,084:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-21 06:18:01,443:INFO: device: cuda:0 n_gpu: 1
2024-05-21 06:18:01,444:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-21 06:18:01,706:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-21 06:18:01,707:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-21 06:18:01,707:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-21 06:18:01,708:WARNING: 	 embed_dim: 512
2024-05-21 06:18:01,708:WARNING: 	 image_resolution: 224
2024-05-21 06:18:01,708:WARNING: 	 vision_layers: 12
2024-05-21 06:18:01,708:WARNING: 	 vision_width: 768
2024-05-21 06:18:01,708:WARNING: 	 vision_patch_size: 32
2024-05-21 06:18:01,708:WARNING: 	 context_length: 77
2024-05-21 06:18:01,708:WARNING: 	 vocab_size: 49408
2024-05-21 06:18:01,709:WARNING: 	 transformer_width: 512
2024-05-21 06:18:01,709:WARNING: 	 transformer_heads: 8
2024-05-21 06:18:01,709:WARNING: 	 transformer_layers: 12
2024-05-21 06:18:01,709:WARNING: 	 cut_top_layer: 0
2024-05-21 06:18:02,712:WARNING: 	 sim_type: seqTransf
2024-05-21 06:18:07,218:INFO: --------------------
2024-05-21 06:18:07,218:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-21 06:18:29,782:INFO: device: cuda:0 n_gpu: 1
2024-05-21 06:18:29,783:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-21 06:18:30,029:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-21 06:18:30,030:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-21 06:18:30,031:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-21 06:18:30,031:WARNING: 	 embed_dim: 512
2024-05-21 06:18:30,031:WARNING: 	 image_resolution: 224
2024-05-21 06:18:30,032:WARNING: 	 vision_layers: 12
2024-05-21 06:18:30,032:WARNING: 	 vision_width: 768
2024-05-21 06:18:30,032:WARNING: 	 vision_patch_size: 32
2024-05-21 06:18:30,032:WARNING: 	 context_length: 77
2024-05-21 06:18:30,032:WARNING: 	 vocab_size: 49408
2024-05-21 06:18:30,032:WARNING: 	 transformer_width: 512
2024-05-21 06:18:30,032:WARNING: 	 transformer_heads: 8
2024-05-21 06:18:30,032:WARNING: 	 transformer_layers: 12
2024-05-21 06:18:30,032:WARNING: 	 cut_top_layer: 0
2024-05-21 06:18:31,053:WARNING: 	 sim_type: seqTransf
2024-05-21 06:18:35,559:INFO: --------------------
2024-05-21 06:18:35,559:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-21 06:27:14,411:INFO: device: cuda:0 n_gpu: 1
2024-05-21 06:27:14,411:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-21 06:27:14,661:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-21 06:27:14,663:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-21 06:27:14,663:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-21 06:27:14,664:WARNING: 	 embed_dim: 512
2024-05-21 06:27:14,664:WARNING: 	 image_resolution: 224
2024-05-21 06:27:14,664:WARNING: 	 vision_layers: 12
2024-05-21 06:27:14,664:WARNING: 	 vision_width: 768
2024-05-21 06:27:14,664:WARNING: 	 vision_patch_size: 32
2024-05-21 06:27:14,664:WARNING: 	 context_length: 77
2024-05-21 06:27:14,664:WARNING: 	 vocab_size: 49408
2024-05-21 06:27:14,664:WARNING: 	 transformer_width: 512
2024-05-21 06:27:14,664:WARNING: 	 transformer_heads: 8
2024-05-21 06:27:14,664:WARNING: 	 transformer_layers: 12
2024-05-21 06:27:14,664:WARNING: 	 cut_top_layer: 0
2024-05-21 06:27:15,676:WARNING: 	 sim_type: seqTransf
2024-05-21 06:27:20,171:INFO: --------------------
2024-05-21 06:27:20,171:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-21 06:30:04,886:INFO: device: cuda:0 n_gpu: 1
2024-05-21 06:30:04,887:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-21 06:30:05,133:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-21 06:30:05,134:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-21 06:30:05,134:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-21 06:30:05,135:WARNING: 	 embed_dim: 512
2024-05-21 06:30:05,135:WARNING: 	 image_resolution: 224
2024-05-21 06:30:05,135:WARNING: 	 vision_layers: 12
2024-05-21 06:30:05,135:WARNING: 	 vision_width: 768
2024-05-21 06:30:05,135:WARNING: 	 vision_patch_size: 32
2024-05-21 06:30:05,135:WARNING: 	 context_length: 77
2024-05-21 06:30:05,135:WARNING: 	 vocab_size: 49408
2024-05-21 06:30:05,135:WARNING: 	 transformer_width: 512
2024-05-21 06:30:05,135:WARNING: 	 transformer_heads: 8
2024-05-21 06:30:05,135:WARNING: 	 transformer_layers: 12
2024-05-21 06:30:05,135:WARNING: 	 cut_top_layer: 0
2024-05-21 06:30:06,148:WARNING: 	 sim_type: seqTransf
2024-05-21 06:30:10,608:INFO: --------------------
2024-05-21 06:30:10,608:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-21 06:30:42,221:INFO: device: cuda:0 n_gpu: 1
2024-05-21 06:30:42,221:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-21 06:30:42,471:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-21 06:30:42,473:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-21 06:30:42,473:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-21 06:30:42,474:WARNING: 	 embed_dim: 512
2024-05-21 06:30:42,474:WARNING: 	 image_resolution: 224
2024-05-21 06:30:42,474:WARNING: 	 vision_layers: 12
2024-05-21 06:30:42,474:WARNING: 	 vision_width: 768
2024-05-21 06:30:42,474:WARNING: 	 vision_patch_size: 32
2024-05-21 06:30:42,474:WARNING: 	 context_length: 77
2024-05-21 06:30:42,474:WARNING: 	 vocab_size: 49408
2024-05-21 06:30:42,474:WARNING: 	 transformer_width: 512
2024-05-21 06:30:42,474:WARNING: 	 transformer_heads: 8
2024-05-21 06:30:42,474:WARNING: 	 transformer_layers: 12
2024-05-21 06:30:42,474:WARNING: 	 cut_top_layer: 0
2024-05-21 06:30:43,526:WARNING: 	 sim_type: seqTransf
2024-05-21 06:30:48,028:INFO: --------------------
2024-05-21 06:30:48,028:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-21 06:39:07,490:INFO: device: cuda:0 n_gpu: 1
2024-05-21 06:39:07,490:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-21 06:39:07,726:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-21 06:39:07,726:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-21 06:39:07,726:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-21 06:39:07,726:WARNING: 	 embed_dim: 512
2024-05-21 06:39:07,726:WARNING: 	 image_resolution: 224
2024-05-21 06:39:07,726:WARNING: 	 vision_layers: 12
2024-05-21 06:39:07,726:WARNING: 	 vision_width: 768
2024-05-21 06:39:07,726:WARNING: 	 vision_patch_size: 32
2024-05-21 06:39:07,726:WARNING: 	 context_length: 77
2024-05-21 06:39:07,726:WARNING: 	 vocab_size: 49408
2024-05-21 06:39:07,726:WARNING: 	 transformer_width: 512
2024-05-21 06:39:07,726:WARNING: 	 transformer_heads: 8
2024-05-21 06:39:07,726:WARNING: 	 transformer_layers: 12
2024-05-21 06:39:07,726:WARNING: 	 cut_top_layer: 0
2024-05-21 06:39:08,724:WARNING: 	 sim_type: seqTransf
2024-05-21 06:39:13,224:INFO: --------------------
2024-05-21 06:39:13,225:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-21 06:43:22,070:INFO: device: cuda:0 n_gpu: 1
2024-05-21 06:43:22,070:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-21 06:43:22,313:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-21 06:43:22,314:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-21 06:43:22,314:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-21 06:43:22,315:WARNING: 	 embed_dim: 512
2024-05-21 06:43:22,315:WARNING: 	 image_resolution: 224
2024-05-21 06:43:22,315:WARNING: 	 vision_layers: 12
2024-05-21 06:43:22,315:WARNING: 	 vision_width: 768
2024-05-21 06:43:22,316:WARNING: 	 vision_patch_size: 32
2024-05-21 06:43:22,316:WARNING: 	 context_length: 77
2024-05-21 06:43:22,316:WARNING: 	 vocab_size: 49408
2024-05-21 06:43:22,316:WARNING: 	 transformer_width: 512
2024-05-21 06:43:22,316:WARNING: 	 transformer_heads: 8
2024-05-21 06:43:22,316:WARNING: 	 transformer_layers: 12
2024-05-21 06:43:22,316:WARNING: 	 cut_top_layer: 0
2024-05-21 06:43:23,326:WARNING: 	 sim_type: seqTransf
2024-05-21 06:43:27,813:INFO: --------------------
2024-05-21 06:43:27,813:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-21 06:44:40,798:INFO: device: cuda:0 n_gpu: 1
2024-05-21 06:44:40,798:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-21 06:44:41,034:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-21 06:44:41,035:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-21 06:44:41,035:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-21 06:44:41,035:WARNING: 	 embed_dim: 512
2024-05-21 06:44:41,035:WARNING: 	 image_resolution: 224
2024-05-21 06:44:41,035:WARNING: 	 vision_layers: 12
2024-05-21 06:44:41,035:WARNING: 	 vision_width: 768
2024-05-21 06:44:41,035:WARNING: 	 vision_patch_size: 32
2024-05-21 06:44:41,035:WARNING: 	 context_length: 77
2024-05-21 06:44:41,035:WARNING: 	 vocab_size: 49408
2024-05-21 06:44:41,035:WARNING: 	 transformer_width: 512
2024-05-21 06:44:41,035:WARNING: 	 transformer_heads: 8
2024-05-21 06:44:41,035:WARNING: 	 transformer_layers: 12
2024-05-21 06:44:41,035:WARNING: 	 cut_top_layer: 0
2024-05-21 06:44:42,021:WARNING: 	 sim_type: seqTransf
2024-05-21 06:44:46,492:INFO: --------------------
2024-05-21 06:44:46,492:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-21 06:46:03,047:INFO: device: cuda:0 n_gpu: 1
2024-05-21 06:46:03,047:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-21 06:46:03,288:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-21 06:46:03,288:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-21 06:46:03,288:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-21 06:46:03,288:WARNING: 	 embed_dim: 512
2024-05-21 06:46:03,288:WARNING: 	 image_resolution: 224
2024-05-21 06:46:03,288:WARNING: 	 vision_layers: 12
2024-05-21 06:46:03,288:WARNING: 	 vision_width: 768
2024-05-21 06:46:03,288:WARNING: 	 vision_patch_size: 32
2024-05-21 06:46:03,288:WARNING: 	 context_length: 77
2024-05-21 06:46:03,288:WARNING: 	 vocab_size: 49408
2024-05-21 06:46:03,288:WARNING: 	 transformer_width: 512
2024-05-21 06:46:03,288:WARNING: 	 transformer_heads: 8
2024-05-21 06:46:03,288:WARNING: 	 transformer_layers: 12
2024-05-21 06:46:03,288:WARNING: 	 cut_top_layer: 0
2024-05-21 06:46:04,288:WARNING: 	 sim_type: seqTransf
2024-05-21 06:46:08,756:INFO: --------------------
2024-05-21 06:46:08,756:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-21 06:46:34,896:INFO: device: cuda:0 n_gpu: 1
2024-05-21 06:46:34,896:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-21 06:46:35,139:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-21 06:46:35,139:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-21 06:46:35,139:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-21 06:46:35,139:WARNING: 	 embed_dim: 512
2024-05-21 06:46:35,139:WARNING: 	 image_resolution: 224
2024-05-21 06:46:35,139:WARNING: 	 vision_layers: 12
2024-05-21 06:46:35,139:WARNING: 	 vision_width: 768
2024-05-21 06:46:35,139:WARNING: 	 vision_patch_size: 32
2024-05-21 06:46:35,139:WARNING: 	 context_length: 77
2024-05-21 06:46:35,139:WARNING: 	 vocab_size: 49408
2024-05-21 06:46:35,139:WARNING: 	 transformer_width: 512
2024-05-21 06:46:35,139:WARNING: 	 transformer_heads: 8
2024-05-21 06:46:35,139:WARNING: 	 transformer_layers: 12
2024-05-21 06:46:35,139:WARNING: 	 cut_top_layer: 0
2024-05-21 06:46:36,140:WARNING: 	 sim_type: seqTransf
2024-05-21 06:46:40,628:INFO: --------------------
2024-05-21 06:46:40,628:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-21 06:48:50,041:INFO: device: cuda:0 n_gpu: 1
2024-05-21 06:48:50,041:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-21 06:48:50,281:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-21 06:48:50,281:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-21 06:48:50,281:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-21 06:48:50,282:WARNING: 	 embed_dim: 512
2024-05-21 06:48:50,282:WARNING: 	 image_resolution: 224
2024-05-21 06:48:50,282:WARNING: 	 vision_layers: 12
2024-05-21 06:48:50,282:WARNING: 	 vision_width: 768
2024-05-21 06:48:50,282:WARNING: 	 vision_patch_size: 32
2024-05-21 06:48:50,282:WARNING: 	 context_length: 77
2024-05-21 06:48:50,282:WARNING: 	 vocab_size: 49408
2024-05-21 06:48:50,282:WARNING: 	 transformer_width: 512
2024-05-21 06:48:50,282:WARNING: 	 transformer_heads: 8
2024-05-21 06:48:50,282:WARNING: 	 transformer_layers: 12
2024-05-21 06:48:50,282:WARNING: 	 cut_top_layer: 0
2024-05-21 06:48:51,281:WARNING: 	 sim_type: seqTransf
2024-05-21 06:48:55,769:INFO: --------------------
2024-05-21 06:48:55,770:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-21 06:49:58,759:INFO: device: cuda:0 n_gpu: 1
2024-05-21 06:49:58,759:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-21 06:49:59,005:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-21 06:49:59,006:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-21 06:49:59,007:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-21 06:49:59,007:WARNING: 	 embed_dim: 512
2024-05-21 06:49:59,007:WARNING: 	 image_resolution: 224
2024-05-21 06:49:59,007:WARNING: 	 vision_layers: 12
2024-05-21 06:49:59,008:WARNING: 	 vision_width: 768
2024-05-21 06:49:59,008:WARNING: 	 vision_patch_size: 32
2024-05-21 06:49:59,008:WARNING: 	 context_length: 77
2024-05-21 06:49:59,008:WARNING: 	 vocab_size: 49408
2024-05-21 06:49:59,008:WARNING: 	 transformer_width: 512
2024-05-21 06:49:59,008:WARNING: 	 transformer_heads: 8
2024-05-21 06:49:59,008:WARNING: 	 transformer_layers: 12
2024-05-21 06:49:59,008:WARNING: 	 cut_top_layer: 0
2024-05-21 06:50:00,030:WARNING: 	 sim_type: seqTransf
2024-05-21 06:50:04,535:INFO: --------------------
2024-05-21 06:50:04,535:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-21 06:50:56,026:INFO: device: cuda:0 n_gpu: 1
2024-05-21 06:50:56,027:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-21 06:50:56,270:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-21 06:50:56,271:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-21 06:50:56,271:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-21 06:50:56,272:WARNING: 	 embed_dim: 512
2024-05-21 06:50:56,272:WARNING: 	 image_resolution: 224
2024-05-21 06:50:56,272:WARNING: 	 vision_layers: 12
2024-05-21 06:50:56,272:WARNING: 	 vision_width: 768
2024-05-21 06:50:56,272:WARNING: 	 vision_patch_size: 32
2024-05-21 06:50:56,272:WARNING: 	 context_length: 77
2024-05-21 06:50:56,272:WARNING: 	 vocab_size: 49408
2024-05-21 06:50:56,272:WARNING: 	 transformer_width: 512
2024-05-21 06:50:56,272:WARNING: 	 transformer_heads: 8
2024-05-21 06:50:56,273:WARNING: 	 transformer_layers: 12
2024-05-21 06:50:56,273:WARNING: 	 cut_top_layer: 0
2024-05-21 06:50:57,276:WARNING: 	 sim_type: seqTransf
2024-05-21 06:51:01,765:INFO: --------------------
2024-05-21 06:51:01,765:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-21 06:51:25,551:INFO: device: cuda:0 n_gpu: 1
2024-05-21 06:51:25,551:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-21 06:51:25,794:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-21 06:51:25,795:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-21 06:51:25,795:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-21 06:51:25,796:WARNING: 	 embed_dim: 512
2024-05-21 06:51:25,796:WARNING: 	 image_resolution: 224
2024-05-21 06:51:25,796:WARNING: 	 vision_layers: 12
2024-05-21 06:51:25,796:WARNING: 	 vision_width: 768
2024-05-21 06:51:25,796:WARNING: 	 vision_patch_size: 32
2024-05-21 06:51:25,796:WARNING: 	 context_length: 77
2024-05-21 06:51:25,796:WARNING: 	 vocab_size: 49408
2024-05-21 06:51:25,797:WARNING: 	 transformer_width: 512
2024-05-21 06:51:25,797:WARNING: 	 transformer_heads: 8
2024-05-21 06:51:25,797:WARNING: 	 transformer_layers: 12
2024-05-21 06:51:25,797:WARNING: 	 cut_top_layer: 0
2024-05-21 06:51:26,807:WARNING: 	 sim_type: seqTransf
2024-05-21 06:51:31,315:INFO: --------------------
2024-05-21 06:51:31,315:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-21 06:51:59,830:INFO: device: cuda:0 n_gpu: 1
2024-05-21 06:51:59,830:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-21 06:52:00,072:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-21 06:52:00,073:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-21 06:52:00,073:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-21 06:52:00,073:WARNING: 	 embed_dim: 512
2024-05-21 06:52:00,073:WARNING: 	 image_resolution: 224
2024-05-21 06:52:00,073:WARNING: 	 vision_layers: 12
2024-05-21 06:52:00,073:WARNING: 	 vision_width: 768
2024-05-21 06:52:00,073:WARNING: 	 vision_patch_size: 32
2024-05-21 06:52:00,073:WARNING: 	 context_length: 77
2024-05-21 06:52:00,073:WARNING: 	 vocab_size: 49408
2024-05-21 06:52:00,073:WARNING: 	 transformer_width: 512
2024-05-21 06:52:00,073:WARNING: 	 transformer_heads: 8
2024-05-21 06:52:00,073:WARNING: 	 transformer_layers: 12
2024-05-21 06:52:00,073:WARNING: 	 cut_top_layer: 0
2024-05-21 06:52:01,074:WARNING: 	 sim_type: seqTransf
2024-05-21 06:52:05,558:INFO: --------------------
2024-05-21 06:52:05,558:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-21 06:54:00,638:INFO: device: cuda:0 n_gpu: 1
2024-05-21 06:54:00,638:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-21 06:54:00,875:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-21 06:54:00,875:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-21 06:54:00,875:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-21 06:54:00,875:WARNING: 	 embed_dim: 512
2024-05-21 06:54:00,875:WARNING: 	 image_resolution: 224
2024-05-21 06:54:00,875:WARNING: 	 vision_layers: 12
2024-05-21 06:54:00,875:WARNING: 	 vision_width: 768
2024-05-21 06:54:00,875:WARNING: 	 vision_patch_size: 32
2024-05-21 06:54:00,875:WARNING: 	 context_length: 77
2024-05-21 06:54:00,875:WARNING: 	 vocab_size: 49408
2024-05-21 06:54:00,875:WARNING: 	 transformer_width: 512
2024-05-21 06:54:00,875:WARNING: 	 transformer_heads: 8
2024-05-21 06:54:00,875:WARNING: 	 transformer_layers: 12
2024-05-21 06:54:00,875:WARNING: 	 cut_top_layer: 0
2024-05-21 06:54:01,861:WARNING: 	 sim_type: seqTransf
2024-05-21 06:54:06,338:INFO: --------------------
2024-05-21 06:54:06,338:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-21 06:56:42,195:INFO: device: cuda:0 n_gpu: 1
2024-05-21 06:56:42,195:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-21 06:56:42,440:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-21 06:56:42,440:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-21 06:56:42,440:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-21 06:56:42,441:WARNING: 	 embed_dim: 512
2024-05-21 06:56:42,441:WARNING: 	 image_resolution: 224
2024-05-21 06:56:42,441:WARNING: 	 vision_layers: 12
2024-05-21 06:56:42,441:WARNING: 	 vision_width: 768
2024-05-21 06:56:42,441:WARNING: 	 vision_patch_size: 32
2024-05-21 06:56:42,441:WARNING: 	 context_length: 77
2024-05-21 06:56:42,441:WARNING: 	 vocab_size: 49408
2024-05-21 06:56:42,441:WARNING: 	 transformer_width: 512
2024-05-21 06:56:42,441:WARNING: 	 transformer_heads: 8
2024-05-21 06:56:42,441:WARNING: 	 transformer_layers: 12
2024-05-21 06:56:42,441:WARNING: 	 cut_top_layer: 0
2024-05-21 06:56:43,446:WARNING: 	 sim_type: seqTransf
2024-05-21 06:56:47,936:INFO: --------------------
2024-05-21 06:56:47,936:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-21 06:57:16,727:INFO: device: cuda:0 n_gpu: 1
2024-05-21 06:57:16,727:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-21 06:57:16,968:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-21 06:57:16,968:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-21 06:57:16,968:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-21 06:57:16,968:WARNING: 	 embed_dim: 512
2024-05-21 06:57:16,968:WARNING: 	 image_resolution: 224
2024-05-21 06:57:16,968:WARNING: 	 vision_layers: 12
2024-05-21 06:57:16,968:WARNING: 	 vision_width: 768
2024-05-21 06:57:16,968:WARNING: 	 vision_patch_size: 32
2024-05-21 06:57:16,968:WARNING: 	 context_length: 77
2024-05-21 06:57:16,968:WARNING: 	 vocab_size: 49408
2024-05-21 06:57:16,968:WARNING: 	 transformer_width: 512
2024-05-21 06:57:16,968:WARNING: 	 transformer_heads: 8
2024-05-21 06:57:16,968:WARNING: 	 transformer_layers: 12
2024-05-21 06:57:16,968:WARNING: 	 cut_top_layer: 0
2024-05-21 06:57:17,973:WARNING: 	 sim_type: seqTransf
2024-05-21 06:57:22,456:INFO: --------------------
2024-05-21 06:57:22,456:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-21 06:57:52,177:INFO: device: cuda:0 n_gpu: 1
2024-05-21 06:57:52,178:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-21 06:57:52,427:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-21 06:57:52,428:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-21 06:57:52,428:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-21 06:57:52,429:WARNING: 	 embed_dim: 512
2024-05-21 06:57:52,429:WARNING: 	 image_resolution: 224
2024-05-21 06:57:52,429:WARNING: 	 vision_layers: 12
2024-05-21 06:57:52,429:WARNING: 	 vision_width: 768
2024-05-21 06:57:52,429:WARNING: 	 vision_patch_size: 32
2024-05-21 06:57:52,429:WARNING: 	 context_length: 77
2024-05-21 06:57:52,429:WARNING: 	 vocab_size: 49408
2024-05-21 06:57:52,429:WARNING: 	 transformer_width: 512
2024-05-21 06:57:52,429:WARNING: 	 transformer_heads: 8
2024-05-21 06:57:52,429:WARNING: 	 transformer_layers: 12
2024-05-21 06:57:52,429:WARNING: 	 cut_top_layer: 0
2024-05-21 06:57:53,455:WARNING: 	 sim_type: seqTransf
2024-05-21 06:57:57,939:INFO: --------------------
2024-05-21 06:57:57,940:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-21 06:58:55,051:INFO: device: cuda:0 n_gpu: 1
2024-05-21 06:58:55,051:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-21 06:58:55,291:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-21 06:58:55,291:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-21 06:58:55,291:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-21 06:58:55,291:WARNING: 	 embed_dim: 512
2024-05-21 06:58:55,291:WARNING: 	 image_resolution: 224
2024-05-21 06:58:55,291:WARNING: 	 vision_layers: 12
2024-05-21 06:58:55,291:WARNING: 	 vision_width: 768
2024-05-21 06:58:55,291:WARNING: 	 vision_patch_size: 32
2024-05-21 06:58:55,292:WARNING: 	 context_length: 77
2024-05-21 06:58:55,292:WARNING: 	 vocab_size: 49408
2024-05-21 06:58:55,292:WARNING: 	 transformer_width: 512
2024-05-21 06:58:55,292:WARNING: 	 transformer_heads: 8
2024-05-21 06:58:55,292:WARNING: 	 transformer_layers: 12
2024-05-21 06:58:55,292:WARNING: 	 cut_top_layer: 0
2024-05-21 06:58:56,301:WARNING: 	 sim_type: seqTransf
2024-05-21 06:59:00,792:INFO: --------------------
2024-05-21 06:59:00,792:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-21 06:59:30,845:INFO: device: cuda:0 n_gpu: 1
2024-05-21 06:59:30,846:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-21 06:59:31,098:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-21 06:59:31,099:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-21 06:59:31,099:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-21 06:59:31,100:WARNING: 	 embed_dim: 512
2024-05-21 06:59:31,100:WARNING: 	 image_resolution: 224
2024-05-21 06:59:31,100:WARNING: 	 vision_layers: 12
2024-05-21 06:59:31,100:WARNING: 	 vision_width: 768
2024-05-21 06:59:31,100:WARNING: 	 vision_patch_size: 32
2024-05-21 06:59:31,100:WARNING: 	 context_length: 77
2024-05-21 06:59:31,100:WARNING: 	 vocab_size: 49408
2024-05-21 06:59:31,100:WARNING: 	 transformer_width: 512
2024-05-21 06:59:31,100:WARNING: 	 transformer_heads: 8
2024-05-21 06:59:31,100:WARNING: 	 transformer_layers: 12
2024-05-21 06:59:31,101:WARNING: 	 cut_top_layer: 0
2024-05-21 06:59:32,124:WARNING: 	 sim_type: seqTransf
2024-05-21 06:59:36,629:INFO: --------------------
2024-05-21 06:59:36,629:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-21 07:00:07,086:INFO: device: cuda:0 n_gpu: 1
2024-05-21 07:00:07,087:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-21 07:00:07,335:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-21 07:00:07,336:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-21 07:00:07,337:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-21 07:00:07,337:WARNING: 	 embed_dim: 512
2024-05-21 07:00:07,337:WARNING: 	 image_resolution: 224
2024-05-21 07:00:07,338:WARNING: 	 vision_layers: 12
2024-05-21 07:00:07,338:WARNING: 	 vision_width: 768
2024-05-21 07:00:07,338:WARNING: 	 vision_patch_size: 32
2024-05-21 07:00:07,338:WARNING: 	 context_length: 77
2024-05-21 07:00:07,338:WARNING: 	 vocab_size: 49408
2024-05-21 07:00:07,338:WARNING: 	 transformer_width: 512
2024-05-21 07:00:07,338:WARNING: 	 transformer_heads: 8
2024-05-21 07:00:07,338:WARNING: 	 transformer_layers: 12
2024-05-21 07:00:07,338:WARNING: 	 cut_top_layer: 0
2024-05-21 07:00:08,352:WARNING: 	 sim_type: seqTransf
2024-05-21 07:00:12,854:INFO: --------------------
2024-05-21 07:00:12,855:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-21 07:02:58,266:INFO: device: cuda:0 n_gpu: 1
2024-05-21 07:02:58,266:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-21 07:02:58,517:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-21 07:02:58,518:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-21 07:02:58,518:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-21 07:02:58,519:WARNING: 	 embed_dim: 512
2024-05-21 07:02:58,519:WARNING: 	 image_resolution: 224
2024-05-21 07:02:58,519:WARNING: 	 vision_layers: 12
2024-05-21 07:02:58,519:WARNING: 	 vision_width: 768
2024-05-21 07:02:58,519:WARNING: 	 vision_patch_size: 32
2024-05-21 07:02:58,519:WARNING: 	 context_length: 77
2024-05-21 07:02:58,519:WARNING: 	 vocab_size: 49408
2024-05-21 07:02:58,519:WARNING: 	 transformer_width: 512
2024-05-21 07:02:58,519:WARNING: 	 transformer_heads: 8
2024-05-21 07:02:58,520:WARNING: 	 transformer_layers: 12
2024-05-21 07:02:58,520:WARNING: 	 cut_top_layer: 0
2024-05-21 07:02:59,564:WARNING: 	 sim_type: seqTransf
2024-05-21 07:03:04,093:INFO: --------------------
2024-05-21 07:03:04,093:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-21 07:04:26,242:INFO: device: cuda:0 n_gpu: 1
2024-05-21 07:04:26,243:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-21 07:04:26,497:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-21 07:04:26,498:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-21 07:04:26,498:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-21 07:04:26,500:WARNING: 	 embed_dim: 512
2024-05-21 07:04:26,500:WARNING: 	 image_resolution: 224
2024-05-21 07:04:26,500:WARNING: 	 vision_layers: 12
2024-05-21 07:04:26,500:WARNING: 	 vision_width: 768
2024-05-21 07:04:26,500:WARNING: 	 vision_patch_size: 32
2024-05-21 07:04:26,500:WARNING: 	 context_length: 77
2024-05-21 07:04:26,500:WARNING: 	 vocab_size: 49408
2024-05-21 07:04:26,500:WARNING: 	 transformer_width: 512
2024-05-21 07:04:26,500:WARNING: 	 transformer_heads: 8
2024-05-21 07:04:26,500:WARNING: 	 transformer_layers: 12
2024-05-21 07:04:26,500:WARNING: 	 cut_top_layer: 0
2024-05-21 07:04:27,519:WARNING: 	 sim_type: seqTransf
2024-05-21 07:04:32,014:INFO: --------------------
2024-05-21 07:04:32,014:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-21 07:06:09,422:INFO: device: cuda:0 n_gpu: 1
2024-05-21 07:06:09,422:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-21 07:06:09,678:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-21 07:06:09,679:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-21 07:06:09,679:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-21 07:06:09,680:WARNING: 	 embed_dim: 512
2024-05-21 07:06:09,680:WARNING: 	 image_resolution: 224
2024-05-21 07:06:09,680:WARNING: 	 vision_layers: 12
2024-05-21 07:06:09,680:WARNING: 	 vision_width: 768
2024-05-21 07:06:09,680:WARNING: 	 vision_patch_size: 32
2024-05-21 07:06:09,680:WARNING: 	 context_length: 77
2024-05-21 07:06:09,681:WARNING: 	 vocab_size: 49408
2024-05-21 07:06:09,681:WARNING: 	 transformer_width: 512
2024-05-21 07:06:09,681:WARNING: 	 transformer_heads: 8
2024-05-21 07:06:09,681:WARNING: 	 transformer_layers: 12
2024-05-21 07:06:09,681:WARNING: 	 cut_top_layer: 0
2024-05-21 07:06:10,705:WARNING: 	 sim_type: seqTransf
2024-05-21 07:06:15,218:INFO: --------------------
2024-05-21 07:06:15,218:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-21 07:10:44,931:INFO: device: cuda:0 n_gpu: 1
2024-05-21 07:10:44,931:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-21 07:10:45,179:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-21 07:10:45,179:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-21 07:10:45,179:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-21 07:10:45,180:WARNING: 	 embed_dim: 512
2024-05-21 07:10:45,180:WARNING: 	 image_resolution: 224
2024-05-21 07:10:45,180:WARNING: 	 vision_layers: 12
2024-05-21 07:10:45,180:WARNING: 	 vision_width: 768
2024-05-21 07:10:45,180:WARNING: 	 vision_patch_size: 32
2024-05-21 07:10:45,180:WARNING: 	 context_length: 77
2024-05-21 07:10:45,180:WARNING: 	 vocab_size: 49408
2024-05-21 07:10:45,180:WARNING: 	 transformer_width: 512
2024-05-21 07:10:45,180:WARNING: 	 transformer_heads: 8
2024-05-21 07:10:45,180:WARNING: 	 transformer_layers: 12
2024-05-21 07:10:45,180:WARNING: 	 cut_top_layer: 0
2024-05-21 07:10:46,175:WARNING: 	 sim_type: seqTransf
2024-05-21 07:10:50,653:INFO: --------------------
2024-05-21 07:10:50,653:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-21 07:11:46,402:INFO: device: cuda:0 n_gpu: 1
2024-05-21 07:11:46,402:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-21 07:11:46,654:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-21 07:11:46,655:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-21 07:11:46,655:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-21 07:11:46,656:WARNING: 	 embed_dim: 512
2024-05-21 07:11:46,656:WARNING: 	 image_resolution: 224
2024-05-21 07:11:46,656:WARNING: 	 vision_layers: 12
2024-05-21 07:11:46,656:WARNING: 	 vision_width: 768
2024-05-21 07:11:46,656:WARNING: 	 vision_patch_size: 32
2024-05-21 07:11:46,656:WARNING: 	 context_length: 77
2024-05-21 07:11:46,656:WARNING: 	 vocab_size: 49408
2024-05-21 07:11:46,656:WARNING: 	 transformer_width: 512
2024-05-21 07:11:46,656:WARNING: 	 transformer_heads: 8
2024-05-21 07:11:46,656:WARNING: 	 transformer_layers: 12
2024-05-21 07:11:46,656:WARNING: 	 cut_top_layer: 0
2024-05-21 07:11:47,688:WARNING: 	 sim_type: seqTransf
2024-05-21 07:11:52,199:INFO: --------------------
2024-05-21 07:11:52,199:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-21 07:13:49,453:INFO: device: cuda:0 n_gpu: 1
2024-05-21 07:13:49,453:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-21 07:13:49,699:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-21 07:13:49,699:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-21 07:13:49,699:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-21 07:13:49,699:WARNING: 	 embed_dim: 512
2024-05-21 07:13:49,699:WARNING: 	 image_resolution: 224
2024-05-21 07:13:49,699:WARNING: 	 vision_layers: 12
2024-05-21 07:13:49,699:WARNING: 	 vision_width: 768
2024-05-21 07:13:49,699:WARNING: 	 vision_patch_size: 32
2024-05-21 07:13:49,699:WARNING: 	 context_length: 77
2024-05-21 07:13:49,699:WARNING: 	 vocab_size: 49408
2024-05-21 07:13:49,699:WARNING: 	 transformer_width: 512
2024-05-21 07:13:49,699:WARNING: 	 transformer_heads: 8
2024-05-21 07:13:49,699:WARNING: 	 transformer_layers: 12
2024-05-21 07:13:49,699:WARNING: 	 cut_top_layer: 0
2024-05-21 07:13:50,702:WARNING: 	 sim_type: seqTransf
2024-05-21 07:13:55,188:INFO: --------------------
2024-05-21 07:13:55,188:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-21 07:15:23,259:INFO: device: cuda:0 n_gpu: 1
2024-05-21 07:15:23,259:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-21 07:15:23,512:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-21 07:15:23,513:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-21 07:15:23,513:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-21 07:15:23,514:WARNING: 	 embed_dim: 512
2024-05-21 07:15:23,514:WARNING: 	 image_resolution: 224
2024-05-21 07:15:23,514:WARNING: 	 vision_layers: 12
2024-05-21 07:15:23,514:WARNING: 	 vision_width: 768
2024-05-21 07:15:23,514:WARNING: 	 vision_patch_size: 32
2024-05-21 07:15:23,514:WARNING: 	 context_length: 77
2024-05-21 07:15:23,514:WARNING: 	 vocab_size: 49408
2024-05-21 07:15:23,514:WARNING: 	 transformer_width: 512
2024-05-21 07:15:23,514:WARNING: 	 transformer_heads: 8
2024-05-21 07:15:23,514:WARNING: 	 transformer_layers: 12
2024-05-21 07:15:23,515:WARNING: 	 cut_top_layer: 0
2024-05-21 07:15:24,543:WARNING: 	 sim_type: seqTransf
2024-05-21 07:15:29,157:INFO: --------------------
2024-05-21 07:15:29,157:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-21 07:19:10,690:INFO: device: cuda:0 n_gpu: 1
2024-05-21 07:19:10,690:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-21 07:19:10,934:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-21 07:19:10,935:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-21 07:19:10,935:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-21 07:19:10,935:WARNING: 	 embed_dim: 512
2024-05-21 07:19:10,935:WARNING: 	 image_resolution: 224
2024-05-21 07:19:10,935:WARNING: 	 vision_layers: 12
2024-05-21 07:19:10,935:WARNING: 	 vision_width: 768
2024-05-21 07:19:10,935:WARNING: 	 vision_patch_size: 32
2024-05-21 07:19:10,935:WARNING: 	 context_length: 77
2024-05-21 07:19:10,935:WARNING: 	 vocab_size: 49408
2024-05-21 07:19:10,935:WARNING: 	 transformer_width: 512
2024-05-21 07:19:10,935:WARNING: 	 transformer_heads: 8
2024-05-21 07:19:10,935:WARNING: 	 transformer_layers: 12
2024-05-21 07:19:10,935:WARNING: 	 cut_top_layer: 0
2024-05-21 07:19:11,939:WARNING: 	 sim_type: seqTransf
2024-05-21 07:19:16,426:INFO: --------------------
2024-05-21 07:19:16,426:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-21 07:22:46,446:INFO: device: cuda:0 n_gpu: 1
2024-05-21 07:22:46,446:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-21 07:22:46,688:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-21 07:22:46,688:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-21 07:22:46,688:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-21 07:22:46,688:WARNING: 	 embed_dim: 512
2024-05-21 07:22:46,688:WARNING: 	 image_resolution: 224
2024-05-21 07:22:46,688:WARNING: 	 vision_layers: 12
2024-05-21 07:22:46,688:WARNING: 	 vision_width: 768
2024-05-21 07:22:46,688:WARNING: 	 vision_patch_size: 32
2024-05-21 07:22:46,688:WARNING: 	 context_length: 77
2024-05-21 07:22:46,688:WARNING: 	 vocab_size: 49408
2024-05-21 07:22:46,688:WARNING: 	 transformer_width: 512
2024-05-21 07:22:46,688:WARNING: 	 transformer_heads: 8
2024-05-21 07:22:46,688:WARNING: 	 transformer_layers: 12
2024-05-21 07:22:46,688:WARNING: 	 cut_top_layer: 0
2024-05-21 07:22:47,691:WARNING: 	 sim_type: seqTransf
2024-05-21 07:22:52,179:INFO: --------------------
2024-05-21 07:22:52,179:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-21 07:23:48,014:INFO: device: cuda:0 n_gpu: 1
2024-05-21 07:23:48,014:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-21 07:23:48,258:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-21 07:23:48,259:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-21 07:23:48,259:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-21 07:23:48,259:WARNING: 	 embed_dim: 512
2024-05-21 07:23:48,259:WARNING: 	 image_resolution: 224
2024-05-21 07:23:48,259:WARNING: 	 vision_layers: 12
2024-05-21 07:23:48,259:WARNING: 	 vision_width: 768
2024-05-21 07:23:48,259:WARNING: 	 vision_patch_size: 32
2024-05-21 07:23:48,259:WARNING: 	 context_length: 77
2024-05-21 07:23:48,259:WARNING: 	 vocab_size: 49408
2024-05-21 07:23:48,259:WARNING: 	 transformer_width: 512
2024-05-21 07:23:48,259:WARNING: 	 transformer_heads: 8
2024-05-21 07:23:48,259:WARNING: 	 transformer_layers: 12
2024-05-21 07:23:48,259:WARNING: 	 cut_top_layer: 0
2024-05-21 07:23:49,264:WARNING: 	 sim_type: seqTransf
2024-05-21 07:23:53,751:INFO: --------------------
2024-05-21 07:23:53,751:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-21 07:24:18,046:INFO: device: cuda:0 n_gpu: 1
2024-05-21 07:24:18,046:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-21 07:24:18,289:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-21 07:24:18,290:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-21 07:24:18,290:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-21 07:24:18,290:WARNING: 	 embed_dim: 512
2024-05-21 07:24:18,290:WARNING: 	 image_resolution: 224
2024-05-21 07:24:18,290:WARNING: 	 vision_layers: 12
2024-05-21 07:24:18,290:WARNING: 	 vision_width: 768
2024-05-21 07:24:18,290:WARNING: 	 vision_patch_size: 32
2024-05-21 07:24:18,290:WARNING: 	 context_length: 77
2024-05-21 07:24:18,290:WARNING: 	 vocab_size: 49408
2024-05-21 07:24:18,290:WARNING: 	 transformer_width: 512
2024-05-21 07:24:18,290:WARNING: 	 transformer_heads: 8
2024-05-21 07:24:18,290:WARNING: 	 transformer_layers: 12
2024-05-21 07:24:18,290:WARNING: 	 cut_top_layer: 0
2024-05-21 07:24:19,292:WARNING: 	 sim_type: seqTransf
2024-05-21 07:24:23,818:INFO: --------------------
2024-05-21 07:24:23,818:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-21 07:25:03,562:INFO: device: cuda:0 n_gpu: 1
2024-05-21 07:25:03,562:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-21 07:25:03,804:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-21 07:25:03,804:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-21 07:25:03,804:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-21 07:25:03,804:WARNING: 	 embed_dim: 512
2024-05-21 07:25:03,804:WARNING: 	 image_resolution: 224
2024-05-21 07:25:03,804:WARNING: 	 vision_layers: 12
2024-05-21 07:25:03,804:WARNING: 	 vision_width: 768
2024-05-21 07:25:03,805:WARNING: 	 vision_patch_size: 32
2024-05-21 07:25:03,805:WARNING: 	 context_length: 77
2024-05-21 07:25:03,805:WARNING: 	 vocab_size: 49408
2024-05-21 07:25:03,805:WARNING: 	 transformer_width: 512
2024-05-21 07:25:03,805:WARNING: 	 transformer_heads: 8
2024-05-21 07:25:03,805:WARNING: 	 transformer_layers: 12
2024-05-21 07:25:03,805:WARNING: 	 cut_top_layer: 0
2024-05-21 07:25:04,789:WARNING: 	 sim_type: seqTransf
2024-05-21 07:25:09,261:INFO: --------------------
2024-05-21 07:25:09,261:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-21 07:25:37,380:INFO: device: cuda:0 n_gpu: 1
2024-05-21 07:25:37,380:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-21 07:25:37,630:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-21 07:25:37,631:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-21 07:25:37,631:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-21 07:25:37,632:WARNING: 	 embed_dim: 512
2024-05-21 07:25:37,632:WARNING: 	 image_resolution: 224
2024-05-21 07:25:37,632:WARNING: 	 vision_layers: 12
2024-05-21 07:25:37,632:WARNING: 	 vision_width: 768
2024-05-21 07:25:37,632:WARNING: 	 vision_patch_size: 32
2024-05-21 07:25:37,633:WARNING: 	 context_length: 77
2024-05-21 07:25:37,633:WARNING: 	 vocab_size: 49408
2024-05-21 07:25:37,633:WARNING: 	 transformer_width: 512
2024-05-21 07:25:37,633:WARNING: 	 transformer_heads: 8
2024-05-21 07:25:37,633:WARNING: 	 transformer_layers: 12
2024-05-21 07:25:37,633:WARNING: 	 cut_top_layer: 0
2024-05-21 07:25:38,655:WARNING: 	 sim_type: seqTransf
2024-05-21 07:25:43,162:INFO: --------------------
2024-05-21 07:25:43,162:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-21 07:29:49,092:INFO: device: cuda:0 n_gpu: 1
2024-05-21 07:29:49,093:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-21 07:29:49,334:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-21 07:29:49,335:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-21 07:29:49,335:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-21 07:29:49,335:WARNING: 	 embed_dim: 512
2024-05-21 07:29:49,335:WARNING: 	 image_resolution: 224
2024-05-21 07:29:49,335:WARNING: 	 vision_layers: 12
2024-05-21 07:29:49,335:WARNING: 	 vision_width: 768
2024-05-21 07:29:49,335:WARNING: 	 vision_patch_size: 32
2024-05-21 07:29:49,335:WARNING: 	 context_length: 77
2024-05-21 07:29:49,335:WARNING: 	 vocab_size: 49408
2024-05-21 07:29:49,335:WARNING: 	 transformer_width: 512
2024-05-21 07:29:49,335:WARNING: 	 transformer_heads: 8
2024-05-21 07:29:49,335:WARNING: 	 transformer_layers: 12
2024-05-21 07:29:49,335:WARNING: 	 cut_top_layer: 0
2024-05-21 07:29:50,324:WARNING: 	 sim_type: seqTransf
2024-05-21 07:29:54,806:INFO: --------------------
2024-05-21 07:29:54,806:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-21 08:24:34,375:INFO: device: cuda:0 n_gpu: 1
2024-05-21 08:24:34,375:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-21 08:24:34,603:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-21 08:24:34,604:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-21 08:24:34,604:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-21 08:24:34,604:WARNING: 	 embed_dim: 512
2024-05-21 08:24:34,604:WARNING: 	 image_resolution: 224
2024-05-21 08:24:34,604:WARNING: 	 vision_layers: 12
2024-05-21 08:24:34,604:WARNING: 	 vision_width: 768
2024-05-21 08:24:34,604:WARNING: 	 vision_patch_size: 32
2024-05-21 08:24:34,604:WARNING: 	 context_length: 77
2024-05-21 08:24:34,604:WARNING: 	 vocab_size: 49408
2024-05-21 08:24:34,604:WARNING: 	 transformer_width: 512
2024-05-21 08:24:34,604:WARNING: 	 transformer_heads: 8
2024-05-21 08:24:34,604:WARNING: 	 transformer_layers: 12
2024-05-21 08:24:34,604:WARNING: 	 cut_top_layer: 0
2024-05-21 08:24:35,576:WARNING: 	 sim_type: seqTransf
2024-05-21 08:24:40,064:INFO: --------------------
2024-05-21 08:24:40,064:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-21 08:25:06,570:INFO: device: cuda:0 n_gpu: 1
2024-05-21 08:25:06,570:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-21 08:25:06,814:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-21 08:25:06,815:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-21 08:25:06,815:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-21 08:25:06,815:WARNING: 	 embed_dim: 512
2024-05-21 08:25:06,815:WARNING: 	 image_resolution: 224
2024-05-21 08:25:06,815:WARNING: 	 vision_layers: 12
2024-05-21 08:25:06,815:WARNING: 	 vision_width: 768
2024-05-21 08:25:06,815:WARNING: 	 vision_patch_size: 32
2024-05-21 08:25:06,815:WARNING: 	 context_length: 77
2024-05-21 08:25:06,815:WARNING: 	 vocab_size: 49408
2024-05-21 08:25:06,815:WARNING: 	 transformer_width: 512
2024-05-21 08:25:06,815:WARNING: 	 transformer_heads: 8
2024-05-21 08:25:06,815:WARNING: 	 transformer_layers: 12
2024-05-21 08:25:06,815:WARNING: 	 cut_top_layer: 0
2024-05-21 08:25:08,145:WARNING: 	 sim_type: seqTransf
2024-05-21 08:25:12,625:INFO: --------------------
2024-05-21 08:25:12,625:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-21 08:26:12,514:INFO: device: cuda:0 n_gpu: 1
2024-05-21 08:26:12,514:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-21 08:26:12,754:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-21 08:26:12,755:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-21 08:26:12,755:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-21 08:26:12,755:WARNING: 	 embed_dim: 512
2024-05-21 08:26:12,755:WARNING: 	 image_resolution: 224
2024-05-21 08:26:12,755:WARNING: 	 vision_layers: 12
2024-05-21 08:26:12,755:WARNING: 	 vision_width: 768
2024-05-21 08:26:12,755:WARNING: 	 vision_patch_size: 32
2024-05-21 08:26:12,755:WARNING: 	 context_length: 77
2024-05-21 08:26:12,755:WARNING: 	 vocab_size: 49408
2024-05-21 08:26:12,755:WARNING: 	 transformer_width: 512
2024-05-21 08:26:12,755:WARNING: 	 transformer_heads: 8
2024-05-21 08:26:12,755:WARNING: 	 transformer_layers: 12
2024-05-21 08:26:12,755:WARNING: 	 cut_top_layer: 0
2024-05-21 08:26:13,759:WARNING: 	 sim_type: seqTransf
2024-05-21 08:26:18,226:INFO: --------------------
2024-05-21 08:26:18,226:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-21 08:27:07,314:INFO: device: cuda:0 n_gpu: 1
2024-05-21 08:27:07,314:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-21 08:27:07,558:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-21 08:27:07,558:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-21 08:27:07,558:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-21 08:27:07,558:WARNING: 	 embed_dim: 512
2024-05-21 08:27:07,558:WARNING: 	 image_resolution: 224
2024-05-21 08:27:07,558:WARNING: 	 vision_layers: 12
2024-05-21 08:27:07,558:WARNING: 	 vision_width: 768
2024-05-21 08:27:07,558:WARNING: 	 vision_patch_size: 32
2024-05-21 08:27:07,558:WARNING: 	 context_length: 77
2024-05-21 08:27:07,558:WARNING: 	 vocab_size: 49408
2024-05-21 08:27:07,558:WARNING: 	 transformer_width: 512
2024-05-21 08:27:07,558:WARNING: 	 transformer_heads: 8
2024-05-21 08:27:07,558:WARNING: 	 transformer_layers: 12
2024-05-21 08:27:07,558:WARNING: 	 cut_top_layer: 0
2024-05-21 08:27:08,559:WARNING: 	 sim_type: seqTransf
2024-05-21 08:27:13,046:INFO: --------------------
2024-05-21 08:27:13,046:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-21 08:28:47,914:INFO: device: cuda:0 n_gpu: 1
2024-05-21 08:28:47,914:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-21 08:28:48,158:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-21 08:28:48,158:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-21 08:28:48,158:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-21 08:28:48,158:WARNING: 	 embed_dim: 512
2024-05-21 08:28:48,158:WARNING: 	 image_resolution: 224
2024-05-21 08:28:48,158:WARNING: 	 vision_layers: 12
2024-05-21 08:28:48,158:WARNING: 	 vision_width: 768
2024-05-21 08:28:48,158:WARNING: 	 vision_patch_size: 32
2024-05-21 08:28:48,158:WARNING: 	 context_length: 77
2024-05-21 08:28:48,158:WARNING: 	 vocab_size: 49408
2024-05-21 08:28:48,158:WARNING: 	 transformer_width: 512
2024-05-21 08:28:48,158:WARNING: 	 transformer_heads: 8
2024-05-21 08:28:48,158:WARNING: 	 transformer_layers: 12
2024-05-21 08:28:48,158:WARNING: 	 cut_top_layer: 0
2024-05-21 08:28:49,166:WARNING: 	 sim_type: seqTransf
2024-05-21 08:28:53,648:INFO: --------------------
2024-05-21 08:28:53,648:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-21 08:29:35,391:INFO: device: cuda:0 n_gpu: 1
2024-05-21 08:29:35,391:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-21 08:29:35,632:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-21 08:29:35,632:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-21 08:29:35,633:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-21 08:29:35,633:WARNING: 	 embed_dim: 512
2024-05-21 08:29:35,633:WARNING: 	 image_resolution: 224
2024-05-21 08:29:35,633:WARNING: 	 vision_layers: 12
2024-05-21 08:29:35,633:WARNING: 	 vision_width: 768
2024-05-21 08:29:35,633:WARNING: 	 vision_patch_size: 32
2024-05-21 08:29:35,633:WARNING: 	 context_length: 77
2024-05-21 08:29:35,633:WARNING: 	 vocab_size: 49408
2024-05-21 08:29:35,633:WARNING: 	 transformer_width: 512
2024-05-21 08:29:35,633:WARNING: 	 transformer_heads: 8
2024-05-21 08:29:35,633:WARNING: 	 transformer_layers: 12
2024-05-21 08:29:35,633:WARNING: 	 cut_top_layer: 0
2024-05-21 08:29:36,633:WARNING: 	 sim_type: seqTransf
2024-05-21 08:29:41,118:INFO: --------------------
2024-05-21 08:29:41,118:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-21 08:30:42,864:INFO: device: cuda:0 n_gpu: 1
2024-05-21 08:30:42,864:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-21 08:30:43,107:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-21 08:30:43,108:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-21 08:30:43,108:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-21 08:30:43,108:WARNING: 	 embed_dim: 512
2024-05-21 08:30:43,108:WARNING: 	 image_resolution: 224
2024-05-21 08:30:43,108:WARNING: 	 vision_layers: 12
2024-05-21 08:30:43,108:WARNING: 	 vision_width: 768
2024-05-21 08:30:43,108:WARNING: 	 vision_patch_size: 32
2024-05-21 08:30:43,108:WARNING: 	 context_length: 77
2024-05-21 08:30:43,108:WARNING: 	 vocab_size: 49408
2024-05-21 08:30:43,108:WARNING: 	 transformer_width: 512
2024-05-21 08:30:43,108:WARNING: 	 transformer_heads: 8
2024-05-21 08:30:43,108:WARNING: 	 transformer_layers: 12
2024-05-21 08:30:43,108:WARNING: 	 cut_top_layer: 0
2024-05-21 08:30:44,108:WARNING: 	 sim_type: seqTransf
2024-05-21 08:30:48,605:INFO: --------------------
2024-05-21 08:30:48,605:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-21 08:31:58,423:INFO: device: cuda:0 n_gpu: 1
2024-05-21 08:31:58,423:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-21 08:31:58,667:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-21 08:31:58,667:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-21 08:31:58,667:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-21 08:31:58,667:WARNING: 	 embed_dim: 512
2024-05-21 08:31:58,667:WARNING: 	 image_resolution: 224
2024-05-21 08:31:58,667:WARNING: 	 vision_layers: 12
2024-05-21 08:31:58,667:WARNING: 	 vision_width: 768
2024-05-21 08:31:58,667:WARNING: 	 vision_patch_size: 32
2024-05-21 08:31:58,667:WARNING: 	 context_length: 77
2024-05-21 08:31:58,667:WARNING: 	 vocab_size: 49408
2024-05-21 08:31:58,667:WARNING: 	 transformer_width: 512
2024-05-21 08:31:58,667:WARNING: 	 transformer_heads: 8
2024-05-21 08:31:58,667:WARNING: 	 transformer_layers: 12
2024-05-21 08:31:58,667:WARNING: 	 cut_top_layer: 0
2024-05-21 08:31:59,671:WARNING: 	 sim_type: seqTransf
2024-05-21 08:32:04,160:INFO: --------------------
2024-05-21 08:32:04,160:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-21 08:32:35,763:INFO: device: cuda:0 n_gpu: 1
2024-05-21 08:32:35,763:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-21 08:32:36,018:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-21 08:32:36,019:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-21 08:32:36,020:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-21 08:32:36,020:WARNING: 	 embed_dim: 512
2024-05-21 08:32:36,020:WARNING: 	 image_resolution: 224
2024-05-21 08:32:36,021:WARNING: 	 vision_layers: 12
2024-05-21 08:32:36,021:WARNING: 	 vision_width: 768
2024-05-21 08:32:36,021:WARNING: 	 vision_patch_size: 32
2024-05-21 08:32:36,021:WARNING: 	 context_length: 77
2024-05-21 08:32:36,021:WARNING: 	 vocab_size: 49408
2024-05-21 08:32:36,021:WARNING: 	 transformer_width: 512
2024-05-21 08:32:36,021:WARNING: 	 transformer_heads: 8
2024-05-21 08:32:36,021:WARNING: 	 transformer_layers: 12
2024-05-21 08:32:36,021:WARNING: 	 cut_top_layer: 0
2024-05-21 08:32:37,054:WARNING: 	 sim_type: seqTransf
2024-05-21 08:32:41,555:INFO: --------------------
2024-05-21 08:32:41,556:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-21 08:34:35,965:INFO: device: cuda:0 n_gpu: 1
2024-05-21 08:34:35,965:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-21 08:34:36,204:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-21 08:34:36,205:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-21 08:34:36,205:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-21 08:34:36,205:WARNING: 	 embed_dim: 512
2024-05-21 08:34:36,205:WARNING: 	 image_resolution: 224
2024-05-21 08:34:36,205:WARNING: 	 vision_layers: 12
2024-05-21 08:34:36,205:WARNING: 	 vision_width: 768
2024-05-21 08:34:36,205:WARNING: 	 vision_patch_size: 32
2024-05-21 08:34:36,205:WARNING: 	 context_length: 77
2024-05-21 08:34:36,205:WARNING: 	 vocab_size: 49408
2024-05-21 08:34:36,205:WARNING: 	 transformer_width: 512
2024-05-21 08:34:36,205:WARNING: 	 transformer_heads: 8
2024-05-21 08:34:36,205:WARNING: 	 transformer_layers: 12
2024-05-21 08:34:36,205:WARNING: 	 cut_top_layer: 0
2024-05-21 08:34:37,195:WARNING: 	 sim_type: seqTransf
2024-05-21 08:34:41,674:INFO: --------------------
2024-05-21 08:34:41,674:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-21 08:35:11,097:INFO: device: cuda:0 n_gpu: 1
2024-05-21 08:35:11,097:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-21 08:35:11,335:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-21 08:35:11,335:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-21 08:35:11,335:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-21 08:35:11,335:WARNING: 	 embed_dim: 512
2024-05-21 08:35:11,335:WARNING: 	 image_resolution: 224
2024-05-21 08:35:11,335:WARNING: 	 vision_layers: 12
2024-05-21 08:35:11,335:WARNING: 	 vision_width: 768
2024-05-21 08:35:11,335:WARNING: 	 vision_patch_size: 32
2024-05-21 08:35:11,335:WARNING: 	 context_length: 77
2024-05-21 08:35:11,336:WARNING: 	 vocab_size: 49408
2024-05-21 08:35:11,336:WARNING: 	 transformer_width: 512
2024-05-21 08:35:11,336:WARNING: 	 transformer_heads: 8
2024-05-21 08:35:11,336:WARNING: 	 transformer_layers: 12
2024-05-21 08:35:11,336:WARNING: 	 cut_top_layer: 0
2024-05-21 08:35:12,330:WARNING: 	 sim_type: seqTransf
2024-05-21 08:35:16,807:INFO: --------------------
2024-05-21 08:35:16,807:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-21 08:35:36,587:INFO: device: cuda:0 n_gpu: 1
2024-05-21 08:35:36,588:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-21 08:35:36,832:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-21 08:35:36,833:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-21 08:35:36,833:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-21 08:35:36,834:WARNING: 	 embed_dim: 512
2024-05-21 08:35:36,834:WARNING: 	 image_resolution: 224
2024-05-21 08:35:36,834:WARNING: 	 vision_layers: 12
2024-05-21 08:35:36,834:WARNING: 	 vision_width: 768
2024-05-21 08:35:36,834:WARNING: 	 vision_patch_size: 32
2024-05-21 08:35:36,834:WARNING: 	 context_length: 77
2024-05-21 08:35:36,834:WARNING: 	 vocab_size: 49408
2024-05-21 08:35:36,834:WARNING: 	 transformer_width: 512
2024-05-21 08:35:36,834:WARNING: 	 transformer_heads: 8
2024-05-21 08:35:36,834:WARNING: 	 transformer_layers: 12
2024-05-21 08:35:36,835:WARNING: 	 cut_top_layer: 0
2024-05-21 08:35:37,846:WARNING: 	 sim_type: seqTransf
2024-05-21 08:35:42,342:INFO: --------------------
2024-05-21 08:35:42,342:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-21 08:38:02,997:INFO: device: cuda:0 n_gpu: 1
2024-05-21 08:38:02,998:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-21 08:38:03,244:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-21 08:38:03,244:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-21 08:38:03,244:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-21 08:38:03,244:WARNING: 	 embed_dim: 512
2024-05-21 08:38:03,244:WARNING: 	 image_resolution: 224
2024-05-21 08:38:03,244:WARNING: 	 vision_layers: 12
2024-05-21 08:38:03,244:WARNING: 	 vision_width: 768
2024-05-21 08:38:03,244:WARNING: 	 vision_patch_size: 32
2024-05-21 08:38:03,244:WARNING: 	 context_length: 77
2024-05-21 08:38:03,245:WARNING: 	 vocab_size: 49408
2024-05-21 08:38:03,245:WARNING: 	 transformer_width: 512
2024-05-21 08:38:03,245:WARNING: 	 transformer_heads: 8
2024-05-21 08:38:03,245:WARNING: 	 transformer_layers: 12
2024-05-21 08:38:03,245:WARNING: 	 cut_top_layer: 0
2024-05-21 08:38:04,249:WARNING: 	 sim_type: seqTransf
2024-05-21 08:38:08,755:INFO: --------------------
2024-05-21 08:38:08,755:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-21 08:38:46,738:INFO: device: cuda:0 n_gpu: 1
2024-05-21 08:38:46,739:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-21 08:38:46,990:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-21 08:38:46,991:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-21 08:38:46,991:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-21 08:38:46,992:WARNING: 	 embed_dim: 512
2024-05-21 08:38:46,992:WARNING: 	 image_resolution: 224
2024-05-21 08:38:46,992:WARNING: 	 vision_layers: 12
2024-05-21 08:38:46,992:WARNING: 	 vision_width: 768
2024-05-21 08:38:46,992:WARNING: 	 vision_patch_size: 32
2024-05-21 08:38:46,992:WARNING: 	 context_length: 77
2024-05-21 08:38:46,992:WARNING: 	 vocab_size: 49408
2024-05-21 08:38:46,993:WARNING: 	 transformer_width: 512
2024-05-21 08:38:46,993:WARNING: 	 transformer_heads: 8
2024-05-21 08:38:46,993:WARNING: 	 transformer_layers: 12
2024-05-21 08:38:46,993:WARNING: 	 cut_top_layer: 0
2024-05-21 08:38:48,004:WARNING: 	 sim_type: seqTransf
2024-05-21 08:38:52,491:INFO: --------------------
2024-05-21 08:38:52,491:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-21 08:39:40,973:INFO: device: cuda:0 n_gpu: 1
2024-05-21 08:39:40,973:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-21 08:39:41,214:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-21 08:39:41,214:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-21 08:39:41,215:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-21 08:39:41,215:WARNING: 	 embed_dim: 512
2024-05-21 08:39:41,215:WARNING: 	 image_resolution: 224
2024-05-21 08:39:41,215:WARNING: 	 vision_layers: 12
2024-05-21 08:39:41,215:WARNING: 	 vision_width: 768
2024-05-21 08:39:41,215:WARNING: 	 vision_patch_size: 32
2024-05-21 08:39:41,215:WARNING: 	 context_length: 77
2024-05-21 08:39:41,215:WARNING: 	 vocab_size: 49408
2024-05-21 08:39:41,215:WARNING: 	 transformer_width: 512
2024-05-21 08:39:41,215:WARNING: 	 transformer_heads: 8
2024-05-21 08:39:41,215:WARNING: 	 transformer_layers: 12
2024-05-21 08:39:41,215:WARNING: 	 cut_top_layer: 0
2024-05-21 08:39:42,221:WARNING: 	 sim_type: seqTransf
2024-05-21 08:39:46,700:INFO: --------------------
2024-05-21 08:39:46,701:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-21 08:40:10,598:INFO: device: cuda:0 n_gpu: 1
2024-05-21 08:40:10,598:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-21 08:40:10,848:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-21 08:40:10,849:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-21 08:40:10,849:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-21 08:40:10,850:WARNING: 	 embed_dim: 512
2024-05-21 08:40:10,850:WARNING: 	 image_resolution: 224
2024-05-21 08:40:10,850:WARNING: 	 vision_layers: 12
2024-05-21 08:40:10,850:WARNING: 	 vision_width: 768
2024-05-21 08:40:10,850:WARNING: 	 vision_patch_size: 32
2024-05-21 08:40:10,850:WARNING: 	 context_length: 77
2024-05-21 08:40:10,851:WARNING: 	 vocab_size: 49408
2024-05-21 08:40:10,851:WARNING: 	 transformer_width: 512
2024-05-21 08:40:10,851:WARNING: 	 transformer_heads: 8
2024-05-21 08:40:10,851:WARNING: 	 transformer_layers: 12
2024-05-21 08:40:10,851:WARNING: 	 cut_top_layer: 0
2024-05-21 08:40:11,873:WARNING: 	 sim_type: seqTransf
2024-05-21 08:40:16,393:INFO: --------------------
2024-05-21 08:40:16,393:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-21 08:42:34,817:INFO: device: cuda:0 n_gpu: 1
2024-05-21 08:42:34,817:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-21 08:42:35,060:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-21 08:42:35,060:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-21 08:42:35,060:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-21 08:42:35,060:WARNING: 	 embed_dim: 512
2024-05-21 08:42:35,060:WARNING: 	 image_resolution: 224
2024-05-21 08:42:35,060:WARNING: 	 vision_layers: 12
2024-05-21 08:42:35,060:WARNING: 	 vision_width: 768
2024-05-21 08:42:35,061:WARNING: 	 vision_patch_size: 32
2024-05-21 08:42:35,061:WARNING: 	 context_length: 77
2024-05-21 08:42:35,061:WARNING: 	 vocab_size: 49408
2024-05-21 08:42:35,061:WARNING: 	 transformer_width: 512
2024-05-21 08:42:35,061:WARNING: 	 transformer_heads: 8
2024-05-21 08:42:35,061:WARNING: 	 transformer_layers: 12
2024-05-21 08:42:35,061:WARNING: 	 cut_top_layer: 0
2024-05-21 08:42:36,067:WARNING: 	 sim_type: seqTransf
2024-05-21 08:42:40,571:INFO: --------------------
2024-05-21 08:42:40,572:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-21 08:42:57,561:INFO: device: cuda:0 n_gpu: 1
2024-05-21 08:42:57,561:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-21 08:42:57,811:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-21 08:42:57,813:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-21 08:42:57,813:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-21 08:42:57,813:WARNING: 	 embed_dim: 512
2024-05-21 08:42:57,814:WARNING: 	 image_resolution: 224
2024-05-21 08:42:57,814:WARNING: 	 vision_layers: 12
2024-05-21 08:42:57,814:WARNING: 	 vision_width: 768
2024-05-21 08:42:57,814:WARNING: 	 vision_patch_size: 32
2024-05-21 08:42:57,814:WARNING: 	 context_length: 77
2024-05-21 08:42:57,814:WARNING: 	 vocab_size: 49408
2024-05-21 08:42:57,814:WARNING: 	 transformer_width: 512
2024-05-21 08:42:57,814:WARNING: 	 transformer_heads: 8
2024-05-21 08:42:57,814:WARNING: 	 transformer_layers: 12
2024-05-21 08:42:57,814:WARNING: 	 cut_top_layer: 0
2024-05-21 08:42:58,825:WARNING: 	 sim_type: seqTransf
2024-05-21 08:43:03,332:INFO: --------------------
2024-05-21 08:43:03,332:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-21 08:45:01,161:INFO: device: cuda:0 n_gpu: 1
2024-05-21 08:45:01,161:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-21 08:45:01,402:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-21 08:45:01,402:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-21 08:45:01,402:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-21 08:45:01,402:WARNING: 	 embed_dim: 512
2024-05-21 08:45:01,402:WARNING: 	 image_resolution: 224
2024-05-21 08:45:01,402:WARNING: 	 vision_layers: 12
2024-05-21 08:45:01,402:WARNING: 	 vision_width: 768
2024-05-21 08:45:01,402:WARNING: 	 vision_patch_size: 32
2024-05-21 08:45:01,402:WARNING: 	 context_length: 77
2024-05-21 08:45:01,402:WARNING: 	 vocab_size: 49408
2024-05-21 08:45:01,402:WARNING: 	 transformer_width: 512
2024-05-21 08:45:01,402:WARNING: 	 transformer_heads: 8
2024-05-21 08:45:01,402:WARNING: 	 transformer_layers: 12
2024-05-21 08:45:01,402:WARNING: 	 cut_top_layer: 0
2024-05-21 08:45:02,404:WARNING: 	 sim_type: seqTransf
2024-05-21 08:45:06,891:INFO: --------------------
2024-05-21 08:45:06,891:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-21 08:45:44,863:INFO: device: cuda:0 n_gpu: 1
2024-05-21 08:45:44,863:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-21 08:45:45,103:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-21 08:45:45,103:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-21 08:45:45,104:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-21 08:45:45,104:WARNING: 	 embed_dim: 512
2024-05-21 08:45:45,104:WARNING: 	 image_resolution: 224
2024-05-21 08:45:45,104:WARNING: 	 vision_layers: 12
2024-05-21 08:45:45,104:WARNING: 	 vision_width: 768
2024-05-21 08:45:45,104:WARNING: 	 vision_patch_size: 32
2024-05-21 08:45:45,104:WARNING: 	 context_length: 77
2024-05-21 08:45:45,104:WARNING: 	 vocab_size: 49408
2024-05-21 08:45:45,104:WARNING: 	 transformer_width: 512
2024-05-21 08:45:45,104:WARNING: 	 transformer_heads: 8
2024-05-21 08:45:45,104:WARNING: 	 transformer_layers: 12
2024-05-21 08:45:45,104:WARNING: 	 cut_top_layer: 0
2024-05-21 08:45:46,100:WARNING: 	 sim_type: seqTransf
2024-05-21 08:45:50,566:INFO: --------------------
2024-05-21 08:45:50,566:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-21 08:47:05,421:INFO: device: cuda:0 n_gpu: 1
2024-05-21 08:47:05,421:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-21 08:47:05,664:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-21 08:47:05,664:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-21 08:47:05,664:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-21 08:47:05,664:WARNING: 	 embed_dim: 512
2024-05-21 08:47:05,664:WARNING: 	 image_resolution: 224
2024-05-21 08:47:05,664:WARNING: 	 vision_layers: 12
2024-05-21 08:47:05,664:WARNING: 	 vision_width: 768
2024-05-21 08:47:05,664:WARNING: 	 vision_patch_size: 32
2024-05-21 08:47:05,664:WARNING: 	 context_length: 77
2024-05-21 08:47:05,664:WARNING: 	 vocab_size: 49408
2024-05-21 08:47:05,664:WARNING: 	 transformer_width: 512
2024-05-21 08:47:05,664:WARNING: 	 transformer_heads: 8
2024-05-21 08:47:05,664:WARNING: 	 transformer_layers: 12
2024-05-21 08:47:05,664:WARNING: 	 cut_top_layer: 0
2024-05-21 08:47:06,664:WARNING: 	 sim_type: seqTransf
2024-05-21 08:47:11,158:INFO: --------------------
2024-05-21 08:47:11,158:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-21 08:47:52,050:INFO: device: cuda:0 n_gpu: 1
2024-05-21 08:47:52,050:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-21 08:47:52,299:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-21 08:47:52,300:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-21 08:47:52,300:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-21 08:47:52,301:WARNING: 	 embed_dim: 512
2024-05-21 08:47:52,301:WARNING: 	 image_resolution: 224
2024-05-21 08:47:52,301:WARNING: 	 vision_layers: 12
2024-05-21 08:47:52,301:WARNING: 	 vision_width: 768
2024-05-21 08:47:52,301:WARNING: 	 vision_patch_size: 32
2024-05-21 08:47:52,302:WARNING: 	 context_length: 77
2024-05-21 08:47:52,302:WARNING: 	 vocab_size: 49408
2024-05-21 08:47:52,302:WARNING: 	 transformer_width: 512
2024-05-21 08:47:52,302:WARNING: 	 transformer_heads: 8
2024-05-21 08:47:52,302:WARNING: 	 transformer_layers: 12
2024-05-21 08:47:52,302:WARNING: 	 cut_top_layer: 0
2024-05-21 08:47:53,335:WARNING: 	 sim_type: seqTransf
2024-05-21 08:47:57,853:INFO: --------------------
2024-05-21 08:47:57,853:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-21 08:59:13,840:INFO: device: cuda:0 n_gpu: 1
2024-05-21 08:59:13,840:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-21 08:59:14,088:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-21 08:59:14,089:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-21 08:59:14,089:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-21 08:59:14,090:WARNING: 	 embed_dim: 512
2024-05-21 08:59:14,090:WARNING: 	 image_resolution: 224
2024-05-21 08:59:14,090:WARNING: 	 vision_layers: 12
2024-05-21 08:59:14,090:WARNING: 	 vision_width: 768
2024-05-21 08:59:14,090:WARNING: 	 vision_patch_size: 32
2024-05-21 08:59:14,090:WARNING: 	 context_length: 77
2024-05-21 08:59:14,090:WARNING: 	 vocab_size: 49408
2024-05-21 08:59:14,090:WARNING: 	 transformer_width: 512
2024-05-21 08:59:14,091:WARNING: 	 transformer_heads: 8
2024-05-21 08:59:14,091:WARNING: 	 transformer_layers: 12
2024-05-21 08:59:14,091:WARNING: 	 cut_top_layer: 0
2024-05-21 08:59:15,112:WARNING: 	 sim_type: seqTransf
2024-05-21 08:59:19,621:INFO: --------------------
2024-05-21 08:59:19,621:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-21 09:00:57,070:INFO: device: cuda:0 n_gpu: 1
2024-05-21 09:00:57,071:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-21 09:00:57,318:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-21 09:00:57,320:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-21 09:00:57,320:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-21 09:00:57,321:WARNING: 	 embed_dim: 512
2024-05-21 09:00:57,321:WARNING: 	 image_resolution: 224
2024-05-21 09:00:57,321:WARNING: 	 vision_layers: 12
2024-05-21 09:00:57,321:WARNING: 	 vision_width: 768
2024-05-21 09:00:57,321:WARNING: 	 vision_patch_size: 32
2024-05-21 09:00:57,321:WARNING: 	 context_length: 77
2024-05-21 09:00:57,321:WARNING: 	 vocab_size: 49408
2024-05-21 09:00:57,321:WARNING: 	 transformer_width: 512
2024-05-21 09:00:57,321:WARNING: 	 transformer_heads: 8
2024-05-21 09:00:57,321:WARNING: 	 transformer_layers: 12
2024-05-21 09:00:57,321:WARNING: 	 cut_top_layer: 0
2024-05-21 09:00:58,333:WARNING: 	 sim_type: seqTransf
2024-05-21 09:01:02,797:INFO: --------------------
2024-05-21 09:01:02,797:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-21 09:04:05,175:INFO: device: cuda:0 n_gpu: 1
2024-05-21 09:04:05,176:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-21 09:04:05,428:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-21 09:04:05,430:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-21 09:04:05,430:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-21 09:04:05,431:WARNING: 	 embed_dim: 512
2024-05-21 09:04:05,431:WARNING: 	 image_resolution: 224
2024-05-21 09:04:05,431:WARNING: 	 vision_layers: 12
2024-05-21 09:04:05,431:WARNING: 	 vision_width: 768
2024-05-21 09:04:05,431:WARNING: 	 vision_patch_size: 32
2024-05-21 09:04:05,431:WARNING: 	 context_length: 77
2024-05-21 09:04:05,431:WARNING: 	 vocab_size: 49408
2024-05-21 09:04:05,431:WARNING: 	 transformer_width: 512
2024-05-21 09:04:05,431:WARNING: 	 transformer_heads: 8
2024-05-21 09:04:05,431:WARNING: 	 transformer_layers: 12
2024-05-21 09:04:05,431:WARNING: 	 cut_top_layer: 0
2024-05-21 09:04:06,480:WARNING: 	 sim_type: seqTransf
2024-05-21 09:04:11,004:INFO: --------------------
2024-05-21 09:04:11,005:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-21 09:04:36,054:INFO: device: cuda:0 n_gpu: 1
2024-05-21 09:04:36,054:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-21 09:04:36,307:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-21 09:04:36,308:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-21 09:04:36,308:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-21 09:04:36,309:WARNING: 	 embed_dim: 512
2024-05-21 09:04:36,309:WARNING: 	 image_resolution: 224
2024-05-21 09:04:36,310:WARNING: 	 vision_layers: 12
2024-05-21 09:04:36,310:WARNING: 	 vision_width: 768
2024-05-21 09:04:36,310:WARNING: 	 vision_patch_size: 32
2024-05-21 09:04:36,310:WARNING: 	 context_length: 77
2024-05-21 09:04:36,310:WARNING: 	 vocab_size: 49408
2024-05-21 09:04:36,310:WARNING: 	 transformer_width: 512
2024-05-21 09:04:36,310:WARNING: 	 transformer_heads: 8
2024-05-21 09:04:36,310:WARNING: 	 transformer_layers: 12
2024-05-21 09:04:36,310:WARNING: 	 cut_top_layer: 0
2024-05-21 09:04:37,339:WARNING: 	 sim_type: seqTransf
2024-05-21 09:04:41,843:INFO: --------------------
2024-05-21 09:04:41,843:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-21 09:07:53,942:INFO: device: cuda:0 n_gpu: 1
2024-05-21 09:07:53,942:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-21 09:07:54,195:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-21 09:07:54,197:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-21 09:07:54,197:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-21 09:07:54,198:WARNING: 	 embed_dim: 512
2024-05-21 09:07:54,198:WARNING: 	 image_resolution: 224
2024-05-21 09:07:54,198:WARNING: 	 vision_layers: 12
2024-05-21 09:07:54,198:WARNING: 	 vision_width: 768
2024-05-21 09:07:54,198:WARNING: 	 vision_patch_size: 32
2024-05-21 09:07:54,198:WARNING: 	 context_length: 77
2024-05-21 09:07:54,198:WARNING: 	 vocab_size: 49408
2024-05-21 09:07:54,198:WARNING: 	 transformer_width: 512
2024-05-21 09:07:54,198:WARNING: 	 transformer_heads: 8
2024-05-21 09:07:54,198:WARNING: 	 transformer_layers: 12
2024-05-21 09:07:54,198:WARNING: 	 cut_top_layer: 0
2024-05-21 09:07:55,229:WARNING: 	 sim_type: seqTransf
2024-05-21 09:07:59,734:INFO: --------------------
2024-05-21 09:07:59,735:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-21 09:09:08,322:INFO: device: cuda:0 n_gpu: 1
2024-05-21 09:09:08,322:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-21 09:09:08,580:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-21 09:09:08,581:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-21 09:09:08,581:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-21 09:09:08,582:WARNING: 	 embed_dim: 512
2024-05-21 09:09:08,582:WARNING: 	 image_resolution: 224
2024-05-21 09:09:08,582:WARNING: 	 vision_layers: 12
2024-05-21 09:09:08,582:WARNING: 	 vision_width: 768
2024-05-21 09:09:08,582:WARNING: 	 vision_patch_size: 32
2024-05-21 09:09:08,582:WARNING: 	 context_length: 77
2024-05-21 09:09:08,583:WARNING: 	 vocab_size: 49408
2024-05-21 09:09:08,583:WARNING: 	 transformer_width: 512
2024-05-21 09:09:08,583:WARNING: 	 transformer_heads: 8
2024-05-21 09:09:08,583:WARNING: 	 transformer_layers: 12
2024-05-21 09:09:08,583:WARNING: 	 cut_top_layer: 0
2024-05-21 09:09:09,626:WARNING: 	 sim_type: seqTransf
2024-05-21 09:09:14,162:INFO: --------------------
2024-05-21 09:09:14,162:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-21 09:09:57,362:INFO: device: cuda:0 n_gpu: 1
2024-05-21 09:09:57,363:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-21 09:09:57,616:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-21 09:09:57,617:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-21 09:09:57,617:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-21 09:09:57,618:WARNING: 	 embed_dim: 512
2024-05-21 09:09:57,618:WARNING: 	 image_resolution: 224
2024-05-21 09:09:57,618:WARNING: 	 vision_layers: 12
2024-05-21 09:09:57,618:WARNING: 	 vision_width: 768
2024-05-21 09:09:57,618:WARNING: 	 vision_patch_size: 32
2024-05-21 09:09:57,619:WARNING: 	 context_length: 77
2024-05-21 09:09:57,619:WARNING: 	 vocab_size: 49408
2024-05-21 09:09:57,619:WARNING: 	 transformer_width: 512
2024-05-21 09:09:57,619:WARNING: 	 transformer_heads: 8
2024-05-21 09:09:57,619:WARNING: 	 transformer_layers: 12
2024-05-21 09:09:57,619:WARNING: 	 cut_top_layer: 0
2024-05-21 09:09:58,646:WARNING: 	 sim_type: seqTransf
2024-05-21 09:10:03,157:INFO: --------------------
2024-05-21 09:10:03,157:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-21 09:11:44,706:INFO: device: cuda:0 n_gpu: 1
2024-05-21 09:11:44,707:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-21 09:11:44,957:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-21 09:11:44,958:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-21 09:11:44,958:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-21 09:11:44,959:WARNING: 	 embed_dim: 512
2024-05-21 09:11:44,959:WARNING: 	 image_resolution: 224
2024-05-21 09:11:44,959:WARNING: 	 vision_layers: 12
2024-05-21 09:11:44,959:WARNING: 	 vision_width: 768
2024-05-21 09:11:44,959:WARNING: 	 vision_patch_size: 32
2024-05-21 09:11:44,959:WARNING: 	 context_length: 77
2024-05-21 09:11:44,959:WARNING: 	 vocab_size: 49408
2024-05-21 09:11:44,959:WARNING: 	 transformer_width: 512
2024-05-21 09:11:44,959:WARNING: 	 transformer_heads: 8
2024-05-21 09:11:44,960:WARNING: 	 transformer_layers: 12
2024-05-21 09:11:44,960:WARNING: 	 cut_top_layer: 0
2024-05-21 09:11:45,974:WARNING: 	 sim_type: seqTransf
2024-05-21 09:11:50,465:INFO: --------------------
2024-05-21 09:11:50,465:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-21 09:12:44,611:INFO: device: cuda:0 n_gpu: 1
2024-05-21 09:12:44,611:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-21 09:12:44,866:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-21 09:12:44,867:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-21 09:12:44,868:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-21 09:12:44,868:WARNING: 	 embed_dim: 512
2024-05-21 09:12:44,869:WARNING: 	 image_resolution: 224
2024-05-21 09:12:44,869:WARNING: 	 vision_layers: 12
2024-05-21 09:12:44,869:WARNING: 	 vision_width: 768
2024-05-21 09:12:44,869:WARNING: 	 vision_patch_size: 32
2024-05-21 09:12:44,869:WARNING: 	 context_length: 77
2024-05-21 09:12:44,869:WARNING: 	 vocab_size: 49408
2024-05-21 09:12:44,869:WARNING: 	 transformer_width: 512
2024-05-21 09:12:44,869:WARNING: 	 transformer_heads: 8
2024-05-21 09:12:44,869:WARNING: 	 transformer_layers: 12
2024-05-21 09:12:44,869:WARNING: 	 cut_top_layer: 0
2024-05-21 09:12:45,904:WARNING: 	 sim_type: seqTransf
2024-05-21 09:12:50,401:INFO: --------------------
2024-05-21 09:12:50,401:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-21 09:14:15,542:INFO: device: cuda:0 n_gpu: 1
2024-05-21 09:14:15,542:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-21 09:14:15,793:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-21 09:14:15,794:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-21 09:14:15,794:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-21 09:14:15,795:WARNING: 	 embed_dim: 512
2024-05-21 09:14:15,795:WARNING: 	 image_resolution: 224
2024-05-21 09:14:15,795:WARNING: 	 vision_layers: 12
2024-05-21 09:14:15,795:WARNING: 	 vision_width: 768
2024-05-21 09:14:15,795:WARNING: 	 vision_patch_size: 32
2024-05-21 09:14:15,795:WARNING: 	 context_length: 77
2024-05-21 09:14:15,795:WARNING: 	 vocab_size: 49408
2024-05-21 09:14:15,795:WARNING: 	 transformer_width: 512
2024-05-21 09:14:15,795:WARNING: 	 transformer_heads: 8
2024-05-21 09:14:15,796:WARNING: 	 transformer_layers: 12
2024-05-21 09:14:15,796:WARNING: 	 cut_top_layer: 0
2024-05-21 09:14:16,818:WARNING: 	 sim_type: seqTransf
2024-05-21 09:14:21,319:INFO: --------------------
2024-05-21 09:14:21,320:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-21 09:15:12,695:INFO: device: cuda:0 n_gpu: 1
2024-05-21 09:15:12,696:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-21 09:15:12,944:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-21 09:15:12,946:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-21 09:15:12,946:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-21 09:15:12,947:WARNING: 	 embed_dim: 512
2024-05-21 09:15:12,947:WARNING: 	 image_resolution: 224
2024-05-21 09:15:12,947:WARNING: 	 vision_layers: 12
2024-05-21 09:15:12,947:WARNING: 	 vision_width: 768
2024-05-21 09:15:12,947:WARNING: 	 vision_patch_size: 32
2024-05-21 09:15:12,947:WARNING: 	 context_length: 77
2024-05-21 09:15:12,947:WARNING: 	 vocab_size: 49408
2024-05-21 09:15:12,947:WARNING: 	 transformer_width: 512
2024-05-21 09:15:12,947:WARNING: 	 transformer_heads: 8
2024-05-21 09:15:12,947:WARNING: 	 transformer_layers: 12
2024-05-21 09:15:12,947:WARNING: 	 cut_top_layer: 0
2024-05-21 09:15:13,957:WARNING: 	 sim_type: seqTransf
2024-05-21 09:15:18,476:INFO: --------------------
2024-05-21 09:15:18,477:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-21 09:16:26,446:INFO: device: cuda:0 n_gpu: 1
2024-05-21 09:16:26,446:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-21 09:16:26,698:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-21 09:16:26,699:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-21 09:16:26,699:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-21 09:16:26,700:WARNING: 	 embed_dim: 512
2024-05-21 09:16:26,700:WARNING: 	 image_resolution: 224
2024-05-21 09:16:26,700:WARNING: 	 vision_layers: 12
2024-05-21 09:16:26,700:WARNING: 	 vision_width: 768
2024-05-21 09:16:26,701:WARNING: 	 vision_patch_size: 32
2024-05-21 09:16:26,701:WARNING: 	 context_length: 77
2024-05-21 09:16:26,701:WARNING: 	 vocab_size: 49408
2024-05-21 09:16:26,701:WARNING: 	 transformer_width: 512
2024-05-21 09:16:26,701:WARNING: 	 transformer_heads: 8
2024-05-21 09:16:26,701:WARNING: 	 transformer_layers: 12
2024-05-21 09:16:26,701:WARNING: 	 cut_top_layer: 0
2024-05-21 09:16:27,727:WARNING: 	 sim_type: seqTransf
2024-05-21 09:16:32,234:INFO: --------------------
2024-05-21 09:16:32,234:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-21 09:18:00,314:INFO: device: cuda:0 n_gpu: 1
2024-05-21 09:18:00,314:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-21 09:18:00,565:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-21 09:18:00,566:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-21 09:18:00,566:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-21 09:18:00,567:WARNING: 	 embed_dim: 512
2024-05-21 09:18:00,567:WARNING: 	 image_resolution: 224
2024-05-21 09:18:00,567:WARNING: 	 vision_layers: 12
2024-05-21 09:18:00,568:WARNING: 	 vision_width: 768
2024-05-21 09:18:00,568:WARNING: 	 vision_patch_size: 32
2024-05-21 09:18:00,568:WARNING: 	 context_length: 77
2024-05-21 09:18:00,568:WARNING: 	 vocab_size: 49408
2024-05-21 09:18:00,568:WARNING: 	 transformer_width: 512
2024-05-21 09:18:00,568:WARNING: 	 transformer_heads: 8
2024-05-21 09:18:00,568:WARNING: 	 transformer_layers: 12
2024-05-21 09:18:00,568:WARNING: 	 cut_top_layer: 0
2024-05-21 09:18:01,584:WARNING: 	 sim_type: seqTransf
2024-05-21 09:18:06,082:INFO: --------------------
2024-05-21 09:18:06,082:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-21 09:19:08,118:INFO: device: cuda:0 n_gpu: 1
2024-05-21 09:19:08,118:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-21 09:19:08,371:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-21 09:19:08,372:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-21 09:19:08,373:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-21 09:19:08,374:WARNING: 	 embed_dim: 512
2024-05-21 09:19:08,374:WARNING: 	 image_resolution: 224
2024-05-21 09:19:08,374:WARNING: 	 vision_layers: 12
2024-05-21 09:19:08,374:WARNING: 	 vision_width: 768
2024-05-21 09:19:08,374:WARNING: 	 vision_patch_size: 32
2024-05-21 09:19:08,374:WARNING: 	 context_length: 77
2024-05-21 09:19:08,374:WARNING: 	 vocab_size: 49408
2024-05-21 09:19:08,374:WARNING: 	 transformer_width: 512
2024-05-21 09:19:08,374:WARNING: 	 transformer_heads: 8
2024-05-21 09:19:08,374:WARNING: 	 transformer_layers: 12
2024-05-21 09:19:08,374:WARNING: 	 cut_top_layer: 0
2024-05-21 09:19:09,411:WARNING: 	 sim_type: seqTransf
2024-05-21 09:19:13,995:INFO: --------------------
2024-05-21 09:19:13,995:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-21 09:20:35,215:INFO: device: cuda:0 n_gpu: 1
2024-05-21 09:20:35,216:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-21 09:20:35,469:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-21 09:20:35,470:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-21 09:20:35,470:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-21 09:20:35,471:WARNING: 	 embed_dim: 512
2024-05-21 09:20:35,471:WARNING: 	 image_resolution: 224
2024-05-21 09:20:35,471:WARNING: 	 vision_layers: 12
2024-05-21 09:20:35,471:WARNING: 	 vision_width: 768
2024-05-21 09:20:35,472:WARNING: 	 vision_patch_size: 32
2024-05-21 09:20:35,472:WARNING: 	 context_length: 77
2024-05-21 09:20:35,472:WARNING: 	 vocab_size: 49408
2024-05-21 09:20:35,472:WARNING: 	 transformer_width: 512
2024-05-21 09:20:35,472:WARNING: 	 transformer_heads: 8
2024-05-21 09:20:35,472:WARNING: 	 transformer_layers: 12
2024-05-21 09:20:35,472:WARNING: 	 cut_top_layer: 0
2024-05-21 09:20:36,493:WARNING: 	 sim_type: seqTransf
2024-05-21 09:20:41,018:INFO: --------------------
2024-05-21 09:20:41,018:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-21 09:21:08,266:INFO: device: cuda:0 n_gpu: 1
2024-05-21 09:21:08,266:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-21 09:21:08,518:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-21 09:21:08,519:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-21 09:21:08,519:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-21 09:21:08,520:WARNING: 	 embed_dim: 512
2024-05-21 09:21:08,520:WARNING: 	 image_resolution: 224
2024-05-21 09:21:08,520:WARNING: 	 vision_layers: 12
2024-05-21 09:21:08,520:WARNING: 	 vision_width: 768
2024-05-21 09:21:08,520:WARNING: 	 vision_patch_size: 32
2024-05-21 09:21:08,520:WARNING: 	 context_length: 77
2024-05-21 09:21:08,520:WARNING: 	 vocab_size: 49408
2024-05-21 09:21:08,521:WARNING: 	 transformer_width: 512
2024-05-21 09:21:08,521:WARNING: 	 transformer_heads: 8
2024-05-21 09:21:08,521:WARNING: 	 transformer_layers: 12
2024-05-21 09:21:08,521:WARNING: 	 cut_top_layer: 0
2024-05-21 09:21:09,550:WARNING: 	 sim_type: seqTransf
2024-05-21 09:21:14,037:INFO: --------------------
2024-05-21 09:21:14,037:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-21 09:22:24,603:INFO: device: cuda:0 n_gpu: 1
2024-05-21 09:22:24,603:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-21 09:22:24,856:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-21 09:22:24,857:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-21 09:22:24,858:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-21 09:22:24,858:WARNING: 	 embed_dim: 512
2024-05-21 09:22:24,858:WARNING: 	 image_resolution: 224
2024-05-21 09:22:24,859:WARNING: 	 vision_layers: 12
2024-05-21 09:22:24,859:WARNING: 	 vision_width: 768
2024-05-21 09:22:24,859:WARNING: 	 vision_patch_size: 32
2024-05-21 09:22:24,859:WARNING: 	 context_length: 77
2024-05-21 09:22:24,859:WARNING: 	 vocab_size: 49408
2024-05-21 09:22:24,859:WARNING: 	 transformer_width: 512
2024-05-21 09:22:24,859:WARNING: 	 transformer_heads: 8
2024-05-21 09:22:24,859:WARNING: 	 transformer_layers: 12
2024-05-21 09:22:24,859:WARNING: 	 cut_top_layer: 0
2024-05-21 09:22:25,883:WARNING: 	 sim_type: seqTransf
2024-05-21 09:22:30,389:INFO: --------------------
2024-05-21 09:22:30,389:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-21 09:29:24,125:INFO: device: cuda:0 n_gpu: 1
2024-05-21 09:29:24,126:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-21 09:29:24,371:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-21 09:29:24,372:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-21 09:29:24,372:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-21 09:29:24,372:WARNING: 	 embed_dim: 512
2024-05-21 09:29:24,372:WARNING: 	 image_resolution: 224
2024-05-21 09:29:24,372:WARNING: 	 vision_layers: 12
2024-05-21 09:29:24,372:WARNING: 	 vision_width: 768
2024-05-21 09:29:24,372:WARNING: 	 vision_patch_size: 32
2024-05-21 09:29:24,372:WARNING: 	 context_length: 77
2024-05-21 09:29:24,372:WARNING: 	 vocab_size: 49408
2024-05-21 09:29:24,372:WARNING: 	 transformer_width: 512
2024-05-21 09:29:24,372:WARNING: 	 transformer_heads: 8
2024-05-21 09:29:24,372:WARNING: 	 transformer_layers: 12
2024-05-21 09:29:24,372:WARNING: 	 cut_top_layer: 0
2024-05-21 09:29:25,377:WARNING: 	 sim_type: seqTransf
2024-05-21 09:29:29,859:INFO: --------------------
2024-05-21 09:29:29,859:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-21 09:33:03,505:INFO: device: cuda:0 n_gpu: 1
2024-05-21 09:33:03,505:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-21 09:33:03,751:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-21 09:33:03,751:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-21 09:33:03,751:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-21 09:33:03,751:WARNING: 	 embed_dim: 512
2024-05-21 09:33:03,751:WARNING: 	 image_resolution: 224
2024-05-21 09:33:03,751:WARNING: 	 vision_layers: 12
2024-05-21 09:33:03,751:WARNING: 	 vision_width: 768
2024-05-21 09:33:03,751:WARNING: 	 vision_patch_size: 32
2024-05-21 09:33:03,751:WARNING: 	 context_length: 77
2024-05-21 09:33:03,751:WARNING: 	 vocab_size: 49408
2024-05-21 09:33:03,751:WARNING: 	 transformer_width: 512
2024-05-21 09:33:03,751:WARNING: 	 transformer_heads: 8
2024-05-21 09:33:03,751:WARNING: 	 transformer_layers: 12
2024-05-21 09:33:03,751:WARNING: 	 cut_top_layer: 0
2024-05-21 09:33:04,754:WARNING: 	 sim_type: seqTransf
2024-05-21 09:33:09,235:INFO: --------------------
2024-05-21 09:33:09,236:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-21 11:23:31,598:INFO: device: cuda:0 n_gpu: 1
2024-05-21 11:23:31,599:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-21 11:23:31,819:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-21 11:23:31,819:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-21 11:23:31,819:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-21 11:23:31,819:WARNING: 	 embed_dim: 512
2024-05-21 11:23:31,819:WARNING: 	 image_resolution: 224
2024-05-21 11:23:31,819:WARNING: 	 vision_layers: 12
2024-05-21 11:23:31,819:WARNING: 	 vision_width: 768
2024-05-21 11:23:31,819:WARNING: 	 vision_patch_size: 32
2024-05-21 11:23:31,819:WARNING: 	 context_length: 77
2024-05-21 11:23:31,819:WARNING: 	 vocab_size: 49408
2024-05-21 11:23:31,819:WARNING: 	 transformer_width: 512
2024-05-21 11:23:31,819:WARNING: 	 transformer_heads: 8
2024-05-21 11:23:31,819:WARNING: 	 transformer_layers: 12
2024-05-21 11:23:31,819:WARNING: 	 cut_top_layer: 0
2024-05-21 11:23:32,690:WARNING: 	 sim_type: seqTransf
2024-05-21 11:23:40,934:INFO: device: cuda:0 n_gpu: 1
2024-05-21 11:23:40,934:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-21 11:23:41,144:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-21 11:23:41,145:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-21 11:23:41,145:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-21 11:23:41,145:WARNING: 	 embed_dim: 512
2024-05-21 11:23:41,145:WARNING: 	 image_resolution: 224
2024-05-21 11:23:41,145:WARNING: 	 vision_layers: 12
2024-05-21 11:23:41,145:WARNING: 	 vision_width: 768
2024-05-21 11:23:41,145:WARNING: 	 vision_patch_size: 32
2024-05-21 11:23:41,145:WARNING: 	 context_length: 77
2024-05-21 11:23:41,145:WARNING: 	 vocab_size: 49408
2024-05-21 11:23:41,145:WARNING: 	 transformer_width: 512
2024-05-21 11:23:41,145:WARNING: 	 transformer_heads: 8
2024-05-21 11:23:41,145:WARNING: 	 transformer_layers: 12
2024-05-21 11:23:41,145:WARNING: 	 cut_top_layer: 0
2024-05-21 11:23:42,050:WARNING: 	 sim_type: seqTransf
2024-05-21 11:23:45,924:INFO: --------------------
2024-05-21 11:23:45,924:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-21 11:26:02,226:INFO: device: cuda:0 n_gpu: 1
2024-05-21 11:26:02,227:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-21 11:26:02,440:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-21 11:26:02,441:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-21 11:26:02,441:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-21 11:26:02,441:WARNING: 	 embed_dim: 512
2024-05-21 11:26:02,441:WARNING: 	 image_resolution: 224
2024-05-21 11:26:02,441:WARNING: 	 vision_layers: 12
2024-05-21 11:26:02,441:WARNING: 	 vision_width: 768
2024-05-21 11:26:02,441:WARNING: 	 vision_patch_size: 32
2024-05-21 11:26:02,441:WARNING: 	 context_length: 77
2024-05-21 11:26:02,441:WARNING: 	 vocab_size: 49408
2024-05-21 11:26:02,441:WARNING: 	 transformer_width: 512
2024-05-21 11:26:02,441:WARNING: 	 transformer_heads: 8
2024-05-21 11:26:02,441:WARNING: 	 transformer_layers: 12
2024-05-21 11:26:02,441:WARNING: 	 cut_top_layer: 0
2024-05-21 11:26:03,304:WARNING: 	 sim_type: seqTransf
2024-05-21 11:26:07,182:INFO: --------------------
2024-05-21 11:26:07,182:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-21 13:19:49,811:INFO: device: cuda:0 n_gpu: 1
2024-05-21 13:19:49,811:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-21 13:19:50,022:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-21 13:19:50,022:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-21 13:19:50,022:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-21 13:19:50,022:WARNING: 	 embed_dim: 512
2024-05-21 13:19:50,022:WARNING: 	 image_resolution: 224
2024-05-21 13:19:50,022:WARNING: 	 vision_layers: 12
2024-05-21 13:19:50,022:WARNING: 	 vision_width: 768
2024-05-21 13:19:50,022:WARNING: 	 vision_patch_size: 32
2024-05-21 13:19:50,022:WARNING: 	 context_length: 77
2024-05-21 13:19:50,022:WARNING: 	 vocab_size: 49408
2024-05-21 13:19:50,022:WARNING: 	 transformer_width: 512
2024-05-21 13:19:50,022:WARNING: 	 transformer_heads: 8
2024-05-21 13:19:50,023:WARNING: 	 transformer_layers: 12
2024-05-21 13:19:50,023:WARNING: 	 cut_top_layer: 0
2024-05-21 13:19:50,855:WARNING: 	 sim_type: seqTransf
2024-05-21 13:19:54,618:INFO: --------------------
2024-05-21 13:19:54,619:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-21 13:20:22,837:INFO: device: cuda:0 n_gpu: 1
2024-05-21 13:20:22,837:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-21 13:20:23,042:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-21 13:20:23,043:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-21 13:20:23,043:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-21 13:20:23,043:WARNING: 	 embed_dim: 512
2024-05-21 13:20:23,043:WARNING: 	 image_resolution: 224
2024-05-21 13:20:23,043:WARNING: 	 vision_layers: 12
2024-05-21 13:20:23,043:WARNING: 	 vision_width: 768
2024-05-21 13:20:23,043:WARNING: 	 vision_patch_size: 32
2024-05-21 13:20:23,043:WARNING: 	 context_length: 77
2024-05-21 13:20:23,043:WARNING: 	 vocab_size: 49408
2024-05-21 13:20:23,043:WARNING: 	 transformer_width: 512
2024-05-21 13:20:23,043:WARNING: 	 transformer_heads: 8
2024-05-21 13:20:23,043:WARNING: 	 transformer_layers: 12
2024-05-21 13:20:23,043:WARNING: 	 cut_top_layer: 0
2024-05-21 13:20:23,891:WARNING: 	 sim_type: seqTransf
2024-05-21 13:20:27,673:INFO: --------------------
2024-05-21 13:20:27,673:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-21 13:20:58,852:INFO: device: cuda:0 n_gpu: 1
2024-05-21 13:20:58,852:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-21 13:20:59,059:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-21 13:20:59,059:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-21 13:20:59,060:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-21 13:20:59,060:WARNING: 	 embed_dim: 512
2024-05-21 13:20:59,060:WARNING: 	 image_resolution: 224
2024-05-21 13:20:59,060:WARNING: 	 vision_layers: 12
2024-05-21 13:20:59,060:WARNING: 	 vision_width: 768
2024-05-21 13:20:59,060:WARNING: 	 vision_patch_size: 32
2024-05-21 13:20:59,060:WARNING: 	 context_length: 77
2024-05-21 13:20:59,060:WARNING: 	 vocab_size: 49408
2024-05-21 13:20:59,060:WARNING: 	 transformer_width: 512
2024-05-21 13:20:59,060:WARNING: 	 transformer_heads: 8
2024-05-21 13:20:59,060:WARNING: 	 transformer_layers: 12
2024-05-21 13:20:59,060:WARNING: 	 cut_top_layer: 0
2024-05-21 13:20:59,906:WARNING: 	 sim_type: seqTransf
2024-05-21 13:21:03,685:INFO: --------------------
2024-05-21 13:21:03,686:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-21 13:22:19,913:INFO: device: cuda:0 n_gpu: 1
2024-05-21 13:22:19,914:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-21 13:22:20,139:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-21 13:22:20,140:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-21 13:22:20,140:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-21 13:22:20,141:WARNING: 	 embed_dim: 512
2024-05-21 13:22:20,141:WARNING: 	 image_resolution: 224
2024-05-21 13:22:20,141:WARNING: 	 vision_layers: 12
2024-05-21 13:22:20,141:WARNING: 	 vision_width: 768
2024-05-21 13:22:20,141:WARNING: 	 vision_patch_size: 32
2024-05-21 13:22:20,141:WARNING: 	 context_length: 77
2024-05-21 13:22:20,142:WARNING: 	 vocab_size: 49408
2024-05-21 13:22:20,142:WARNING: 	 transformer_width: 512
2024-05-21 13:22:20,142:WARNING: 	 transformer_heads: 8
2024-05-21 13:22:20,142:WARNING: 	 transformer_layers: 12
2024-05-21 13:22:20,142:WARNING: 	 cut_top_layer: 0
2024-05-21 13:22:21,012:WARNING: 	 sim_type: seqTransf
2024-05-21 13:22:24,813:INFO: --------------------
2024-05-21 13:22:24,813:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-21 13:23:18,069:INFO: device: cuda:0 n_gpu: 1
2024-05-21 13:23:18,069:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-21 13:23:18,300:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-21 13:23:18,300:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-21 13:23:18,300:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-21 13:23:18,300:WARNING: 	 embed_dim: 512
2024-05-21 13:23:18,300:WARNING: 	 image_resolution: 224
2024-05-21 13:23:18,300:WARNING: 	 vision_layers: 12
2024-05-21 13:23:18,300:WARNING: 	 vision_width: 768
2024-05-21 13:23:18,300:WARNING: 	 vision_patch_size: 32
2024-05-21 13:23:18,300:WARNING: 	 context_length: 77
2024-05-21 13:23:18,300:WARNING: 	 vocab_size: 49408
2024-05-21 13:23:18,300:WARNING: 	 transformer_width: 512
2024-05-21 13:23:18,300:WARNING: 	 transformer_heads: 8
2024-05-21 13:23:18,300:WARNING: 	 transformer_layers: 12
2024-05-21 13:23:18,300:WARNING: 	 cut_top_layer: 0
2024-05-21 13:23:19,229:WARNING: 	 sim_type: seqTransf
2024-05-21 13:23:23,137:INFO: --------------------
2024-05-21 13:23:23,138:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-21 13:24:23,186:INFO: device: cuda:0 n_gpu: 1
2024-05-21 13:24:23,187:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-21 13:24:23,417:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-21 13:24:23,418:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-21 13:24:23,418:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-21 13:24:23,419:WARNING: 	 embed_dim: 512
2024-05-21 13:24:23,419:WARNING: 	 image_resolution: 224
2024-05-21 13:24:23,419:WARNING: 	 vision_layers: 12
2024-05-21 13:24:23,419:WARNING: 	 vision_width: 768
2024-05-21 13:24:23,419:WARNING: 	 vision_patch_size: 32
2024-05-21 13:24:23,419:WARNING: 	 context_length: 77
2024-05-21 13:24:23,419:WARNING: 	 vocab_size: 49408
2024-05-21 13:24:23,419:WARNING: 	 transformer_width: 512
2024-05-21 13:24:23,419:WARNING: 	 transformer_heads: 8
2024-05-21 13:24:23,419:WARNING: 	 transformer_layers: 12
2024-05-21 13:24:23,419:WARNING: 	 cut_top_layer: 0
2024-05-21 13:24:24,304:WARNING: 	 sim_type: seqTransf
2024-05-21 13:24:28,153:INFO: --------------------
2024-05-21 13:24:28,154:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-21 13:28:56,566:INFO: device: cuda:0 n_gpu: 1
2024-05-21 13:28:56,566:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-21 13:28:57,476:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-21 13:28:57,477:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-21 13:28:57,477:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-21 13:28:57,477:WARNING: 	 embed_dim: 512
2024-05-21 13:28:57,477:WARNING: 	 image_resolution: 224
2024-05-21 13:28:57,477:WARNING: 	 vision_layers: 12
2024-05-21 13:28:57,477:WARNING: 	 vision_width: 768
2024-05-21 13:28:57,477:WARNING: 	 vision_patch_size: 32
2024-05-21 13:28:57,477:WARNING: 	 context_length: 77
2024-05-21 13:28:57,477:WARNING: 	 vocab_size: 49408
2024-05-21 13:28:57,477:WARNING: 	 transformer_width: 512
2024-05-21 13:28:57,477:WARNING: 	 transformer_heads: 8
2024-05-21 13:28:57,477:WARNING: 	 transformer_layers: 12
2024-05-21 13:28:57,477:WARNING: 	 cut_top_layer: 0
2024-05-21 13:28:58,398:WARNING: 	 sim_type: seqTransf
2024-05-21 13:29:02,287:INFO: --------------------
2024-05-21 13:29:02,287:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-21 13:30:11,958:INFO: device: cuda:0 n_gpu: 1
2024-05-21 13:30:11,958:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-21 13:30:12,202:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-21 13:30:12,203:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-21 13:30:12,203:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-21 13:30:12,204:WARNING: 	 embed_dim: 512
2024-05-21 13:30:12,204:WARNING: 	 image_resolution: 224
2024-05-21 13:30:12,204:WARNING: 	 vision_layers: 12
2024-05-21 13:30:12,204:WARNING: 	 vision_width: 768
2024-05-21 13:30:12,204:WARNING: 	 vision_patch_size: 32
2024-05-21 13:30:12,204:WARNING: 	 context_length: 77
2024-05-21 13:30:12,204:WARNING: 	 vocab_size: 49408
2024-05-21 13:30:12,204:WARNING: 	 transformer_width: 512
2024-05-21 13:30:12,204:WARNING: 	 transformer_heads: 8
2024-05-21 13:30:12,204:WARNING: 	 transformer_layers: 12
2024-05-21 13:30:12,204:WARNING: 	 cut_top_layer: 0
2024-05-21 13:30:13,124:WARNING: 	 sim_type: seqTransf
2024-05-21 13:30:17,057:INFO: --------------------
2024-05-21 13:30:17,057:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-21 13:35:21,906:INFO: device: cuda:0 n_gpu: 1
2024-05-21 13:35:21,907:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-21 13:35:22,140:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-21 13:35:22,141:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-21 13:35:22,141:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-21 13:35:22,142:WARNING: 	 embed_dim: 512
2024-05-21 13:35:22,142:WARNING: 	 image_resolution: 224
2024-05-21 13:35:22,142:WARNING: 	 vision_layers: 12
2024-05-21 13:35:22,142:WARNING: 	 vision_width: 768
2024-05-21 13:35:22,142:WARNING: 	 vision_patch_size: 32
2024-05-21 13:35:22,142:WARNING: 	 context_length: 77
2024-05-21 13:35:22,142:WARNING: 	 vocab_size: 49408
2024-05-21 13:35:22,142:WARNING: 	 transformer_width: 512
2024-05-21 13:35:22,142:WARNING: 	 transformer_heads: 8
2024-05-21 13:35:22,142:WARNING: 	 transformer_layers: 12
2024-05-21 13:35:22,142:WARNING: 	 cut_top_layer: 0
2024-05-21 13:35:23,116:WARNING: 	 sim_type: seqTransf
2024-05-21 13:35:27,039:INFO: --------------------
2024-05-21 13:35:27,040:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-21 13:40:49,823:INFO: device: cuda:0 n_gpu: 1
2024-05-21 13:40:49,823:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-21 13:40:50,035:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-21 13:40:50,035:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-21 13:40:50,035:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-21 13:40:50,036:WARNING: 	 embed_dim: 512
2024-05-21 13:40:50,036:WARNING: 	 image_resolution: 224
2024-05-21 13:40:50,036:WARNING: 	 vision_layers: 12
2024-05-21 13:40:50,036:WARNING: 	 vision_width: 768
2024-05-21 13:40:50,036:WARNING: 	 vision_patch_size: 32
2024-05-21 13:40:50,036:WARNING: 	 context_length: 77
2024-05-21 13:40:50,036:WARNING: 	 vocab_size: 49408
2024-05-21 13:40:50,036:WARNING: 	 transformer_width: 512
2024-05-21 13:40:50,036:WARNING: 	 transformer_heads: 8
2024-05-21 13:40:50,036:WARNING: 	 transformer_layers: 12
2024-05-21 13:40:50,036:WARNING: 	 cut_top_layer: 0
2024-05-21 13:40:50,897:WARNING: 	 sim_type: seqTransf
2024-05-21 13:41:23,179:INFO: device: cuda:0 n_gpu: 1
2024-05-21 13:41:23,179:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-21 13:41:23,397:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-21 13:41:23,397:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-21 13:41:23,397:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-21 13:41:23,398:WARNING: 	 embed_dim: 512
2024-05-21 13:41:23,398:WARNING: 	 image_resolution: 224
2024-05-21 13:41:23,398:WARNING: 	 vision_layers: 12
2024-05-21 13:41:23,398:WARNING: 	 vision_width: 768
2024-05-21 13:41:23,398:WARNING: 	 vision_patch_size: 32
2024-05-21 13:41:23,398:WARNING: 	 context_length: 77
2024-05-21 13:41:23,398:WARNING: 	 vocab_size: 49408
2024-05-21 13:41:23,398:WARNING: 	 transformer_width: 512
2024-05-21 13:41:23,398:WARNING: 	 transformer_heads: 8
2024-05-21 13:41:23,398:WARNING: 	 transformer_layers: 12
2024-05-21 13:41:23,398:WARNING: 	 cut_top_layer: 0
2024-05-21 13:41:24,292:WARNING: 	 sim_type: seqTransf
2024-05-21 13:41:28,169:INFO: --------------------
2024-05-21 13:41:28,169:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-21 13:42:21,796:INFO: device: cuda:0 n_gpu: 1
2024-05-21 13:42:21,796:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-21 13:42:22,029:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-21 13:42:22,030:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-21 13:42:22,030:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-21 13:42:22,031:WARNING: 	 embed_dim: 512
2024-05-21 13:42:22,031:WARNING: 	 image_resolution: 224
2024-05-21 13:42:22,031:WARNING: 	 vision_layers: 12
2024-05-21 13:42:22,031:WARNING: 	 vision_width: 768
2024-05-21 13:42:22,031:WARNING: 	 vision_patch_size: 32
2024-05-21 13:42:22,031:WARNING: 	 context_length: 77
2024-05-21 13:42:22,031:WARNING: 	 vocab_size: 49408
2024-05-21 13:42:22,031:WARNING: 	 transformer_width: 512
2024-05-21 13:42:22,032:WARNING: 	 transformer_heads: 8
2024-05-21 13:42:22,032:WARNING: 	 transformer_layers: 12
2024-05-21 13:42:22,032:WARNING: 	 cut_top_layer: 0
2024-05-21 13:42:22,922:WARNING: 	 sim_type: seqTransf
2024-05-21 13:42:26,825:INFO: --------------------
2024-05-21 13:42:26,825:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-21 13:43:25,999:INFO: device: cuda:0 n_gpu: 1
2024-05-21 13:43:25,999:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-21 13:43:26,232:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-21 13:43:26,233:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-21 13:43:26,233:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-21 13:43:26,234:WARNING: 	 embed_dim: 512
2024-05-21 13:43:26,234:WARNING: 	 image_resolution: 224
2024-05-21 13:43:26,234:WARNING: 	 vision_layers: 12
2024-05-21 13:43:26,234:WARNING: 	 vision_width: 768
2024-05-21 13:43:26,234:WARNING: 	 vision_patch_size: 32
2024-05-21 13:43:26,234:WARNING: 	 context_length: 77
2024-05-21 13:43:26,234:WARNING: 	 vocab_size: 49408
2024-05-21 13:43:26,235:WARNING: 	 transformer_width: 512
2024-05-21 13:43:26,235:WARNING: 	 transformer_heads: 8
2024-05-21 13:43:26,235:WARNING: 	 transformer_layers: 12
2024-05-21 13:43:26,235:WARNING: 	 cut_top_layer: 0
2024-05-21 13:43:27,130:WARNING: 	 sim_type: seqTransf
2024-05-21 13:43:31,018:INFO: --------------------
2024-05-21 13:43:31,018:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-21 13:45:54,421:INFO: device: cuda:0 n_gpu: 1
2024-05-21 13:45:54,422:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-21 13:45:54,658:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-21 13:45:54,659:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-21 13:45:54,659:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-21 13:45:54,660:WARNING: 	 embed_dim: 512
2024-05-21 13:45:54,660:WARNING: 	 image_resolution: 224
2024-05-21 13:45:54,660:WARNING: 	 vision_layers: 12
2024-05-21 13:45:54,660:WARNING: 	 vision_width: 768
2024-05-21 13:45:54,660:WARNING: 	 vision_patch_size: 32
2024-05-21 13:45:54,660:WARNING: 	 context_length: 77
2024-05-21 13:45:54,660:WARNING: 	 vocab_size: 49408
2024-05-21 13:45:54,660:WARNING: 	 transformer_width: 512
2024-05-21 13:45:54,661:WARNING: 	 transformer_heads: 8
2024-05-21 13:45:54,661:WARNING: 	 transformer_layers: 12
2024-05-21 13:45:54,661:WARNING: 	 cut_top_layer: 0
2024-05-21 13:45:55,555:WARNING: 	 sim_type: seqTransf
2024-05-21 13:45:59,453:INFO: --------------------
2024-05-21 13:45:59,453:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-21 13:48:41,879:INFO: device: cuda:0 n_gpu: 1
2024-05-21 13:48:41,879:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-21 13:48:42,119:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-21 13:48:42,120:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-21 13:48:42,120:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-21 13:48:42,121:WARNING: 	 embed_dim: 512
2024-05-21 13:48:42,121:WARNING: 	 image_resolution: 224
2024-05-21 13:48:42,121:WARNING: 	 vision_layers: 12
2024-05-21 13:48:42,121:WARNING: 	 vision_width: 768
2024-05-21 13:48:42,121:WARNING: 	 vision_patch_size: 32
2024-05-21 13:48:42,121:WARNING: 	 context_length: 77
2024-05-21 13:48:42,121:WARNING: 	 vocab_size: 49408
2024-05-21 13:48:42,121:WARNING: 	 transformer_width: 512
2024-05-21 13:48:42,121:WARNING: 	 transformer_heads: 8
2024-05-21 13:48:42,121:WARNING: 	 transformer_layers: 12
2024-05-21 13:48:42,121:WARNING: 	 cut_top_layer: 0
2024-05-21 13:48:43,027:WARNING: 	 sim_type: seqTransf
2024-05-21 13:48:46,919:INFO: --------------------
2024-05-21 13:48:46,919:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-21 13:56:23,405:INFO: device: cuda:0 n_gpu: 1
2024-05-21 13:56:23,405:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-21 13:56:23,627:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-21 13:56:23,627:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-21 13:56:23,627:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-21 13:56:23,627:WARNING: 	 embed_dim: 512
2024-05-21 13:56:23,627:WARNING: 	 image_resolution: 224
2024-05-21 13:56:23,627:WARNING: 	 vision_layers: 12
2024-05-21 13:56:23,627:WARNING: 	 vision_width: 768
2024-05-21 13:56:23,627:WARNING: 	 vision_patch_size: 32
2024-05-21 13:56:23,627:WARNING: 	 context_length: 77
2024-05-21 13:56:23,627:WARNING: 	 vocab_size: 49408
2024-05-21 13:56:23,627:WARNING: 	 transformer_width: 512
2024-05-21 13:56:23,627:WARNING: 	 transformer_heads: 8
2024-05-21 13:56:23,627:WARNING: 	 transformer_layers: 12
2024-05-21 13:56:23,627:WARNING: 	 cut_top_layer: 0
2024-05-21 13:56:24,498:WARNING: 	 sim_type: seqTransf
2024-05-21 13:56:28,398:INFO: --------------------
2024-05-21 13:56:28,398:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-21 13:57:34,619:INFO: device: cuda:0 n_gpu: 1
2024-05-21 13:57:34,620:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-21 13:57:34,862:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-21 13:57:34,863:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-21 13:57:34,863:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-21 13:57:34,864:WARNING: 	 embed_dim: 512
2024-05-21 13:57:34,864:WARNING: 	 image_resolution: 224
2024-05-21 13:57:34,864:WARNING: 	 vision_layers: 12
2024-05-21 13:57:34,865:WARNING: 	 vision_width: 768
2024-05-21 13:57:34,865:WARNING: 	 vision_patch_size: 32
2024-05-21 13:57:34,865:WARNING: 	 context_length: 77
2024-05-21 13:57:34,865:WARNING: 	 vocab_size: 49408
2024-05-21 13:57:34,865:WARNING: 	 transformer_width: 512
2024-05-21 13:57:34,865:WARNING: 	 transformer_heads: 8
2024-05-21 13:57:34,865:WARNING: 	 transformer_layers: 12
2024-05-21 13:57:34,865:WARNING: 	 cut_top_layer: 0
2024-05-21 13:57:35,764:WARNING: 	 sim_type: seqTransf
2024-05-21 13:57:39,662:INFO: --------------------
2024-05-21 13:57:39,662:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-21 14:02:13,297:INFO: device: cuda:0 n_gpu: 1
2024-05-21 14:02:13,297:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-21 14:02:13,512:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-21 14:02:13,512:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-21 14:02:13,512:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-21 14:02:13,513:WARNING: 	 embed_dim: 512
2024-05-21 14:02:13,513:WARNING: 	 image_resolution: 224
2024-05-21 14:02:13,513:WARNING: 	 vision_layers: 12
2024-05-21 14:02:13,513:WARNING: 	 vision_width: 768
2024-05-21 14:02:13,513:WARNING: 	 vision_patch_size: 32
2024-05-21 14:02:13,513:WARNING: 	 context_length: 77
2024-05-21 14:02:13,513:WARNING: 	 vocab_size: 49408
2024-05-21 14:02:13,513:WARNING: 	 transformer_width: 512
2024-05-21 14:02:13,513:WARNING: 	 transformer_heads: 8
2024-05-21 14:02:13,513:WARNING: 	 transformer_layers: 12
2024-05-21 14:02:13,513:WARNING: 	 cut_top_layer: 0
2024-05-21 14:02:14,408:WARNING: 	 sim_type: seqTransf
2024-05-21 14:02:18,287:INFO: --------------------
2024-05-21 14:02:18,288:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-21 14:03:07,811:INFO: device: cuda:0 n_gpu: 1
2024-05-21 14:03:07,812:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-21 14:03:08,028:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-21 14:03:08,028:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-21 14:03:08,028:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-21 14:03:08,028:WARNING: 	 embed_dim: 512
2024-05-21 14:03:08,028:WARNING: 	 image_resolution: 224
2024-05-21 14:03:08,028:WARNING: 	 vision_layers: 12
2024-05-21 14:03:08,028:WARNING: 	 vision_width: 768
2024-05-21 14:03:08,028:WARNING: 	 vision_patch_size: 32
2024-05-21 14:03:08,028:WARNING: 	 context_length: 77
2024-05-21 14:03:08,028:WARNING: 	 vocab_size: 49408
2024-05-21 14:03:08,028:WARNING: 	 transformer_width: 512
2024-05-21 14:03:08,028:WARNING: 	 transformer_heads: 8
2024-05-21 14:03:08,028:WARNING: 	 transformer_layers: 12
2024-05-21 14:03:08,028:WARNING: 	 cut_top_layer: 0
2024-05-21 14:03:08,892:WARNING: 	 sim_type: seqTransf
2024-05-21 14:03:12,777:INFO: --------------------
2024-05-21 14:03:12,777:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-21 14:04:53,928:INFO: device: cuda:0 n_gpu: 1
2024-05-21 14:04:53,928:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-21 14:04:54,147:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-21 14:04:54,147:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-21 14:04:54,147:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-21 14:04:54,148:WARNING: 	 embed_dim: 512
2024-05-21 14:04:54,148:WARNING: 	 image_resolution: 224
2024-05-21 14:04:54,148:WARNING: 	 vision_layers: 12
2024-05-21 14:04:54,148:WARNING: 	 vision_width: 768
2024-05-21 14:04:54,148:WARNING: 	 vision_patch_size: 32
2024-05-21 14:04:54,148:WARNING: 	 context_length: 77
2024-05-21 14:04:54,148:WARNING: 	 vocab_size: 49408
2024-05-21 14:04:54,148:WARNING: 	 transformer_width: 512
2024-05-21 14:04:54,148:WARNING: 	 transformer_heads: 8
2024-05-21 14:04:54,148:WARNING: 	 transformer_layers: 12
2024-05-21 14:04:54,148:WARNING: 	 cut_top_layer: 0
2024-05-21 14:04:55,035:WARNING: 	 sim_type: seqTransf
2024-05-21 14:04:58,921:INFO: --------------------
2024-05-21 14:04:58,922:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-21 14:05:34,370:INFO: device: cuda:0 n_gpu: 1
2024-05-21 14:05:34,370:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-21 14:05:34,591:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-21 14:05:34,591:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-21 14:05:34,591:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-21 14:05:34,592:WARNING: 	 embed_dim: 512
2024-05-21 14:05:34,592:WARNING: 	 image_resolution: 224
2024-05-21 14:05:34,592:WARNING: 	 vision_layers: 12
2024-05-21 14:05:34,592:WARNING: 	 vision_width: 768
2024-05-21 14:05:34,592:WARNING: 	 vision_patch_size: 32
2024-05-21 14:05:34,592:WARNING: 	 context_length: 77
2024-05-21 14:05:34,592:WARNING: 	 vocab_size: 49408
2024-05-21 14:05:34,592:WARNING: 	 transformer_width: 512
2024-05-21 14:05:34,592:WARNING: 	 transformer_heads: 8
2024-05-21 14:05:34,592:WARNING: 	 transformer_layers: 12
2024-05-21 14:05:34,592:WARNING: 	 cut_top_layer: 0
2024-05-21 14:05:35,458:WARNING: 	 sim_type: seqTransf
2024-05-21 14:05:39,305:INFO: --------------------
2024-05-21 14:05:39,306:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-21 14:32:26,585:INFO: device: cuda:0 n_gpu: 1
2024-05-21 14:32:26,585:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-21 14:32:26,802:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-21 14:32:26,803:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-21 14:32:26,803:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-21 14:32:26,803:WARNING: 	 embed_dim: 512
2024-05-21 14:32:26,803:WARNING: 	 image_resolution: 224
2024-05-21 14:32:26,803:WARNING: 	 vision_layers: 12
2024-05-21 14:32:26,803:WARNING: 	 vision_width: 768
2024-05-21 14:32:26,803:WARNING: 	 vision_patch_size: 32
2024-05-21 14:32:26,803:WARNING: 	 context_length: 77
2024-05-21 14:32:26,803:WARNING: 	 vocab_size: 49408
2024-05-21 14:32:26,803:WARNING: 	 transformer_width: 512
2024-05-21 14:32:26,803:WARNING: 	 transformer_heads: 8
2024-05-21 14:32:26,803:WARNING: 	 transformer_layers: 12
2024-05-21 14:32:26,803:WARNING: 	 cut_top_layer: 0
2024-05-21 14:32:27,677:WARNING: 	 sim_type: seqTransf
2024-05-21 14:32:31,572:INFO: --------------------
2024-05-21 14:32:31,572:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-21 14:33:25,702:INFO: device: cuda:0 n_gpu: 1
2024-05-21 14:33:25,702:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-21 14:33:25,917:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-21 14:33:25,917:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-21 14:33:25,917:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-21 14:33:25,917:WARNING: 	 embed_dim: 512
2024-05-21 14:33:25,917:WARNING: 	 image_resolution: 224
2024-05-21 14:33:25,917:WARNING: 	 vision_layers: 12
2024-05-21 14:33:25,918:WARNING: 	 vision_width: 768
2024-05-21 14:33:25,918:WARNING: 	 vision_patch_size: 32
2024-05-21 14:33:25,918:WARNING: 	 context_length: 77
2024-05-21 14:33:25,918:WARNING: 	 vocab_size: 49408
2024-05-21 14:33:25,918:WARNING: 	 transformer_width: 512
2024-05-21 14:33:25,918:WARNING: 	 transformer_heads: 8
2024-05-21 14:33:25,918:WARNING: 	 transformer_layers: 12
2024-05-21 14:33:25,918:WARNING: 	 cut_top_layer: 0
2024-05-21 14:33:26,787:WARNING: 	 sim_type: seqTransf
2024-05-21 14:33:30,674:INFO: --------------------
2024-05-21 14:33:30,674:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-22 00:14:56,404:INFO: device: cuda:0 n_gpu: 1
2024-05-22 00:14:56,404:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-22 00:14:56,688:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-22 00:14:56,689:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-22 00:14:56,689:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-22 00:14:56,690:WARNING: 	 embed_dim: 512
2024-05-22 00:14:56,690:WARNING: 	 image_resolution: 224
2024-05-22 00:14:56,690:WARNING: 	 vision_layers: 12
2024-05-22 00:14:56,690:WARNING: 	 vision_width: 768
2024-05-22 00:14:56,690:WARNING: 	 vision_patch_size: 32
2024-05-22 00:14:56,691:WARNING: 	 context_length: 77
2024-05-22 00:14:56,691:WARNING: 	 vocab_size: 49408
2024-05-22 00:14:56,691:WARNING: 	 transformer_width: 512
2024-05-22 00:14:56,691:WARNING: 	 transformer_heads: 8
2024-05-22 00:14:56,691:WARNING: 	 transformer_layers: 12
2024-05-22 00:14:56,691:WARNING: 	 cut_top_layer: 0
2024-05-22 00:14:57,716:WARNING: 	 sim_type: seqTransf
2024-05-22 00:15:02,242:INFO: --------------------
2024-05-22 00:15:02,242:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-22 00:24:15,593:INFO: device: cuda:0 n_gpu: 1
2024-05-22 00:24:15,659:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-22 00:24:15,899:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-22 00:24:15,900:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-22 00:24:15,900:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-22 00:24:15,901:WARNING: 	 embed_dim: 512
2024-05-22 00:24:15,901:WARNING: 	 image_resolution: 224
2024-05-22 00:24:15,901:WARNING: 	 vision_layers: 12
2024-05-22 00:24:15,901:WARNING: 	 vision_width: 768
2024-05-22 00:24:15,901:WARNING: 	 vision_patch_size: 32
2024-05-22 00:24:15,901:WARNING: 	 context_length: 77
2024-05-22 00:24:15,901:WARNING: 	 vocab_size: 49408
2024-05-22 00:24:15,902:WARNING: 	 transformer_width: 512
2024-05-22 00:24:15,902:WARNING: 	 transformer_heads: 8
2024-05-22 00:24:15,902:WARNING: 	 transformer_layers: 12
2024-05-22 00:24:15,902:WARNING: 	 cut_top_layer: 0
2024-05-22 00:24:16,881:WARNING: 	 sim_type: seqTransf
2024-05-22 00:24:21,375:INFO: --------------------
2024-05-22 00:24:21,375:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-22 00:24:23,112:INFO: ***** Running test *****
2024-05-22 00:24:23,113:INFO:   Num examples = 1
2024-05-22 00:24:23,113:INFO:   Batch size = 64
2024-05-22 00:24:23,113:INFO:   Num steps = 1
2024-05-22 00:25:09,778:INFO: device: cuda:0 n_gpu: 1
2024-05-22 00:25:09,846:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-22 00:25:10,079:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-22 00:25:10,080:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-22 00:25:10,081:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-22 00:25:10,081:WARNING: 	 embed_dim: 512
2024-05-22 00:25:10,082:WARNING: 	 image_resolution: 224
2024-05-22 00:25:10,082:WARNING: 	 vision_layers: 12
2024-05-22 00:25:10,082:WARNING: 	 vision_width: 768
2024-05-22 00:25:10,082:WARNING: 	 vision_patch_size: 32
2024-05-22 00:25:10,082:WARNING: 	 context_length: 77
2024-05-22 00:25:10,082:WARNING: 	 vocab_size: 49408
2024-05-22 00:25:10,082:WARNING: 	 transformer_width: 512
2024-05-22 00:25:10,082:WARNING: 	 transformer_heads: 8
2024-05-22 00:25:10,082:WARNING: 	 transformer_layers: 12
2024-05-22 00:25:10,082:WARNING: 	 cut_top_layer: 0
2024-05-22 00:25:11,076:WARNING: 	 sim_type: seqTransf
2024-05-22 00:25:15,596:INFO: --------------------
2024-05-22 00:25:15,597:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-22 00:25:17,348:INFO: ***** Running test *****
2024-05-22 00:25:17,349:INFO:   Num examples = 1
2024-05-22 00:25:17,349:INFO:   Batch size = 64
2024-05-22 00:25:17,349:INFO:   Num steps = 1
2024-05-22 00:44:42,228:INFO: device: cuda:0 n_gpu: 1
2024-05-22 00:44:42,298:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-22 00:44:42,512:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-22 00:44:42,512:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-22 00:44:42,512:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-22 00:44:42,512:WARNING: 	 embed_dim: 512
2024-05-22 00:44:42,512:WARNING: 	 image_resolution: 224
2024-05-22 00:44:42,512:WARNING: 	 vision_layers: 12
2024-05-22 00:44:42,512:WARNING: 	 vision_width: 768
2024-05-22 00:44:42,512:WARNING: 	 vision_patch_size: 32
2024-05-22 00:44:42,512:WARNING: 	 context_length: 77
2024-05-22 00:44:42,512:WARNING: 	 vocab_size: 49408
2024-05-22 00:44:42,512:WARNING: 	 transformer_width: 512
2024-05-22 00:44:42,513:WARNING: 	 transformer_heads: 8
2024-05-22 00:44:42,513:WARNING: 	 transformer_layers: 12
2024-05-22 00:44:42,513:WARNING: 	 cut_top_layer: 0
2024-05-22 00:44:43,471:WARNING: 	 sim_type: seqTransf
2024-05-22 00:44:47,948:INFO: --------------------
2024-05-22 00:44:47,948:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-22 00:44:49,669:INFO: ***** Running test *****
2024-05-22 00:44:49,669:INFO:   Num examples = 1
2024-05-22 00:44:49,669:INFO:   Batch size = 64
2024-05-22 00:44:49,669:INFO:   Num steps = 1
2024-05-22 00:44:49,860:INFO: sim matrix size: 1, 1
2024-05-22 00:44:49,860:INFO: 	 Length-T: 1, Length-V:1
2024-05-22 00:44:49,860:INFO: Text-to-Video:
2024-05-22 00:44:49,860:INFO: 	>>>  R@1: 100.0 - R@5: 100.0 - R@10: 100.0 - Median R: 1.0 - Mean R: 1.0
2024-05-22 00:44:49,860:INFO: Video-to-Text:
2024-05-22 00:44:49,860:INFO: 	>>>  V2T$R@1: 100.0 - V2T$R@5: 100.0 - V2T$R@10: 100.0 - V2T$Median R: 1.0 - V2T$Mean R: 1.0
2024-05-22 00:45:01,251:INFO: device: cuda:0 n_gpu: 1
2024-05-22 00:45:01,317:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-22 00:45:01,547:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-22 00:45:01,548:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-22 00:45:01,548:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-22 00:45:01,549:WARNING: 	 embed_dim: 512
2024-05-22 00:45:01,549:WARNING: 	 image_resolution: 224
2024-05-22 00:45:01,549:WARNING: 	 vision_layers: 12
2024-05-22 00:45:01,549:WARNING: 	 vision_width: 768
2024-05-22 00:45:01,549:WARNING: 	 vision_patch_size: 32
2024-05-22 00:45:01,550:WARNING: 	 context_length: 77
2024-05-22 00:45:01,550:WARNING: 	 vocab_size: 49408
2024-05-22 00:45:01,550:WARNING: 	 transformer_width: 512
2024-05-22 00:45:01,550:WARNING: 	 transformer_heads: 8
2024-05-22 00:45:01,550:WARNING: 	 transformer_layers: 12
2024-05-22 00:45:01,550:WARNING: 	 cut_top_layer: 0
2024-05-22 00:45:02,545:WARNING: 	 sim_type: seqTransf
2024-05-22 00:45:07,057:INFO: --------------------
2024-05-22 00:45:07,057:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-22 00:45:08,803:INFO: ***** Running test *****
2024-05-22 00:45:08,803:INFO:   Num examples = 1
2024-05-22 00:45:08,803:INFO:   Batch size = 64
2024-05-22 00:45:08,803:INFO:   Num steps = 1
2024-05-22 00:48:22,786:INFO: sim matrix size: 1, 1
2024-05-22 00:54:29,279:INFO: 	 Length-T: 1, Length-V:1
2024-05-22 00:54:50,792:INFO: Text-to-Video:
2024-05-22 00:54:52,391:INFO: 	>>>  R@1: 100.0 - R@5: 100.0 - R@10: 100.0 - Median R: 1.0 - Mean R: 1.0
2024-05-22 00:54:53,261:INFO: Video-to-Text:
2024-05-22 00:54:54,894:INFO: 	>>>  V2T$R@1: 100.0 - V2T$R@5: 100.0 - V2T$R@10: 100.0 - V2T$Median R: 1.0 - V2T$Mean R: 1.0
2024-05-22 01:38:50,970:INFO: device: cuda:0 n_gpu: 1
2024-05-22 01:38:51,037:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-22 01:38:51,332:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-22 01:38:51,334:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-22 01:38:51,334:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-22 01:38:51,335:WARNING: 	 embed_dim: 512
2024-05-22 01:38:51,335:WARNING: 	 image_resolution: 224
2024-05-22 01:38:51,335:WARNING: 	 vision_layers: 12
2024-05-22 01:38:51,335:WARNING: 	 vision_width: 768
2024-05-22 01:38:51,335:WARNING: 	 vision_patch_size: 32
2024-05-22 01:38:51,335:WARNING: 	 context_length: 77
2024-05-22 01:38:51,335:WARNING: 	 vocab_size: 49408
2024-05-22 01:38:51,335:WARNING: 	 transformer_width: 512
2024-05-22 01:38:51,335:WARNING: 	 transformer_heads: 8
2024-05-22 01:38:51,335:WARNING: 	 transformer_layers: 12
2024-05-22 01:38:51,335:WARNING: 	 cut_top_layer: 0
2024-05-22 01:38:52,323:WARNING: 	 sim_type: seqTransf
2024-05-22 01:38:56,811:INFO: --------------------
2024-05-22 01:38:56,811:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-22 01:38:58,595:INFO: ***** Running test *****
2024-05-22 01:38:58,595:INFO:   Num examples = 1
2024-05-22 01:38:58,595:INFO:   Batch size = 64
2024-05-22 01:38:58,595:INFO:   Num steps = 1
2024-05-22 01:39:52,438:INFO: sim matrix size: 1, 1
2024-05-22 01:39:52,439:INFO: 	 Length-T: 1, Length-V:1
2024-05-22 01:39:52,439:INFO: Text-to-Video:
2024-05-22 01:39:52,440:INFO: 	>>>  R@1: 100.0 - R@5: 100.0 - R@10: 100.0 - Median R: 1.0 - Mean R: 1.0
2024-05-22 01:39:52,440:INFO: Video-to-Text:
2024-05-22 01:39:52,441:INFO: 	>>>  V2T$R@1: 100.0 - V2T$R@5: 100.0 - V2T$R@10: 100.0 - V2T$Median R: 1.0 - V2T$Mean R: 1.0
2024-05-22 01:53:21,351:INFO: device: cuda:0 n_gpu: 1
2024-05-22 01:53:21,352:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-22 01:53:21,585:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-22 01:53:21,587:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-22 01:53:21,587:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-22 01:53:21,588:WARNING: 	 embed_dim: 512
2024-05-22 01:53:21,588:WARNING: 	 image_resolution: 224
2024-05-22 01:53:21,588:WARNING: 	 vision_layers: 12
2024-05-22 01:53:21,588:WARNING: 	 vision_width: 768
2024-05-22 01:53:21,588:WARNING: 	 vision_patch_size: 32
2024-05-22 01:53:21,588:WARNING: 	 context_length: 77
2024-05-22 01:53:21,588:WARNING: 	 vocab_size: 49408
2024-05-22 01:53:21,588:WARNING: 	 transformer_width: 512
2024-05-22 01:53:21,588:WARNING: 	 transformer_heads: 8
2024-05-22 01:53:21,588:WARNING: 	 transformer_layers: 12
2024-05-22 01:53:21,588:WARNING: 	 cut_top_layer: 0
2024-05-22 01:53:22,588:WARNING: 	 sim_type: seqTransf
2024-05-22 01:53:27,089:INFO: --------------------
2024-05-22 01:53:27,089:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-22 01:54:24,565:INFO: device: cuda:0 n_gpu: 1
2024-05-22 01:54:24,565:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-22 01:54:24,794:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-22 01:54:24,794:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-22 01:54:24,794:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-22 01:54:24,794:WARNING: 	 embed_dim: 512
2024-05-22 01:54:24,794:WARNING: 	 image_resolution: 224
2024-05-22 01:54:24,794:WARNING: 	 vision_layers: 12
2024-05-22 01:54:24,794:WARNING: 	 vision_width: 768
2024-05-22 01:54:24,794:WARNING: 	 vision_patch_size: 32
2024-05-22 01:54:24,794:WARNING: 	 context_length: 77
2024-05-22 01:54:24,794:WARNING: 	 vocab_size: 49408
2024-05-22 01:54:24,794:WARNING: 	 transformer_width: 512
2024-05-22 01:54:24,794:WARNING: 	 transformer_heads: 8
2024-05-22 01:54:24,794:WARNING: 	 transformer_layers: 12
2024-05-22 01:54:24,794:WARNING: 	 cut_top_layer: 0
2024-05-22 01:54:25,782:WARNING: 	 sim_type: seqTransf
2024-05-22 01:54:30,263:INFO: --------------------
2024-05-22 01:54:30,263:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-22 01:54:48,673:INFO: device: cuda:0 n_gpu: 1
2024-05-22 01:54:48,673:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-22 01:54:48,900:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-22 01:54:48,901:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-22 01:54:48,901:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-22 01:54:48,901:WARNING: 	 embed_dim: 512
2024-05-22 01:54:48,901:WARNING: 	 image_resolution: 224
2024-05-22 01:54:48,901:WARNING: 	 vision_layers: 12
2024-05-22 01:54:48,901:WARNING: 	 vision_width: 768
2024-05-22 01:54:48,901:WARNING: 	 vision_patch_size: 32
2024-05-22 01:54:48,901:WARNING: 	 context_length: 77
2024-05-22 01:54:48,901:WARNING: 	 vocab_size: 49408
2024-05-22 01:54:48,901:WARNING: 	 transformer_width: 512
2024-05-22 01:54:48,901:WARNING: 	 transformer_heads: 8
2024-05-22 01:54:48,901:WARNING: 	 transformer_layers: 12
2024-05-22 01:54:48,901:WARNING: 	 cut_top_layer: 0
2024-05-22 01:54:49,873:WARNING: 	 sim_type: seqTransf
2024-05-22 01:54:54,345:INFO: --------------------
2024-05-22 01:54:54,345:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-22 01:56:27,253:INFO: device: cuda:0 n_gpu: 1
2024-05-22 01:56:27,253:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-22 01:56:27,497:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-22 01:56:27,497:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-22 01:56:27,497:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-22 01:56:27,497:WARNING: 	 embed_dim: 512
2024-05-22 01:56:27,497:WARNING: 	 image_resolution: 224
2024-05-22 01:56:27,497:WARNING: 	 vision_layers: 12
2024-05-22 01:56:27,497:WARNING: 	 vision_width: 768
2024-05-22 01:56:27,497:WARNING: 	 vision_patch_size: 32
2024-05-22 01:56:27,497:WARNING: 	 context_length: 77
2024-05-22 01:56:27,497:WARNING: 	 vocab_size: 49408
2024-05-22 01:56:27,497:WARNING: 	 transformer_width: 512
2024-05-22 01:56:27,497:WARNING: 	 transformer_heads: 8
2024-05-22 01:56:27,497:WARNING: 	 transformer_layers: 12
2024-05-22 01:56:27,497:WARNING: 	 cut_top_layer: 0
2024-05-22 01:56:28,469:WARNING: 	 sim_type: seqTransf
2024-05-22 01:56:32,932:INFO: --------------------
2024-05-22 01:56:32,932:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-22 01:57:19,002:INFO: device: cuda:0 n_gpu: 1
2024-05-22 01:57:19,002:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-22 01:57:19,237:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-22 01:57:19,238:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-22 01:57:19,238:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-22 01:57:19,239:WARNING: 	 embed_dim: 512
2024-05-22 01:57:19,239:WARNING: 	 image_resolution: 224
2024-05-22 01:57:19,239:WARNING: 	 vision_layers: 12
2024-05-22 01:57:19,239:WARNING: 	 vision_width: 768
2024-05-22 01:57:19,239:WARNING: 	 vision_patch_size: 32
2024-05-22 01:57:19,239:WARNING: 	 context_length: 77
2024-05-22 01:57:19,239:WARNING: 	 vocab_size: 49408
2024-05-22 01:57:19,239:WARNING: 	 transformer_width: 512
2024-05-22 01:57:19,240:WARNING: 	 transformer_heads: 8
2024-05-22 01:57:19,240:WARNING: 	 transformer_layers: 12
2024-05-22 01:57:19,240:WARNING: 	 cut_top_layer: 0
2024-05-22 01:57:20,245:WARNING: 	 sim_type: seqTransf
2024-05-22 01:57:24,750:INFO: --------------------
2024-05-22 01:57:24,750:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-22 01:59:37,393:INFO: device: cuda:0 n_gpu: 1
2024-05-22 01:59:37,393:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-22 01:59:37,629:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-22 01:59:37,630:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-22 01:59:37,630:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-22 01:59:37,631:WARNING: 	 embed_dim: 512
2024-05-22 01:59:37,631:WARNING: 	 image_resolution: 224
2024-05-22 01:59:37,631:WARNING: 	 vision_layers: 12
2024-05-22 01:59:37,631:WARNING: 	 vision_width: 768
2024-05-22 01:59:37,631:WARNING: 	 vision_patch_size: 32
2024-05-22 01:59:37,631:WARNING: 	 context_length: 77
2024-05-22 01:59:37,631:WARNING: 	 vocab_size: 49408
2024-05-22 01:59:37,631:WARNING: 	 transformer_width: 512
2024-05-22 01:59:37,631:WARNING: 	 transformer_heads: 8
2024-05-22 01:59:37,632:WARNING: 	 transformer_layers: 12
2024-05-22 01:59:37,632:WARNING: 	 cut_top_layer: 0
2024-05-22 01:59:38,624:WARNING: 	 sim_type: seqTransf
2024-05-22 01:59:43,123:INFO: --------------------
2024-05-22 01:59:43,123:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-22 02:02:20,293:INFO: device: cuda:0 n_gpu: 1
2024-05-22 02:02:20,293:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-22 02:02:20,518:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-22 02:02:20,518:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-22 02:02:20,518:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-22 02:02:20,518:WARNING: 	 embed_dim: 512
2024-05-22 02:02:20,518:WARNING: 	 image_resolution: 224
2024-05-22 02:02:20,518:WARNING: 	 vision_layers: 12
2024-05-22 02:02:20,518:WARNING: 	 vision_width: 768
2024-05-22 02:02:20,518:WARNING: 	 vision_patch_size: 32
2024-05-22 02:02:20,518:WARNING: 	 context_length: 77
2024-05-22 02:02:20,518:WARNING: 	 vocab_size: 49408
2024-05-22 02:02:20,518:WARNING: 	 transformer_width: 512
2024-05-22 02:02:20,518:WARNING: 	 transformer_heads: 8
2024-05-22 02:02:20,518:WARNING: 	 transformer_layers: 12
2024-05-22 02:02:20,518:WARNING: 	 cut_top_layer: 0
2024-05-22 02:02:21,498:WARNING: 	 sim_type: seqTransf
2024-05-22 02:02:25,989:INFO: --------------------
2024-05-22 02:02:25,989:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-22 02:04:25,279:INFO: device: cuda:0 n_gpu: 1
2024-05-22 02:04:25,279:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-22 02:04:25,507:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-22 02:04:25,507:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-22 02:04:25,507:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-22 02:04:25,507:WARNING: 	 embed_dim: 512
2024-05-22 02:04:25,507:WARNING: 	 image_resolution: 224
2024-05-22 02:04:25,508:WARNING: 	 vision_layers: 12
2024-05-22 02:04:25,508:WARNING: 	 vision_width: 768
2024-05-22 02:04:25,508:WARNING: 	 vision_patch_size: 32
2024-05-22 02:04:25,508:WARNING: 	 context_length: 77
2024-05-22 02:04:25,508:WARNING: 	 vocab_size: 49408
2024-05-22 02:04:25,508:WARNING: 	 transformer_width: 512
2024-05-22 02:04:25,508:WARNING: 	 transformer_heads: 8
2024-05-22 02:04:25,508:WARNING: 	 transformer_layers: 12
2024-05-22 02:04:25,508:WARNING: 	 cut_top_layer: 0
2024-05-22 02:04:26,490:WARNING: 	 sim_type: seqTransf
2024-05-22 02:04:30,967:INFO: --------------------
2024-05-22 02:04:30,967:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-22 02:06:22,725:INFO: device: cuda:0 n_gpu: 1
2024-05-22 02:06:22,725:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-22 02:06:22,953:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-22 02:06:22,953:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-22 02:06:22,953:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-22 02:06:22,953:WARNING: 	 embed_dim: 512
2024-05-22 02:06:22,953:WARNING: 	 image_resolution: 224
2024-05-22 02:06:22,953:WARNING: 	 vision_layers: 12
2024-05-22 02:06:22,953:WARNING: 	 vision_width: 768
2024-05-22 02:06:22,953:WARNING: 	 vision_patch_size: 32
2024-05-22 02:06:22,953:WARNING: 	 context_length: 77
2024-05-22 02:06:22,953:WARNING: 	 vocab_size: 49408
2024-05-22 02:06:22,953:WARNING: 	 transformer_width: 512
2024-05-22 02:06:22,953:WARNING: 	 transformer_heads: 8
2024-05-22 02:06:22,954:WARNING: 	 transformer_layers: 12
2024-05-22 02:06:22,954:WARNING: 	 cut_top_layer: 0
2024-05-22 02:06:23,924:WARNING: 	 sim_type: seqTransf
2024-05-22 02:06:28,405:INFO: --------------------
2024-05-22 02:06:28,405:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-22 02:08:55,337:INFO: device: cuda:0 n_gpu: 1
2024-05-22 02:08:55,337:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-22 02:08:55,563:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-22 02:08:55,564:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-22 02:08:55,564:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-22 02:08:55,564:WARNING: 	 embed_dim: 512
2024-05-22 02:08:55,564:WARNING: 	 image_resolution: 224
2024-05-22 02:08:55,564:WARNING: 	 vision_layers: 12
2024-05-22 02:08:55,564:WARNING: 	 vision_width: 768
2024-05-22 02:08:55,564:WARNING: 	 vision_patch_size: 32
2024-05-22 02:08:55,564:WARNING: 	 context_length: 77
2024-05-22 02:08:55,564:WARNING: 	 vocab_size: 49408
2024-05-22 02:08:55,564:WARNING: 	 transformer_width: 512
2024-05-22 02:08:55,564:WARNING: 	 transformer_heads: 8
2024-05-22 02:08:55,564:WARNING: 	 transformer_layers: 12
2024-05-22 02:08:55,564:WARNING: 	 cut_top_layer: 0
2024-05-22 02:08:56,545:WARNING: 	 sim_type: seqTransf
2024-05-22 02:09:01,025:INFO: --------------------
2024-05-22 02:09:01,025:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-22 02:10:08,225:INFO: device: cuda:0 n_gpu: 1
2024-05-22 02:10:08,225:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-22 02:10:08,458:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-22 02:10:08,458:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-22 02:10:08,458:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-22 02:10:08,459:WARNING: 	 embed_dim: 512
2024-05-22 02:10:08,459:WARNING: 	 image_resolution: 224
2024-05-22 02:10:08,459:WARNING: 	 vision_layers: 12
2024-05-22 02:10:08,459:WARNING: 	 vision_width: 768
2024-05-22 02:10:08,459:WARNING: 	 vision_patch_size: 32
2024-05-22 02:10:08,459:WARNING: 	 context_length: 77
2024-05-22 02:10:08,459:WARNING: 	 vocab_size: 49408
2024-05-22 02:10:08,459:WARNING: 	 transformer_width: 512
2024-05-22 02:10:08,459:WARNING: 	 transformer_heads: 8
2024-05-22 02:10:08,459:WARNING: 	 transformer_layers: 12
2024-05-22 02:10:08,459:WARNING: 	 cut_top_layer: 0
2024-05-22 02:10:09,438:WARNING: 	 sim_type: seqTransf
2024-05-22 02:10:13,918:INFO: --------------------
2024-05-22 02:10:13,918:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-22 02:10:23,294:INFO: device: cuda:0 n_gpu: 1
2024-05-22 02:10:23,294:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-22 02:10:23,522:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-22 02:10:23,522:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-22 02:10:23,522:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-22 02:10:23,522:WARNING: 	 embed_dim: 512
2024-05-22 02:10:23,522:WARNING: 	 image_resolution: 224
2024-05-22 02:10:23,522:WARNING: 	 vision_layers: 12
2024-05-22 02:10:23,522:WARNING: 	 vision_width: 768
2024-05-22 02:10:23,522:WARNING: 	 vision_patch_size: 32
2024-05-22 02:10:23,522:WARNING: 	 context_length: 77
2024-05-22 02:10:23,522:WARNING: 	 vocab_size: 49408
2024-05-22 02:10:23,522:WARNING: 	 transformer_width: 512
2024-05-22 02:10:23,522:WARNING: 	 transformer_heads: 8
2024-05-22 02:10:23,522:WARNING: 	 transformer_layers: 12
2024-05-22 02:10:23,522:WARNING: 	 cut_top_layer: 0
2024-05-22 02:10:24,504:WARNING: 	 sim_type: seqTransf
2024-05-22 02:10:28,988:INFO: --------------------
2024-05-22 02:10:28,988:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-22 02:12:17,717:INFO: device: cuda:0 n_gpu: 1
2024-05-22 02:12:17,717:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-22 02:12:17,954:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-22 02:12:17,955:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-22 02:12:17,955:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-22 02:12:17,956:WARNING: 	 embed_dim: 512
2024-05-22 02:12:17,956:WARNING: 	 image_resolution: 224
2024-05-22 02:12:17,956:WARNING: 	 vision_layers: 12
2024-05-22 02:12:17,956:WARNING: 	 vision_width: 768
2024-05-22 02:12:17,956:WARNING: 	 vision_patch_size: 32
2024-05-22 02:12:17,957:WARNING: 	 context_length: 77
2024-05-22 02:12:17,957:WARNING: 	 vocab_size: 49408
2024-05-22 02:12:17,957:WARNING: 	 transformer_width: 512
2024-05-22 02:12:17,957:WARNING: 	 transformer_heads: 8
2024-05-22 02:12:17,957:WARNING: 	 transformer_layers: 12
2024-05-22 02:12:17,957:WARNING: 	 cut_top_layer: 0
2024-05-22 02:12:18,957:WARNING: 	 sim_type: seqTransf
2024-05-22 02:12:23,475:INFO: --------------------
2024-05-22 02:12:23,475:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-22 02:15:06,084:INFO: device: cuda:0 n_gpu: 1
2024-05-22 02:15:06,085:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-22 02:15:06,321:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-22 02:15:06,323:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-22 02:15:06,323:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-22 02:15:06,324:WARNING: 	 embed_dim: 512
2024-05-22 02:15:06,324:WARNING: 	 image_resolution: 224
2024-05-22 02:15:06,324:WARNING: 	 vision_layers: 12
2024-05-22 02:15:06,324:WARNING: 	 vision_width: 768
2024-05-22 02:15:06,324:WARNING: 	 vision_patch_size: 32
2024-05-22 02:15:06,324:WARNING: 	 context_length: 77
2024-05-22 02:15:06,324:WARNING: 	 vocab_size: 49408
2024-05-22 02:15:06,324:WARNING: 	 transformer_width: 512
2024-05-22 02:15:06,324:WARNING: 	 transformer_heads: 8
2024-05-22 02:15:06,324:WARNING: 	 transformer_layers: 12
2024-05-22 02:15:06,324:WARNING: 	 cut_top_layer: 0
2024-05-22 02:15:07,323:WARNING: 	 sim_type: seqTransf
2024-05-22 02:15:11,816:INFO: --------------------
2024-05-22 02:15:11,816:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-22 02:15:50,473:INFO: device: cuda:0 n_gpu: 1
2024-05-22 02:15:50,473:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-22 02:15:50,702:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-22 02:15:50,702:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-22 02:15:50,702:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-22 02:15:50,702:WARNING: 	 embed_dim: 512
2024-05-22 02:15:50,702:WARNING: 	 image_resolution: 224
2024-05-22 02:15:50,702:WARNING: 	 vision_layers: 12
2024-05-22 02:15:50,703:WARNING: 	 vision_width: 768
2024-05-22 02:15:50,703:WARNING: 	 vision_patch_size: 32
2024-05-22 02:15:50,703:WARNING: 	 context_length: 77
2024-05-22 02:15:50,703:WARNING: 	 vocab_size: 49408
2024-05-22 02:15:50,703:WARNING: 	 transformer_width: 512
2024-05-22 02:15:50,703:WARNING: 	 transformer_heads: 8
2024-05-22 02:15:50,703:WARNING: 	 transformer_layers: 12
2024-05-22 02:15:50,703:WARNING: 	 cut_top_layer: 0
2024-05-22 02:15:51,695:WARNING: 	 sim_type: seqTransf
2024-05-22 02:15:56,172:INFO: --------------------
2024-05-22 02:15:56,172:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-22 02:17:00,901:INFO: device: cuda:0 n_gpu: 1
2024-05-22 02:17:00,901:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-22 02:17:01,133:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-22 02:17:01,133:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-22 02:17:01,133:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-22 02:17:01,133:WARNING: 	 embed_dim: 512
2024-05-22 02:17:01,133:WARNING: 	 image_resolution: 224
2024-05-22 02:17:01,133:WARNING: 	 vision_layers: 12
2024-05-22 02:17:01,133:WARNING: 	 vision_width: 768
2024-05-22 02:17:01,133:WARNING: 	 vision_patch_size: 32
2024-05-22 02:17:01,133:WARNING: 	 context_length: 77
2024-05-22 02:17:01,133:WARNING: 	 vocab_size: 49408
2024-05-22 02:17:01,133:WARNING: 	 transformer_width: 512
2024-05-22 02:17:01,133:WARNING: 	 transformer_heads: 8
2024-05-22 02:17:01,133:WARNING: 	 transformer_layers: 12
2024-05-22 02:17:01,133:WARNING: 	 cut_top_layer: 0
2024-05-22 02:17:02,111:WARNING: 	 sim_type: seqTransf
2024-05-22 02:17:06,584:INFO: --------------------
2024-05-22 02:17:06,584:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-22 02:17:55,591:INFO: device: cuda:0 n_gpu: 1
2024-05-22 02:17:55,591:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-22 02:17:55,824:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-22 02:17:55,825:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-22 02:17:55,825:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-22 02:17:55,825:WARNING: 	 embed_dim: 512
2024-05-22 02:17:55,825:WARNING: 	 image_resolution: 224
2024-05-22 02:17:55,825:WARNING: 	 vision_layers: 12
2024-05-22 02:17:55,825:WARNING: 	 vision_width: 768
2024-05-22 02:17:55,825:WARNING: 	 vision_patch_size: 32
2024-05-22 02:17:55,825:WARNING: 	 context_length: 77
2024-05-22 02:17:55,825:WARNING: 	 vocab_size: 49408
2024-05-22 02:17:55,825:WARNING: 	 transformer_width: 512
2024-05-22 02:17:55,825:WARNING: 	 transformer_heads: 8
2024-05-22 02:17:55,825:WARNING: 	 transformer_layers: 12
2024-05-22 02:17:55,825:WARNING: 	 cut_top_layer: 0
2024-05-22 02:17:56,798:WARNING: 	 sim_type: seqTransf
2024-05-22 02:18:01,280:INFO: --------------------
2024-05-22 02:18:01,280:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-22 02:19:47,225:INFO: device: cuda:0 n_gpu: 1
2024-05-22 02:19:47,305:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-22 02:19:47,522:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-22 02:19:47,522:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-22 02:19:47,522:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-22 02:19:47,523:WARNING: 	 embed_dim: 512
2024-05-22 02:19:47,523:WARNING: 	 image_resolution: 224
2024-05-22 02:19:47,523:WARNING: 	 vision_layers: 12
2024-05-22 02:19:47,523:WARNING: 	 vision_width: 768
2024-05-22 02:19:47,523:WARNING: 	 vision_patch_size: 32
2024-05-22 02:19:47,523:WARNING: 	 context_length: 77
2024-05-22 02:19:47,523:WARNING: 	 vocab_size: 49408
2024-05-22 02:19:47,523:WARNING: 	 transformer_width: 512
2024-05-22 02:19:47,523:WARNING: 	 transformer_heads: 8
2024-05-22 02:19:47,523:WARNING: 	 transformer_layers: 12
2024-05-22 02:19:47,523:WARNING: 	 cut_top_layer: 0
2024-05-22 02:19:48,501:WARNING: 	 sim_type: seqTransf
2024-05-22 02:19:52,986:INFO: --------------------
2024-05-22 02:19:52,986:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-22 02:19:54,735:INFO: ***** Running test *****
2024-05-22 02:19:54,735:INFO:   Num examples = 1
2024-05-22 02:19:54,735:INFO:   Batch size = 64
2024-05-22 02:19:54,735:INFO:   Num steps = 1
2024-05-22 02:19:54,927:INFO: sim matrix size: 1, 1
2024-05-22 02:19:54,927:INFO: 	 Length-T: 1, Length-V:1
2024-05-22 02:19:54,927:INFO: Text-to-Video:
2024-05-22 02:19:54,927:INFO: 	>>>  R@1: 100.0 - R@5: 100.0 - R@10: 100.0 - Median R: 1.0 - Mean R: 1.0
2024-05-22 02:19:54,927:INFO: Video-to-Text:
2024-05-22 02:19:54,927:INFO: 	>>>  V2T$R@1: 100.0 - V2T$R@5: 100.0 - V2T$R@10: 100.0 - V2T$Median R: 1.0 - V2T$Mean R: 1.0
2024-05-22 02:21:07,561:INFO: device: cuda:0 n_gpu: 1
2024-05-22 02:21:07,631:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-22 02:21:07,845:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-22 02:21:07,845:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-22 02:21:07,845:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-22 02:21:07,846:WARNING: 	 embed_dim: 512
2024-05-22 02:21:07,846:WARNING: 	 image_resolution: 224
2024-05-22 02:21:07,846:WARNING: 	 vision_layers: 12
2024-05-22 02:21:07,846:WARNING: 	 vision_width: 768
2024-05-22 02:21:07,846:WARNING: 	 vision_patch_size: 32
2024-05-22 02:21:07,846:WARNING: 	 context_length: 77
2024-05-22 02:21:07,846:WARNING: 	 vocab_size: 49408
2024-05-22 02:21:07,846:WARNING: 	 transformer_width: 512
2024-05-22 02:21:07,846:WARNING: 	 transformer_heads: 8
2024-05-22 02:21:07,846:WARNING: 	 transformer_layers: 12
2024-05-22 02:21:07,846:WARNING: 	 cut_top_layer: 0
2024-05-22 02:21:08,813:WARNING: 	 sim_type: seqTransf
2024-05-22 02:21:13,278:INFO: --------------------
2024-05-22 02:21:13,279:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-22 02:21:15,030:INFO: ***** Running test *****
2024-05-22 02:21:15,030:INFO:   Num examples = 1
2024-05-22 02:21:15,030:INFO:   Batch size = 64
2024-05-22 02:21:15,030:INFO:   Num steps = 1
2024-05-22 02:21:15,222:INFO: sim matrix size: 1, 1
2024-05-22 02:21:15,222:INFO: 	 Length-T: 1, Length-V:1
2024-05-22 02:21:15,222:INFO: Text-to-Video:
2024-05-22 02:21:15,222:INFO: 	>>>  R@1: 100.0 - R@5: 100.0 - R@10: 100.0 - Median R: 1.0 - Mean R: 1.0
2024-05-22 02:21:15,222:INFO: Video-to-Text:
2024-05-22 02:21:15,222:INFO: 	>>>  V2T$R@1: 100.0 - V2T$R@5: 100.0 - V2T$R@10: 100.0 - V2T$Median R: 1.0 - V2T$Mean R: 1.0
2024-05-22 02:49:40,189:INFO: device: cuda:0 n_gpu: 1
2024-05-22 02:49:40,259:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-22 02:49:40,483:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-22 02:49:40,483:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-22 02:49:40,483:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-22 02:49:40,483:WARNING: 	 embed_dim: 512
2024-05-22 02:49:40,483:WARNING: 	 image_resolution: 224
2024-05-22 02:49:40,483:WARNING: 	 vision_layers: 12
2024-05-22 02:49:40,483:WARNING: 	 vision_width: 768
2024-05-22 02:49:40,483:WARNING: 	 vision_patch_size: 32
2024-05-22 02:49:40,483:WARNING: 	 context_length: 77
2024-05-22 02:49:40,483:WARNING: 	 vocab_size: 49408
2024-05-22 02:49:40,483:WARNING: 	 transformer_width: 512
2024-05-22 02:49:40,483:WARNING: 	 transformer_heads: 8
2024-05-22 02:49:40,483:WARNING: 	 transformer_layers: 12
2024-05-22 02:49:40,483:WARNING: 	 cut_top_layer: 0
2024-05-22 02:49:41,468:WARNING: 	 sim_type: seqTransf
2024-05-22 02:49:45,943:INFO: --------------------
2024-05-22 02:49:45,944:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-22 02:49:47,724:INFO: ***** Running test *****
2024-05-22 02:49:47,724:INFO:   Num examples = 1
2024-05-22 02:49:47,724:INFO:   Batch size = 64
2024-05-22 02:49:47,724:INFO:   Num steps = 1
2024-05-22 02:50:23,273:INFO: device: cuda:0 n_gpu: 1
2024-05-22 02:50:23,344:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-22 02:50:23,566:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-22 02:50:23,567:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-22 02:50:23,567:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-22 02:50:23,567:WARNING: 	 embed_dim: 512
2024-05-22 02:50:23,567:WARNING: 	 image_resolution: 224
2024-05-22 02:50:23,567:WARNING: 	 vision_layers: 12
2024-05-22 02:50:23,567:WARNING: 	 vision_width: 768
2024-05-22 02:50:23,567:WARNING: 	 vision_patch_size: 32
2024-05-22 02:50:23,567:WARNING: 	 context_length: 77
2024-05-22 02:50:23,567:WARNING: 	 vocab_size: 49408
2024-05-22 02:50:23,567:WARNING: 	 transformer_width: 512
2024-05-22 02:50:23,567:WARNING: 	 transformer_heads: 8
2024-05-22 02:50:23,567:WARNING: 	 transformer_layers: 12
2024-05-22 02:50:23,567:WARNING: 	 cut_top_layer: 0
2024-05-22 02:50:24,540:WARNING: 	 sim_type: seqTransf
2024-05-22 02:50:29,012:INFO: --------------------
2024-05-22 02:50:29,013:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-22 02:50:30,785:INFO: ***** Running test *****
2024-05-22 02:50:30,785:INFO:   Num examples = 1
2024-05-22 02:50:30,785:INFO:   Batch size = 64
2024-05-22 02:50:30,785:INFO:   Num steps = 1
2024-05-22 02:50:30,987:INFO: sim matrix size: 1, 1
2024-05-22 02:50:30,987:INFO: 	 Length-T: 1, Length-V:1
2024-05-22 02:50:30,987:INFO: Text-to-Video:
2024-05-22 02:50:30,988:INFO: 	>>>  R@1: 100.0 - R@5: 100.0 - R@10: 100.0 - Median R: 1.0 - Mean R: 1.0
2024-05-22 02:50:30,988:INFO: Video-to-Text:
2024-05-22 02:50:30,988:INFO: 	>>>  V2T$R@1: 100.0 - V2T$R@5: 100.0 - V2T$R@10: 100.0 - V2T$Median R: 1.0 - V2T$Mean R: 1.0
2024-05-22 02:51:36,161:INFO: device: cuda:0 n_gpu: 1
2024-05-22 02:51:36,232:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-22 02:51:36,472:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-22 02:51:36,474:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-22 02:51:36,474:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-22 02:51:36,475:WARNING: 	 embed_dim: 512
2024-05-22 02:51:36,475:WARNING: 	 image_resolution: 224
2024-05-22 02:51:36,475:WARNING: 	 vision_layers: 12
2024-05-22 02:51:36,475:WARNING: 	 vision_width: 768
2024-05-22 02:51:36,475:WARNING: 	 vision_patch_size: 32
2024-05-22 02:51:36,475:WARNING: 	 context_length: 77
2024-05-22 02:51:36,475:WARNING: 	 vocab_size: 49408
2024-05-22 02:51:36,475:WARNING: 	 transformer_width: 512
2024-05-22 02:51:36,475:WARNING: 	 transformer_heads: 8
2024-05-22 02:51:36,475:WARNING: 	 transformer_layers: 12
2024-05-22 02:51:36,475:WARNING: 	 cut_top_layer: 0
2024-05-22 02:51:37,478:WARNING: 	 sim_type: seqTransf
2024-05-22 02:51:41,957:INFO: --------------------
2024-05-22 02:51:41,957:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-22 02:51:43,749:INFO: ***** Running test *****
2024-05-22 02:51:43,749:INFO:   Num examples = 1
2024-05-22 02:51:43,749:INFO:   Batch size = 64
2024-05-22 02:51:43,749:INFO:   Num steps = 1
2024-05-22 02:52:34,578:INFO: device: cuda:0 n_gpu: 1
2024-05-22 02:52:34,646:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-22 02:52:34,884:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-22 02:52:34,885:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-22 02:52:34,885:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-22 02:52:34,886:WARNING: 	 embed_dim: 512
2024-05-22 02:52:34,886:WARNING: 	 image_resolution: 224
2024-05-22 02:52:34,886:WARNING: 	 vision_layers: 12
2024-05-22 02:52:34,886:WARNING: 	 vision_width: 768
2024-05-22 02:52:34,886:WARNING: 	 vision_patch_size: 32
2024-05-22 02:52:34,886:WARNING: 	 context_length: 77
2024-05-22 02:52:34,886:WARNING: 	 vocab_size: 49408
2024-05-22 02:52:34,887:WARNING: 	 transformer_width: 512
2024-05-22 02:52:34,887:WARNING: 	 transformer_heads: 8
2024-05-22 02:52:34,887:WARNING: 	 transformer_layers: 12
2024-05-22 02:52:34,887:WARNING: 	 cut_top_layer: 0
2024-05-22 02:52:35,907:WARNING: 	 sim_type: seqTransf
2024-05-22 02:52:40,404:INFO: --------------------
2024-05-22 02:52:40,404:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-22 02:52:42,189:INFO: ***** Running test *****
2024-05-22 02:52:42,189:INFO:   Num examples = 1
2024-05-22 02:52:42,190:INFO:   Batch size = 64
2024-05-22 02:52:42,190:INFO:   Num steps = 1
2024-05-22 02:59:58,141:INFO: device: cuda:0 n_gpu: 1
2024-05-22 02:59:58,141:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-22 02:59:58,373:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-22 02:59:58,373:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-22 02:59:58,373:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-22 02:59:58,373:WARNING: 	 embed_dim: 512
2024-05-22 02:59:58,373:WARNING: 	 image_resolution: 224
2024-05-22 02:59:58,373:WARNING: 	 vision_layers: 12
2024-05-22 02:59:58,373:WARNING: 	 vision_width: 768
2024-05-22 02:59:58,373:WARNING: 	 vision_patch_size: 32
2024-05-22 02:59:58,373:WARNING: 	 context_length: 77
2024-05-22 02:59:58,373:WARNING: 	 vocab_size: 49408
2024-05-22 02:59:58,373:WARNING: 	 transformer_width: 512
2024-05-22 02:59:58,373:WARNING: 	 transformer_heads: 8
2024-05-22 02:59:58,373:WARNING: 	 transformer_layers: 12
2024-05-22 02:59:58,373:WARNING: 	 cut_top_layer: 0
2024-05-22 02:59:59,362:WARNING: 	 sim_type: seqTransf
2024-05-22 03:00:03,863:INFO: --------------------
2024-05-22 03:00:03,863:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-22 03:01:19,672:INFO: device: cuda:0 n_gpu: 1
2024-05-22 03:01:19,746:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-22 03:01:19,984:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-22 03:01:19,985:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-22 03:01:19,986:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-22 03:01:19,986:WARNING: 	 embed_dim: 512
2024-05-22 03:01:19,986:WARNING: 	 image_resolution: 224
2024-05-22 03:01:19,987:WARNING: 	 vision_layers: 12
2024-05-22 03:01:19,987:WARNING: 	 vision_width: 768
2024-05-22 03:01:19,987:WARNING: 	 vision_patch_size: 32
2024-05-22 03:01:19,987:WARNING: 	 context_length: 77
2024-05-22 03:01:19,987:WARNING: 	 vocab_size: 49408
2024-05-22 03:01:19,987:WARNING: 	 transformer_width: 512
2024-05-22 03:01:19,987:WARNING: 	 transformer_heads: 8
2024-05-22 03:01:19,987:WARNING: 	 transformer_layers: 12
2024-05-22 03:01:19,987:WARNING: 	 cut_top_layer: 0
2024-05-22 03:01:20,984:WARNING: 	 sim_type: seqTransf
2024-05-22 03:01:25,453:INFO: --------------------
2024-05-22 03:01:25,453:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-22 03:01:27,242:INFO: ***** Running test *****
2024-05-22 03:01:27,242:INFO:   Num examples = 1
2024-05-22 03:01:27,242:INFO:   Batch size = 64
2024-05-22 03:01:27,242:INFO:   Num steps = 1
2024-05-22 03:05:37,919:INFO: device: cuda:0 n_gpu: 1
2024-05-22 03:05:37,994:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-22 03:05:38,232:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-22 03:05:38,233:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-22 03:05:38,233:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-22 03:05:38,234:WARNING: 	 embed_dim: 512
2024-05-22 03:05:38,234:WARNING: 	 image_resolution: 224
2024-05-22 03:05:38,234:WARNING: 	 vision_layers: 12
2024-05-22 03:05:38,234:WARNING: 	 vision_width: 768
2024-05-22 03:05:38,234:WARNING: 	 vision_patch_size: 32
2024-05-22 03:05:38,234:WARNING: 	 context_length: 77
2024-05-22 03:05:38,235:WARNING: 	 vocab_size: 49408
2024-05-22 03:05:38,235:WARNING: 	 transformer_width: 512
2024-05-22 03:05:38,235:WARNING: 	 transformer_heads: 8
2024-05-22 03:05:38,235:WARNING: 	 transformer_layers: 12
2024-05-22 03:05:38,235:WARNING: 	 cut_top_layer: 0
2024-05-22 03:05:39,239:WARNING: 	 sim_type: seqTransf
2024-05-22 03:05:43,740:INFO: --------------------
2024-05-22 03:05:43,740:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-22 03:05:45,571:INFO: ***** Running test *****
2024-05-22 03:05:45,571:INFO:   Num examples = 1
2024-05-22 03:05:45,571:INFO:   Batch size = 64
2024-05-22 03:05:45,571:INFO:   Num steps = 1
2024-05-22 03:09:44,852:INFO: sim matrix size: 1, 1
2024-05-22 03:09:44,853:INFO: 	 Length-T: 1, Length-V:1
2024-05-22 03:09:44,853:INFO: Text-to-Video:
2024-05-22 03:09:44,854:INFO: 	>>>  R@1: 100.0 - R@5: 100.0 - R@10: 100.0 - Median R: 1.0 - Mean R: 1.0
2024-05-22 03:09:44,854:INFO: Video-to-Text:
2024-05-22 03:09:44,854:INFO: 	>>>  V2T$R@1: 100.0 - V2T$R@5: 100.0 - V2T$R@10: 100.0 - V2T$Median R: 1.0 - V2T$Mean R: 1.0
2024-05-22 03:09:48,834:INFO: device: cuda:0 n_gpu: 1
2024-05-22 03:09:48,903:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-22 03:09:49,143:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-22 03:09:49,144:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-22 03:09:49,144:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-22 03:09:49,145:WARNING: 	 embed_dim: 512
2024-05-22 03:09:49,145:WARNING: 	 image_resolution: 224
2024-05-22 03:09:49,145:WARNING: 	 vision_layers: 12
2024-05-22 03:09:49,145:WARNING: 	 vision_width: 768
2024-05-22 03:09:49,146:WARNING: 	 vision_patch_size: 32
2024-05-22 03:09:49,146:WARNING: 	 context_length: 77
2024-05-22 03:09:49,146:WARNING: 	 vocab_size: 49408
2024-05-22 03:09:49,146:WARNING: 	 transformer_width: 512
2024-05-22 03:09:49,146:WARNING: 	 transformer_heads: 8
2024-05-22 03:09:49,146:WARNING: 	 transformer_layers: 12
2024-05-22 03:09:49,146:WARNING: 	 cut_top_layer: 0
2024-05-22 03:09:50,149:WARNING: 	 sim_type: seqTransf
2024-05-22 03:09:54,653:INFO: --------------------
2024-05-22 03:09:54,653:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-22 03:09:56,440:INFO: ***** Running test *****
2024-05-22 03:09:56,440:INFO:   Num examples = 1
2024-05-22 03:09:56,440:INFO:   Batch size = 64
2024-05-22 03:09:56,440:INFO:   Num steps = 1
2024-05-22 03:10:14,301:INFO: device: cuda:0 n_gpu: 1
2024-05-22 03:10:14,375:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-22 03:10:14,623:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-22 03:10:14,624:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-22 03:10:14,624:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-22 03:10:14,625:WARNING: 	 embed_dim: 512
2024-05-22 03:10:14,625:WARNING: 	 image_resolution: 224
2024-05-22 03:10:14,625:WARNING: 	 vision_layers: 12
2024-05-22 03:10:14,625:WARNING: 	 vision_width: 768
2024-05-22 03:10:14,625:WARNING: 	 vision_patch_size: 32
2024-05-22 03:10:14,625:WARNING: 	 context_length: 77
2024-05-22 03:10:14,626:WARNING: 	 vocab_size: 49408
2024-05-22 03:10:14,626:WARNING: 	 transformer_width: 512
2024-05-22 03:10:14,626:WARNING: 	 transformer_heads: 8
2024-05-22 03:10:14,626:WARNING: 	 transformer_layers: 12
2024-05-22 03:10:14,626:WARNING: 	 cut_top_layer: 0
2024-05-22 03:10:15,634:WARNING: 	 sim_type: seqTransf
2024-05-22 03:10:20,124:INFO: --------------------
2024-05-22 03:10:20,124:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-22 03:10:21,924:INFO: ***** Running test *****
2024-05-22 03:10:21,924:INFO:   Num examples = 1
2024-05-22 03:10:21,924:INFO:   Batch size = 64
2024-05-22 03:10:21,924:INFO:   Num steps = 1
2024-05-22 03:12:31,878:INFO: device: cuda:0 n_gpu: 1
2024-05-22 03:12:31,878:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-22 03:12:32,110:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-22 03:12:32,110:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-22 03:12:32,110:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-22 03:12:32,111:WARNING: 	 embed_dim: 512
2024-05-22 03:12:32,111:WARNING: 	 image_resolution: 224
2024-05-22 03:12:32,111:WARNING: 	 vision_layers: 12
2024-05-22 03:12:32,111:WARNING: 	 vision_width: 768
2024-05-22 03:12:32,111:WARNING: 	 vision_patch_size: 32
2024-05-22 03:12:32,111:WARNING: 	 context_length: 77
2024-05-22 03:12:32,111:WARNING: 	 vocab_size: 49408
2024-05-22 03:12:32,111:WARNING: 	 transformer_width: 512
2024-05-22 03:12:32,111:WARNING: 	 transformer_heads: 8
2024-05-22 03:12:32,111:WARNING: 	 transformer_layers: 12
2024-05-22 03:12:32,111:WARNING: 	 cut_top_layer: 0
2024-05-22 03:12:33,107:WARNING: 	 sim_type: seqTransf
2024-05-22 03:12:37,626:INFO: --------------------
2024-05-22 03:12:37,626:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-22 03:13:06,715:INFO: device: cuda:0 n_gpu: 1
2024-05-22 03:13:06,715:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-22 03:13:06,953:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-22 03:13:06,953:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-22 03:13:06,953:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-22 03:13:06,954:WARNING: 	 embed_dim: 512
2024-05-22 03:13:06,954:WARNING: 	 image_resolution: 224
2024-05-22 03:13:06,954:WARNING: 	 vision_layers: 12
2024-05-22 03:13:06,954:WARNING: 	 vision_width: 768
2024-05-22 03:13:06,954:WARNING: 	 vision_patch_size: 32
2024-05-22 03:13:06,954:WARNING: 	 context_length: 77
2024-05-22 03:13:06,954:WARNING: 	 vocab_size: 49408
2024-05-22 03:13:06,954:WARNING: 	 transformer_width: 512
2024-05-22 03:13:06,954:WARNING: 	 transformer_heads: 8
2024-05-22 03:13:06,954:WARNING: 	 transformer_layers: 12
2024-05-22 03:13:06,954:WARNING: 	 cut_top_layer: 0
2024-05-22 03:13:07,946:WARNING: 	 sim_type: seqTransf
2024-05-22 03:13:12,427:INFO: --------------------
2024-05-22 03:13:12,428:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-22 03:14:06,017:INFO: device: cuda:0 n_gpu: 1
2024-05-22 03:14:06,018:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-22 03:14:06,249:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-22 03:14:06,249:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-22 03:14:06,249:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-22 03:14:06,249:WARNING: 	 embed_dim: 512
2024-05-22 03:14:06,250:WARNING: 	 image_resolution: 224
2024-05-22 03:14:06,250:WARNING: 	 vision_layers: 12
2024-05-22 03:14:06,250:WARNING: 	 vision_width: 768
2024-05-22 03:14:06,250:WARNING: 	 vision_patch_size: 32
2024-05-22 03:14:06,250:WARNING: 	 context_length: 77
2024-05-22 03:14:06,250:WARNING: 	 vocab_size: 49408
2024-05-22 03:14:06,250:WARNING: 	 transformer_width: 512
2024-05-22 03:14:06,250:WARNING: 	 transformer_heads: 8
2024-05-22 03:14:06,250:WARNING: 	 transformer_layers: 12
2024-05-22 03:14:06,250:WARNING: 	 cut_top_layer: 0
2024-05-22 03:14:07,234:WARNING: 	 sim_type: seqTransf
2024-05-22 03:14:11,693:INFO: --------------------
2024-05-22 03:14:11,693:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-22 03:19:34,570:INFO: device: cuda:0 n_gpu: 1
2024-05-22 03:19:34,570:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-22 03:19:34,801:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-22 03:19:34,801:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-22 03:19:34,801:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-22 03:19:34,801:WARNING: 	 embed_dim: 512
2024-05-22 03:19:34,801:WARNING: 	 image_resolution: 224
2024-05-22 03:19:34,801:WARNING: 	 vision_layers: 12
2024-05-22 03:19:34,801:WARNING: 	 vision_width: 768
2024-05-22 03:19:34,801:WARNING: 	 vision_patch_size: 32
2024-05-22 03:19:34,801:WARNING: 	 context_length: 77
2024-05-22 03:19:34,801:WARNING: 	 vocab_size: 49408
2024-05-22 03:19:34,801:WARNING: 	 transformer_width: 512
2024-05-22 03:19:34,801:WARNING: 	 transformer_heads: 8
2024-05-22 03:19:34,801:WARNING: 	 transformer_layers: 12
2024-05-22 03:19:34,801:WARNING: 	 cut_top_layer: 0
2024-05-22 03:19:35,799:WARNING: 	 sim_type: seqTransf
2024-05-22 03:19:40,305:INFO: --------------------
2024-05-22 03:19:40,305:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-22 03:20:30,662:INFO: device: cuda:0 n_gpu: 1
2024-05-22 03:20:30,662:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-22 03:20:30,902:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-22 03:20:30,903:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-22 03:20:30,903:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-22 03:20:30,903:WARNING: 	 embed_dim: 512
2024-05-22 03:20:30,903:WARNING: 	 image_resolution: 224
2024-05-22 03:20:30,903:WARNING: 	 vision_layers: 12
2024-05-22 03:20:30,903:WARNING: 	 vision_width: 768
2024-05-22 03:20:30,903:WARNING: 	 vision_patch_size: 32
2024-05-22 03:20:30,903:WARNING: 	 context_length: 77
2024-05-22 03:20:30,903:WARNING: 	 vocab_size: 49408
2024-05-22 03:20:30,903:WARNING: 	 transformer_width: 512
2024-05-22 03:20:30,903:WARNING: 	 transformer_heads: 8
2024-05-22 03:20:30,903:WARNING: 	 transformer_layers: 12
2024-05-22 03:20:30,903:WARNING: 	 cut_top_layer: 0
2024-05-22 03:20:31,897:WARNING: 	 sim_type: seqTransf
2024-05-22 03:20:36,368:INFO: --------------------
2024-05-22 03:20:36,368:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-22 03:21:03,738:INFO: device: cuda:0 n_gpu: 1
2024-05-22 03:21:03,739:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-22 03:21:03,986:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-22 03:21:03,987:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-22 03:21:03,987:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-22 03:21:03,988:WARNING: 	 embed_dim: 512
2024-05-22 03:21:03,988:WARNING: 	 image_resolution: 224
2024-05-22 03:21:03,988:WARNING: 	 vision_layers: 12
2024-05-22 03:21:03,988:WARNING: 	 vision_width: 768
2024-05-22 03:21:03,988:WARNING: 	 vision_patch_size: 32
2024-05-22 03:21:03,988:WARNING: 	 context_length: 77
2024-05-22 03:21:03,988:WARNING: 	 vocab_size: 49408
2024-05-22 03:21:03,988:WARNING: 	 transformer_width: 512
2024-05-22 03:21:03,989:WARNING: 	 transformer_heads: 8
2024-05-22 03:21:03,989:WARNING: 	 transformer_layers: 12
2024-05-22 03:21:03,989:WARNING: 	 cut_top_layer: 0
2024-05-22 03:21:04,999:WARNING: 	 sim_type: seqTransf
2024-05-22 03:21:09,507:INFO: --------------------
2024-05-22 03:21:09,507:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-22 03:22:08,254:INFO: device: cuda:0 n_gpu: 1
2024-05-22 03:22:08,254:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-22 03:22:08,485:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-22 03:22:08,486:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-22 03:22:08,486:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-22 03:22:08,486:WARNING: 	 embed_dim: 512
2024-05-22 03:22:08,486:WARNING: 	 image_resolution: 224
2024-05-22 03:22:08,486:WARNING: 	 vision_layers: 12
2024-05-22 03:22:08,486:WARNING: 	 vision_width: 768
2024-05-22 03:22:08,486:WARNING: 	 vision_patch_size: 32
2024-05-22 03:22:08,486:WARNING: 	 context_length: 77
2024-05-22 03:22:08,486:WARNING: 	 vocab_size: 49408
2024-05-22 03:22:08,486:WARNING: 	 transformer_width: 512
2024-05-22 03:22:08,486:WARNING: 	 transformer_heads: 8
2024-05-22 03:22:08,486:WARNING: 	 transformer_layers: 12
2024-05-22 03:22:08,486:WARNING: 	 cut_top_layer: 0
2024-05-22 03:22:09,482:WARNING: 	 sim_type: seqTransf
2024-05-22 03:22:13,972:INFO: --------------------
2024-05-22 03:22:13,972:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-22 03:29:30,222:INFO: device: cuda:0 n_gpu: 1
2024-05-22 03:29:30,222:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-22 03:29:30,454:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-22 03:29:30,454:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-22 03:29:30,454:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-22 03:29:30,454:WARNING: 	 embed_dim: 512
2024-05-22 03:29:30,454:WARNING: 	 image_resolution: 224
2024-05-22 03:29:30,454:WARNING: 	 vision_layers: 12
2024-05-22 03:29:30,455:WARNING: 	 vision_width: 768
2024-05-22 03:29:30,455:WARNING: 	 vision_patch_size: 32
2024-05-22 03:29:30,455:WARNING: 	 context_length: 77
2024-05-22 03:29:30,455:WARNING: 	 vocab_size: 49408
2024-05-22 03:29:30,455:WARNING: 	 transformer_width: 512
2024-05-22 03:29:30,455:WARNING: 	 transformer_heads: 8
2024-05-22 03:29:30,455:WARNING: 	 transformer_layers: 12
2024-05-22 03:29:30,455:WARNING: 	 cut_top_layer: 0
2024-05-22 03:29:31,452:WARNING: 	 sim_type: seqTransf
2024-05-22 03:29:35,934:INFO: --------------------
2024-05-22 03:29:35,935:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-22 03:29:43,221:INFO: device: cuda:0 n_gpu: 1
2024-05-22 03:29:43,221:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-22 03:29:43,452:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-22 03:29:43,452:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-22 03:29:43,452:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-22 03:29:43,453:WARNING: 	 embed_dim: 512
2024-05-22 03:29:43,453:WARNING: 	 image_resolution: 224
2024-05-22 03:29:43,453:WARNING: 	 vision_layers: 12
2024-05-22 03:29:43,453:WARNING: 	 vision_width: 768
2024-05-22 03:29:43,453:WARNING: 	 vision_patch_size: 32
2024-05-22 03:29:43,453:WARNING: 	 context_length: 77
2024-05-22 03:29:43,453:WARNING: 	 vocab_size: 49408
2024-05-22 03:29:43,453:WARNING: 	 transformer_width: 512
2024-05-22 03:29:43,453:WARNING: 	 transformer_heads: 8
2024-05-22 03:29:43,453:WARNING: 	 transformer_layers: 12
2024-05-22 03:29:43,453:WARNING: 	 cut_top_layer: 0
2024-05-22 03:29:44,447:WARNING: 	 sim_type: seqTransf
2024-05-22 03:29:48,936:INFO: --------------------
2024-05-22 03:29:48,936:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-22 03:32:29,358:INFO: device: cuda:0 n_gpu: 1
2024-05-22 03:32:29,359:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-22 03:32:29,593:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-22 03:32:29,593:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-22 03:32:29,593:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-22 03:32:29,594:WARNING: 	 embed_dim: 512
2024-05-22 03:32:29,594:WARNING: 	 image_resolution: 224
2024-05-22 03:32:29,594:WARNING: 	 vision_layers: 12
2024-05-22 03:32:29,594:WARNING: 	 vision_width: 768
2024-05-22 03:32:29,594:WARNING: 	 vision_patch_size: 32
2024-05-22 03:32:29,594:WARNING: 	 context_length: 77
2024-05-22 03:32:29,594:WARNING: 	 vocab_size: 49408
2024-05-22 03:32:29,594:WARNING: 	 transformer_width: 512
2024-05-22 03:32:29,594:WARNING: 	 transformer_heads: 8
2024-05-22 03:32:29,594:WARNING: 	 transformer_layers: 12
2024-05-22 03:32:29,594:WARNING: 	 cut_top_layer: 0
2024-05-22 03:32:30,600:WARNING: 	 sim_type: seqTransf
2024-05-22 03:32:35,102:INFO: --------------------
2024-05-22 03:32:35,102:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-22 03:49:58,641:INFO: device: cuda:0 n_gpu: 1
2024-05-22 03:49:58,711:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-22 03:49:58,949:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-22 03:49:58,950:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-22 03:49:58,951:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-22 03:49:58,951:WARNING: 	 embed_dim: 512
2024-05-22 03:49:58,952:WARNING: 	 image_resolution: 224
2024-05-22 03:49:58,952:WARNING: 	 vision_layers: 12
2024-05-22 03:49:58,952:WARNING: 	 vision_width: 768
2024-05-22 03:49:58,952:WARNING: 	 vision_patch_size: 32
2024-05-22 03:49:58,952:WARNING: 	 context_length: 77
2024-05-22 03:49:58,952:WARNING: 	 vocab_size: 49408
2024-05-22 03:49:58,952:WARNING: 	 transformer_width: 512
2024-05-22 03:49:58,952:WARNING: 	 transformer_heads: 8
2024-05-22 03:49:58,952:WARNING: 	 transformer_layers: 12
2024-05-22 03:49:58,952:WARNING: 	 cut_top_layer: 0
2024-05-22 03:49:59,960:WARNING: 	 sim_type: seqTransf
2024-05-22 03:50:04,460:INFO: --------------------
2024-05-22 03:50:04,460:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-22 03:50:06,248:INFO: ***** Running test *****
2024-05-22 03:50:06,249:INFO:   Num examples = 1
2024-05-22 03:50:06,249:INFO:   Batch size = 64
2024-05-22 03:50:06,249:INFO:   Num steps = 1
2024-05-22 03:52:01,029:INFO: device: cuda:0 n_gpu: 1
2024-05-22 03:52:01,099:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-22 03:52:01,340:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-22 03:52:01,341:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-22 03:52:01,341:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-22 03:52:01,342:WARNING: 	 embed_dim: 512
2024-05-22 03:52:01,342:WARNING: 	 image_resolution: 224
2024-05-22 03:52:01,342:WARNING: 	 vision_layers: 12
2024-05-22 03:52:01,343:WARNING: 	 vision_width: 768
2024-05-22 03:52:01,343:WARNING: 	 vision_patch_size: 32
2024-05-22 03:52:01,343:WARNING: 	 context_length: 77
2024-05-22 03:52:01,343:WARNING: 	 vocab_size: 49408
2024-05-22 03:52:01,343:WARNING: 	 transformer_width: 512
2024-05-22 03:52:01,343:WARNING: 	 transformer_heads: 8
2024-05-22 03:52:01,343:WARNING: 	 transformer_layers: 12
2024-05-22 03:52:01,343:WARNING: 	 cut_top_layer: 0
2024-05-22 03:52:02,347:WARNING: 	 sim_type: seqTransf
2024-05-22 03:52:06,847:INFO: --------------------
2024-05-22 03:52:06,847:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-22 03:52:08,630:INFO: ***** Running test *****
2024-05-22 03:52:08,630:INFO:   Num examples = 1
2024-05-22 03:52:08,630:INFO:   Batch size = 64
2024-05-22 03:52:08,630:INFO:   Num steps = 1
2024-05-22 04:10:18,081:INFO: device: cuda:0 n_gpu: 1
2024-05-22 04:10:18,150:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-22 04:10:18,368:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-22 04:10:18,368:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-22 04:10:18,368:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-22 04:10:18,368:WARNING: 	 embed_dim: 512
2024-05-22 04:10:18,368:WARNING: 	 image_resolution: 224
2024-05-22 04:10:18,368:WARNING: 	 vision_layers: 12
2024-05-22 04:10:18,368:WARNING: 	 vision_width: 768
2024-05-22 04:10:18,368:WARNING: 	 vision_patch_size: 32
2024-05-22 04:10:18,368:WARNING: 	 context_length: 77
2024-05-22 04:10:18,368:WARNING: 	 vocab_size: 49408
2024-05-22 04:10:18,368:WARNING: 	 transformer_width: 512
2024-05-22 04:10:18,368:WARNING: 	 transformer_heads: 8
2024-05-22 04:10:18,368:WARNING: 	 transformer_layers: 12
2024-05-22 04:10:18,368:WARNING: 	 cut_top_layer: 0
2024-05-22 04:10:19,338:WARNING: 	 sim_type: seqTransf
2024-05-22 04:10:23,804:INFO: --------------------
2024-05-22 04:10:23,804:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-22 04:10:25,584:INFO: ***** Running test *****
2024-05-22 04:10:25,584:INFO:   Num examples = 1
2024-05-22 04:10:25,584:INFO:   Batch size = 64
2024-05-22 04:10:25,584:INFO:   Num steps = 1
2024-05-22 04:10:50,349:INFO: device: cuda:0 n_gpu: 1
2024-05-22 04:10:50,416:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-22 04:10:50,660:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-22 04:10:50,661:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-22 04:10:50,661:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-22 04:10:50,662:WARNING: 	 embed_dim: 512
2024-05-22 04:10:50,662:WARNING: 	 image_resolution: 224
2024-05-22 04:10:50,662:WARNING: 	 vision_layers: 12
2024-05-22 04:10:50,662:WARNING: 	 vision_width: 768
2024-05-22 04:10:50,662:WARNING: 	 vision_patch_size: 32
2024-05-22 04:10:50,662:WARNING: 	 context_length: 77
2024-05-22 04:10:50,662:WARNING: 	 vocab_size: 49408
2024-05-22 04:10:50,663:WARNING: 	 transformer_width: 512
2024-05-22 04:10:50,663:WARNING: 	 transformer_heads: 8
2024-05-22 04:10:50,663:WARNING: 	 transformer_layers: 12
2024-05-22 04:10:50,663:WARNING: 	 cut_top_layer: 0
2024-05-22 04:10:51,661:WARNING: 	 sim_type: seqTransf
2024-05-22 04:10:56,147:INFO: --------------------
2024-05-22 04:10:56,148:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-22 04:10:57,960:INFO: ***** Running test *****
2024-05-22 04:10:57,960:INFO:   Num examples = 1
2024-05-22 04:10:57,960:INFO:   Batch size = 64
2024-05-22 04:10:57,960:INFO:   Num steps = 1
2024-05-22 04:11:43,565:INFO: device: cuda:0 n_gpu: 1
2024-05-22 04:11:43,632:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-22 04:11:43,877:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-22 04:11:43,878:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-22 04:11:43,878:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-22 04:11:43,879:WARNING: 	 embed_dim: 512
2024-05-22 04:11:43,879:WARNING: 	 image_resolution: 224
2024-05-22 04:11:43,879:WARNING: 	 vision_layers: 12
2024-05-22 04:11:43,879:WARNING: 	 vision_width: 768
2024-05-22 04:11:43,879:WARNING: 	 vision_patch_size: 32
2024-05-22 04:11:43,879:WARNING: 	 context_length: 77
2024-05-22 04:11:43,879:WARNING: 	 vocab_size: 49408
2024-05-22 04:11:43,879:WARNING: 	 transformer_width: 512
2024-05-22 04:11:43,879:WARNING: 	 transformer_heads: 8
2024-05-22 04:11:43,879:WARNING: 	 transformer_layers: 12
2024-05-22 04:11:43,880:WARNING: 	 cut_top_layer: 0
2024-05-22 04:11:44,884:WARNING: 	 sim_type: seqTransf
2024-05-22 04:11:49,385:INFO: --------------------
2024-05-22 04:11:49,385:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-22 04:11:51,194:INFO: ***** Running test *****
2024-05-22 04:11:51,194:INFO:   Num examples = 1
2024-05-22 04:11:51,194:INFO:   Batch size = 64
2024-05-22 04:11:51,194:INFO:   Num steps = 1
2024-05-22 04:13:12,827:INFO: device: cuda:0 n_gpu: 1
2024-05-22 04:13:12,827:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-22 04:13:13,071:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-22 04:13:13,073:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-22 04:13:13,073:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-22 04:13:13,074:WARNING: 	 embed_dim: 512
2024-05-22 04:13:13,074:WARNING: 	 image_resolution: 224
2024-05-22 04:13:13,074:WARNING: 	 vision_layers: 12
2024-05-22 04:13:13,074:WARNING: 	 vision_width: 768
2024-05-22 04:13:13,074:WARNING: 	 vision_patch_size: 32
2024-05-22 04:13:13,074:WARNING: 	 context_length: 77
2024-05-22 04:13:13,074:WARNING: 	 vocab_size: 49408
2024-05-22 04:13:13,074:WARNING: 	 transformer_width: 512
2024-05-22 04:13:13,074:WARNING: 	 transformer_heads: 8
2024-05-22 04:13:13,074:WARNING: 	 transformer_layers: 12
2024-05-22 04:13:13,074:WARNING: 	 cut_top_layer: 0
2024-05-22 04:13:14,080:WARNING: 	 sim_type: seqTransf
2024-05-22 04:13:18,571:INFO: --------------------
2024-05-22 04:13:18,571:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-22 04:13:56,122:INFO: device: cuda:0 n_gpu: 1
2024-05-22 04:13:56,194:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-22 04:13:56,432:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-22 04:13:56,434:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-22 04:13:56,434:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-22 04:13:56,435:WARNING: 	 embed_dim: 512
2024-05-22 04:13:56,435:WARNING: 	 image_resolution: 224
2024-05-22 04:13:56,435:WARNING: 	 vision_layers: 12
2024-05-22 04:13:56,435:WARNING: 	 vision_width: 768
2024-05-22 04:13:56,435:WARNING: 	 vision_patch_size: 32
2024-05-22 04:13:56,435:WARNING: 	 context_length: 77
2024-05-22 04:13:56,435:WARNING: 	 vocab_size: 49408
2024-05-22 04:13:56,435:WARNING: 	 transformer_width: 512
2024-05-22 04:13:56,435:WARNING: 	 transformer_heads: 8
2024-05-22 04:13:56,435:WARNING: 	 transformer_layers: 12
2024-05-22 04:13:56,435:WARNING: 	 cut_top_layer: 0
2024-05-22 04:13:57,432:WARNING: 	 sim_type: seqTransf
2024-05-22 04:14:01,910:INFO: --------------------
2024-05-22 04:14:01,911:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-22 04:14:03,706:INFO: ***** Running test *****
2024-05-22 04:14:03,706:INFO:   Num examples = 1
2024-05-22 04:14:03,706:INFO:   Batch size = 64
2024-05-22 04:14:03,706:INFO:   Num steps = 1
2024-05-22 04:14:40,818:INFO: device: cuda:0 n_gpu: 1
2024-05-22 04:14:40,889:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-22 04:14:41,130:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-22 04:14:41,132:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-22 04:14:41,132:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-22 04:14:41,133:WARNING: 	 embed_dim: 512
2024-05-22 04:14:41,133:WARNING: 	 image_resolution: 224
2024-05-22 04:14:41,133:WARNING: 	 vision_layers: 12
2024-05-22 04:14:41,133:WARNING: 	 vision_width: 768
2024-05-22 04:14:41,133:WARNING: 	 vision_patch_size: 32
2024-05-22 04:14:41,133:WARNING: 	 context_length: 77
2024-05-22 04:14:41,133:WARNING: 	 vocab_size: 49408
2024-05-22 04:14:41,133:WARNING: 	 transformer_width: 512
2024-05-22 04:14:41,133:WARNING: 	 transformer_heads: 8
2024-05-22 04:14:41,133:WARNING: 	 transformer_layers: 12
2024-05-22 04:14:41,133:WARNING: 	 cut_top_layer: 0
2024-05-22 04:14:42,134:WARNING: 	 sim_type: seqTransf
2024-05-22 04:14:46,667:INFO: --------------------
2024-05-22 04:14:46,668:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-22 04:14:48,457:INFO: ***** Running test *****
2024-05-22 04:14:48,457:INFO:   Num examples = 1
2024-05-22 04:14:48,457:INFO:   Batch size = 64
2024-05-22 04:14:48,457:INFO:   Num steps = 1
2024-05-22 04:15:01,034:INFO: device: cuda:0 n_gpu: 1
2024-05-22 04:15:01,103:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-22 04:15:01,342:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-22 04:15:01,344:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-22 04:15:01,344:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-22 04:15:01,345:WARNING: 	 embed_dim: 512
2024-05-22 04:15:01,345:WARNING: 	 image_resolution: 224
2024-05-22 04:15:01,345:WARNING: 	 vision_layers: 12
2024-05-22 04:15:01,345:WARNING: 	 vision_width: 768
2024-05-22 04:15:01,345:WARNING: 	 vision_patch_size: 32
2024-05-22 04:15:01,345:WARNING: 	 context_length: 77
2024-05-22 04:15:01,345:WARNING: 	 vocab_size: 49408
2024-05-22 04:15:01,345:WARNING: 	 transformer_width: 512
2024-05-22 04:15:01,345:WARNING: 	 transformer_heads: 8
2024-05-22 04:15:01,345:WARNING: 	 transformer_layers: 12
2024-05-22 04:15:01,345:WARNING: 	 cut_top_layer: 0
2024-05-22 04:15:02,355:WARNING: 	 sim_type: seqTransf
2024-05-22 04:15:06,854:INFO: --------------------
2024-05-22 04:15:06,854:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-22 04:15:08,654:INFO: ***** Running test *****
2024-05-22 04:15:08,654:INFO:   Num examples = 1
2024-05-22 04:15:08,654:INFO:   Batch size = 64
2024-05-22 04:15:08,655:INFO:   Num steps = 1
2024-05-22 04:16:12,735:INFO: device: cuda:0 n_gpu: 1
2024-05-22 04:16:12,809:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-22 04:16:13,048:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-22 04:16:13,049:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-22 04:16:13,050:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-22 04:16:13,050:WARNING: 	 embed_dim: 512
2024-05-22 04:16:13,051:WARNING: 	 image_resolution: 224
2024-05-22 04:16:13,051:WARNING: 	 vision_layers: 12
2024-05-22 04:16:13,051:WARNING: 	 vision_width: 768
2024-05-22 04:16:13,051:WARNING: 	 vision_patch_size: 32
2024-05-22 04:16:13,051:WARNING: 	 context_length: 77
2024-05-22 04:16:13,051:WARNING: 	 vocab_size: 49408
2024-05-22 04:16:13,051:WARNING: 	 transformer_width: 512
2024-05-22 04:16:13,051:WARNING: 	 transformer_heads: 8
2024-05-22 04:16:13,051:WARNING: 	 transformer_layers: 12
2024-05-22 04:16:13,051:WARNING: 	 cut_top_layer: 0
2024-05-22 04:16:14,055:WARNING: 	 sim_type: seqTransf
2024-05-22 04:16:18,571:INFO: --------------------
2024-05-22 04:16:18,571:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-22 04:16:20,353:INFO: ***** Running test *****
2024-05-22 04:16:20,353:INFO:   Num examples = 1
2024-05-22 04:16:20,354:INFO:   Batch size = 64
2024-05-22 04:16:20,354:INFO:   Num steps = 1
2024-05-22 04:16:58,022:INFO: device: cuda:0 n_gpu: 1
2024-05-22 04:16:58,092:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-22 04:16:58,332:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-22 04:16:58,334:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-22 04:16:58,334:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-22 04:16:58,334:WARNING: 	 embed_dim: 512
2024-05-22 04:16:58,335:WARNING: 	 image_resolution: 224
2024-05-22 04:16:58,335:WARNING: 	 vision_layers: 12
2024-05-22 04:16:58,335:WARNING: 	 vision_width: 768
2024-05-22 04:16:58,335:WARNING: 	 vision_patch_size: 32
2024-05-22 04:16:58,335:WARNING: 	 context_length: 77
2024-05-22 04:16:58,335:WARNING: 	 vocab_size: 49408
2024-05-22 04:16:58,335:WARNING: 	 transformer_width: 512
2024-05-22 04:16:58,335:WARNING: 	 transformer_heads: 8
2024-05-22 04:16:58,335:WARNING: 	 transformer_layers: 12
2024-05-22 04:16:58,335:WARNING: 	 cut_top_layer: 0
2024-05-22 04:16:59,342:WARNING: 	 sim_type: seqTransf
2024-05-22 04:17:03,834:INFO: --------------------
2024-05-22 04:17:03,834:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-22 04:17:05,643:INFO: ***** Running test *****
2024-05-22 04:17:05,643:INFO:   Num examples = 1
2024-05-22 04:17:05,643:INFO:   Batch size = 64
2024-05-22 04:17:05,644:INFO:   Num steps = 1
2024-05-22 04:19:51,477:INFO: device: cuda:0 n_gpu: 1
2024-05-22 04:19:51,478:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-22 04:19:51,720:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-22 04:19:51,721:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-22 04:19:51,721:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-22 04:19:51,722:WARNING: 	 embed_dim: 512
2024-05-22 04:19:51,722:WARNING: 	 image_resolution: 224
2024-05-22 04:19:51,722:WARNING: 	 vision_layers: 12
2024-05-22 04:19:51,722:WARNING: 	 vision_width: 768
2024-05-22 04:19:51,722:WARNING: 	 vision_patch_size: 32
2024-05-22 04:19:51,722:WARNING: 	 context_length: 77
2024-05-22 04:19:51,722:WARNING: 	 vocab_size: 49408
2024-05-22 04:19:51,722:WARNING: 	 transformer_width: 512
2024-05-22 04:19:51,722:WARNING: 	 transformer_heads: 8
2024-05-22 04:19:51,722:WARNING: 	 transformer_layers: 12
2024-05-22 04:19:51,722:WARNING: 	 cut_top_layer: 0
2024-05-22 04:19:52,743:WARNING: 	 sim_type: seqTransf
2024-05-22 04:19:57,234:INFO: --------------------
2024-05-22 04:19:57,235:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-22 04:20:49,197:INFO: device: cuda:0 n_gpu: 1
2024-05-22 04:20:49,267:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-22 04:20:49,509:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-22 04:20:49,510:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-22 04:20:49,510:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-22 04:20:49,511:WARNING: 	 embed_dim: 512
2024-05-22 04:20:49,511:WARNING: 	 image_resolution: 224
2024-05-22 04:20:49,511:WARNING: 	 vision_layers: 12
2024-05-22 04:20:49,511:WARNING: 	 vision_width: 768
2024-05-22 04:20:49,511:WARNING: 	 vision_patch_size: 32
2024-05-22 04:20:49,511:WARNING: 	 context_length: 77
2024-05-22 04:20:49,511:WARNING: 	 vocab_size: 49408
2024-05-22 04:20:49,511:WARNING: 	 transformer_width: 512
2024-05-22 04:20:49,511:WARNING: 	 transformer_heads: 8
2024-05-22 04:20:49,511:WARNING: 	 transformer_layers: 12
2024-05-22 04:20:49,511:WARNING: 	 cut_top_layer: 0
2024-05-22 04:20:50,517:WARNING: 	 sim_type: seqTransf
2024-05-22 04:20:55,011:INFO: --------------------
2024-05-22 04:20:55,012:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-22 04:20:56,799:INFO: ***** Running test *****
2024-05-22 04:20:56,799:INFO:   Num examples = 1
2024-05-22 04:20:56,799:INFO:   Batch size = 64
2024-05-22 04:20:56,799:INFO:   Num steps = 1
2024-05-22 04:21:15,710:INFO: device: cuda:0 n_gpu: 1
2024-05-22 04:21:15,779:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-22 04:21:16,016:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-22 04:21:16,018:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-22 04:21:16,018:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-22 04:21:16,019:WARNING: 	 embed_dim: 512
2024-05-22 04:21:16,019:WARNING: 	 image_resolution: 224
2024-05-22 04:21:16,019:WARNING: 	 vision_layers: 12
2024-05-22 04:21:16,019:WARNING: 	 vision_width: 768
2024-05-22 04:21:16,019:WARNING: 	 vision_patch_size: 32
2024-05-22 04:21:16,019:WARNING: 	 context_length: 77
2024-05-22 04:21:16,019:WARNING: 	 vocab_size: 49408
2024-05-22 04:21:16,019:WARNING: 	 transformer_width: 512
2024-05-22 04:21:16,019:WARNING: 	 transformer_heads: 8
2024-05-22 04:21:16,019:WARNING: 	 transformer_layers: 12
2024-05-22 04:21:16,019:WARNING: 	 cut_top_layer: 0
2024-05-22 04:21:17,023:WARNING: 	 sim_type: seqTransf
2024-05-22 04:21:21,475:INFO: --------------------
2024-05-22 04:21:21,476:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-22 04:21:23,265:INFO: ***** Running test *****
2024-05-22 04:21:23,266:INFO:   Num examples = 1
2024-05-22 04:21:23,266:INFO:   Batch size = 64
2024-05-22 04:21:23,266:INFO:   Num steps = 1
2024-05-22 04:21:45,904:INFO: device: cuda:0 n_gpu: 1
2024-05-22 04:21:45,975:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-22 04:21:46,213:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-22 04:21:46,214:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-22 04:21:46,214:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-22 04:21:46,215:WARNING: 	 embed_dim: 512
2024-05-22 04:21:46,215:WARNING: 	 image_resolution: 224
2024-05-22 04:21:46,215:WARNING: 	 vision_layers: 12
2024-05-22 04:21:46,215:WARNING: 	 vision_width: 768
2024-05-22 04:21:46,215:WARNING: 	 vision_patch_size: 32
2024-05-22 04:21:46,215:WARNING: 	 context_length: 77
2024-05-22 04:21:46,215:WARNING: 	 vocab_size: 49408
2024-05-22 04:21:46,216:WARNING: 	 transformer_width: 512
2024-05-22 04:21:46,216:WARNING: 	 transformer_heads: 8
2024-05-22 04:21:46,216:WARNING: 	 transformer_layers: 12
2024-05-22 04:21:46,216:WARNING: 	 cut_top_layer: 0
2024-05-22 04:21:47,224:WARNING: 	 sim_type: seqTransf
2024-05-22 04:21:51,737:INFO: --------------------
2024-05-22 04:21:51,737:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-22 04:21:53,523:INFO: ***** Running test *****
2024-05-22 04:21:53,523:INFO:   Num examples = 1
2024-05-22 04:21:53,523:INFO:   Batch size = 64
2024-05-22 04:21:53,523:INFO:   Num steps = 1
2024-05-22 04:23:31,309:INFO: device: cuda:0 n_gpu: 1
2024-05-22 04:23:31,310:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-22 04:23:31,555:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-22 04:23:31,556:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-22 04:23:31,556:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-22 04:23:31,557:WARNING: 	 embed_dim: 512
2024-05-22 04:23:31,557:WARNING: 	 image_resolution: 224
2024-05-22 04:23:31,557:WARNING: 	 vision_layers: 12
2024-05-22 04:23:31,557:WARNING: 	 vision_width: 768
2024-05-22 04:23:31,557:WARNING: 	 vision_patch_size: 32
2024-05-22 04:23:31,557:WARNING: 	 context_length: 77
2024-05-22 04:23:31,557:WARNING: 	 vocab_size: 49408
2024-05-22 04:23:31,557:WARNING: 	 transformer_width: 512
2024-05-22 04:23:31,557:WARNING: 	 transformer_heads: 8
2024-05-22 04:23:31,557:WARNING: 	 transformer_layers: 12
2024-05-22 04:23:31,557:WARNING: 	 cut_top_layer: 0
2024-05-22 04:23:32,566:WARNING: 	 sim_type: seqTransf
2024-05-22 04:23:37,058:INFO: --------------------
2024-05-22 04:23:37,059:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-22 04:24:48,502:INFO: device: cuda:0 n_gpu: 1
2024-05-22 04:24:48,570:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-22 04:24:48,821:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-22 04:24:48,823:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-22 04:24:48,823:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-22 04:24:48,824:WARNING: 	 embed_dim: 512
2024-05-22 04:24:48,824:WARNING: 	 image_resolution: 224
2024-05-22 04:24:48,824:WARNING: 	 vision_layers: 12
2024-05-22 04:24:48,824:WARNING: 	 vision_width: 768
2024-05-22 04:24:48,824:WARNING: 	 vision_patch_size: 32
2024-05-22 04:24:48,824:WARNING: 	 context_length: 77
2024-05-22 04:24:48,824:WARNING: 	 vocab_size: 49408
2024-05-22 04:24:48,824:WARNING: 	 transformer_width: 512
2024-05-22 04:24:48,824:WARNING: 	 transformer_heads: 8
2024-05-22 04:24:48,824:WARNING: 	 transformer_layers: 12
2024-05-22 04:24:48,824:WARNING: 	 cut_top_layer: 0
2024-05-22 04:24:49,838:WARNING: 	 sim_type: seqTransf
2024-05-22 04:24:54,338:INFO: --------------------
2024-05-22 04:24:54,338:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-22 04:24:56,136:INFO: ***** Running test *****
2024-05-22 04:24:56,136:INFO:   Num examples = 1
2024-05-22 04:24:56,136:INFO:   Batch size = 64
2024-05-22 04:24:56,136:INFO:   Num steps = 1
2024-05-22 04:25:30,217:INFO: device: cuda:0 n_gpu: 1
2024-05-22 04:25:30,285:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-22 04:25:30,524:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-22 04:25:30,525:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-22 04:25:30,525:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-22 04:25:30,526:WARNING: 	 embed_dim: 512
2024-05-22 04:25:30,526:WARNING: 	 image_resolution: 224
2024-05-22 04:25:30,526:WARNING: 	 vision_layers: 12
2024-05-22 04:25:30,526:WARNING: 	 vision_width: 768
2024-05-22 04:25:30,526:WARNING: 	 vision_patch_size: 32
2024-05-22 04:25:30,526:WARNING: 	 context_length: 77
2024-05-22 04:25:30,526:WARNING: 	 vocab_size: 49408
2024-05-22 04:25:30,526:WARNING: 	 transformer_width: 512
2024-05-22 04:25:30,526:WARNING: 	 transformer_heads: 8
2024-05-22 04:25:30,526:WARNING: 	 transformer_layers: 12
2024-05-22 04:25:30,526:WARNING: 	 cut_top_layer: 0
2024-05-22 04:25:31,542:WARNING: 	 sim_type: seqTransf
2024-05-22 04:25:36,043:INFO: --------------------
2024-05-22 04:25:36,043:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-22 04:25:37,841:INFO: ***** Running test *****
2024-05-22 04:25:37,841:INFO:   Num examples = 1
2024-05-22 04:25:37,841:INFO:   Batch size = 64
2024-05-22 04:25:37,841:INFO:   Num steps = 1
2024-05-22 04:25:49,610:INFO: device: cuda:0 n_gpu: 1
2024-05-22 04:25:49,685:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-22 04:25:49,928:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-22 04:25:49,929:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-22 04:25:49,930:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-22 04:25:49,930:WARNING: 	 embed_dim: 512
2024-05-22 04:25:49,931:WARNING: 	 image_resolution: 224
2024-05-22 04:25:49,931:WARNING: 	 vision_layers: 12
2024-05-22 04:25:49,931:WARNING: 	 vision_width: 768
2024-05-22 04:25:49,931:WARNING: 	 vision_patch_size: 32
2024-05-22 04:25:49,931:WARNING: 	 context_length: 77
2024-05-22 04:25:49,931:WARNING: 	 vocab_size: 49408
2024-05-22 04:25:49,931:WARNING: 	 transformer_width: 512
2024-05-22 04:25:49,931:WARNING: 	 transformer_heads: 8
2024-05-22 04:25:49,931:WARNING: 	 transformer_layers: 12
2024-05-22 04:25:49,931:WARNING: 	 cut_top_layer: 0
2024-05-22 04:25:50,922:WARNING: 	 sim_type: seqTransf
2024-05-22 04:25:55,392:INFO: --------------------
2024-05-22 04:25:55,392:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-22 04:25:57,180:INFO: ***** Running test *****
2024-05-22 04:25:57,180:INFO:   Num examples = 1
2024-05-22 04:25:57,180:INFO:   Batch size = 64
2024-05-22 04:25:57,180:INFO:   Num steps = 1
2024-05-22 04:26:23,861:INFO: device: cuda:0 n_gpu: 1
2024-05-22 04:26:23,930:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-22 04:26:24,173:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-22 04:26:24,175:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-22 04:26:24,175:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-22 04:26:24,176:WARNING: 	 embed_dim: 512
2024-05-22 04:26:24,176:WARNING: 	 image_resolution: 224
2024-05-22 04:26:24,176:WARNING: 	 vision_layers: 12
2024-05-22 04:26:24,176:WARNING: 	 vision_width: 768
2024-05-22 04:26:24,176:WARNING: 	 vision_patch_size: 32
2024-05-22 04:26:24,176:WARNING: 	 context_length: 77
2024-05-22 04:26:24,176:WARNING: 	 vocab_size: 49408
2024-05-22 04:26:24,176:WARNING: 	 transformer_width: 512
2024-05-22 04:26:24,176:WARNING: 	 transformer_heads: 8
2024-05-22 04:26:24,176:WARNING: 	 transformer_layers: 12
2024-05-22 04:26:24,176:WARNING: 	 cut_top_layer: 0
2024-05-22 04:26:25,185:WARNING: 	 sim_type: seqTransf
2024-05-22 04:26:29,690:INFO: --------------------
2024-05-22 04:26:29,690:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-22 04:26:31,464:INFO: ***** Running test *****
2024-05-22 04:26:31,464:INFO:   Num examples = 1
2024-05-22 04:26:31,465:INFO:   Batch size = 64
2024-05-22 04:26:31,465:INFO:   Num steps = 1
2024-05-22 04:27:18,390:INFO: device: cuda:0 n_gpu: 1
2024-05-22 04:27:18,461:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-22 04:27:18,685:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-22 04:27:18,685:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-22 04:27:18,685:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-22 04:27:18,685:WARNING: 	 embed_dim: 512
2024-05-22 04:27:18,685:WARNING: 	 image_resolution: 224
2024-05-22 04:27:18,685:WARNING: 	 vision_layers: 12
2024-05-22 04:27:18,685:WARNING: 	 vision_width: 768
2024-05-22 04:27:18,685:WARNING: 	 vision_patch_size: 32
2024-05-22 04:27:18,685:WARNING: 	 context_length: 77
2024-05-22 04:27:18,685:WARNING: 	 vocab_size: 49408
2024-05-22 04:27:18,685:WARNING: 	 transformer_width: 512
2024-05-22 04:27:18,685:WARNING: 	 transformer_heads: 8
2024-05-22 04:27:18,685:WARNING: 	 transformer_layers: 12
2024-05-22 04:27:18,685:WARNING: 	 cut_top_layer: 0
2024-05-22 04:27:19,665:WARNING: 	 sim_type: seqTransf
2024-05-22 04:27:24,120:INFO: --------------------
2024-05-22 04:27:24,120:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-22 04:27:25,897:INFO: ***** Running test *****
2024-05-22 04:27:25,897:INFO:   Num examples = 1
2024-05-22 04:27:25,898:INFO:   Batch size = 64
2024-05-22 04:27:25,898:INFO:   Num steps = 1
2024-05-22 04:27:26,179:INFO: sim matrix size: 1, 1
2024-05-22 04:27:26,179:INFO: 	 Length-T: 1, Length-V:1
2024-05-22 04:27:26,179:INFO: Text-to-Video:
2024-05-22 04:27:26,179:INFO: 	>>>  R@1: 100.0 - R@5: 100.0 - R@10: 100.0 - Median R: 1.0 - Mean R: 1.0
2024-05-22 04:27:26,179:INFO: Video-to-Text:
2024-05-22 04:27:26,179:INFO: 	>>>  V2T$R@1: 100.0 - V2T$R@5: 100.0 - V2T$R@10: 100.0 - V2T$Median R: 1.0 - V2T$Mean R: 1.0
2024-05-22 04:56:47,762:INFO: device: cuda:0 n_gpu: 1
2024-05-22 04:56:47,762:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-22 04:56:47,998:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-22 04:56:47,998:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-22 04:56:47,998:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-22 04:56:47,998:WARNING: 	 embed_dim: 512
2024-05-22 04:56:47,998:WARNING: 	 image_resolution: 224
2024-05-22 04:56:47,998:WARNING: 	 vision_layers: 12
2024-05-22 04:56:47,998:WARNING: 	 vision_width: 768
2024-05-22 04:56:47,998:WARNING: 	 vision_patch_size: 32
2024-05-22 04:56:47,998:WARNING: 	 context_length: 77
2024-05-22 04:56:47,998:WARNING: 	 vocab_size: 49408
2024-05-22 04:56:47,998:WARNING: 	 transformer_width: 512
2024-05-22 04:56:47,998:WARNING: 	 transformer_heads: 8
2024-05-22 04:56:47,998:WARNING: 	 transformer_layers: 12
2024-05-22 04:56:47,998:WARNING: 	 cut_top_layer: 0
2024-05-22 04:56:49,114:WARNING: 	 sim_type: seqTransf
2024-05-22 04:56:53,628:INFO: --------------------
2024-05-22 04:56:53,628:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-22 04:57:43,704:INFO: device: cuda:0 n_gpu: 1
2024-05-22 04:57:43,704:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-22 04:57:43,945:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-22 04:57:43,946:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-22 04:57:43,946:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-22 04:57:43,947:WARNING: 	 embed_dim: 512
2024-05-22 04:57:43,947:WARNING: 	 image_resolution: 224
2024-05-22 04:57:43,947:WARNING: 	 vision_layers: 12
2024-05-22 04:57:43,947:WARNING: 	 vision_width: 768
2024-05-22 04:57:43,947:WARNING: 	 vision_patch_size: 32
2024-05-22 04:57:43,947:WARNING: 	 context_length: 77
2024-05-22 04:57:43,947:WARNING: 	 vocab_size: 49408
2024-05-22 04:57:43,947:WARNING: 	 transformer_width: 512
2024-05-22 04:57:43,947:WARNING: 	 transformer_heads: 8
2024-05-22 04:57:43,947:WARNING: 	 transformer_layers: 12
2024-05-22 04:57:43,947:WARNING: 	 cut_top_layer: 0
2024-05-22 04:57:44,949:WARNING: 	 sim_type: seqTransf
2024-05-22 04:57:49,440:INFO: --------------------
2024-05-22 04:57:49,440:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-22 04:58:46,493:INFO: device: cuda:0 n_gpu: 1
2024-05-22 04:58:46,493:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-22 04:58:46,745:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-22 04:58:46,746:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-22 04:58:46,746:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-22 04:58:46,747:WARNING: 	 embed_dim: 512
2024-05-22 04:58:46,747:WARNING: 	 image_resolution: 224
2024-05-22 04:58:46,747:WARNING: 	 vision_layers: 12
2024-05-22 04:58:46,747:WARNING: 	 vision_width: 768
2024-05-22 04:58:46,747:WARNING: 	 vision_patch_size: 32
2024-05-22 04:58:46,747:WARNING: 	 context_length: 77
2024-05-22 04:58:46,747:WARNING: 	 vocab_size: 49408
2024-05-22 04:58:46,747:WARNING: 	 transformer_width: 512
2024-05-22 04:58:46,748:WARNING: 	 transformer_heads: 8
2024-05-22 04:58:46,748:WARNING: 	 transformer_layers: 12
2024-05-22 04:58:46,748:WARNING: 	 cut_top_layer: 0
2024-05-22 04:58:47,764:WARNING: 	 sim_type: seqTransf
2024-05-22 04:58:52,274:INFO: --------------------
2024-05-22 04:58:52,274:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-22 04:59:26,225:INFO: device: cuda:0 n_gpu: 1
2024-05-22 04:59:26,225:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-22 04:59:26,456:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-22 04:59:26,456:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-22 04:59:26,456:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-22 04:59:26,456:WARNING: 	 embed_dim: 512
2024-05-22 04:59:26,456:WARNING: 	 image_resolution: 224
2024-05-22 04:59:26,456:WARNING: 	 vision_layers: 12
2024-05-22 04:59:26,456:WARNING: 	 vision_width: 768
2024-05-22 04:59:26,456:WARNING: 	 vision_patch_size: 32
2024-05-22 04:59:26,456:WARNING: 	 context_length: 77
2024-05-22 04:59:26,456:WARNING: 	 vocab_size: 49408
2024-05-22 04:59:26,456:WARNING: 	 transformer_width: 512
2024-05-22 04:59:26,456:WARNING: 	 transformer_heads: 8
2024-05-22 04:59:26,456:WARNING: 	 transformer_layers: 12
2024-05-22 04:59:26,456:WARNING: 	 cut_top_layer: 0
2024-05-22 04:59:27,444:WARNING: 	 sim_type: seqTransf
2024-05-22 04:59:31,923:INFO: --------------------
2024-05-22 04:59:31,923:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-22 05:06:49,789:INFO: device: cuda:0 n_gpu: 1
2024-05-22 05:06:49,789:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-22 05:06:50,020:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-22 05:06:50,020:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-22 05:06:50,020:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-22 05:06:50,020:WARNING: 	 embed_dim: 512
2024-05-22 05:06:50,020:WARNING: 	 image_resolution: 224
2024-05-22 05:06:50,020:WARNING: 	 vision_layers: 12
2024-05-22 05:06:50,020:WARNING: 	 vision_width: 768
2024-05-22 05:06:50,020:WARNING: 	 vision_patch_size: 32
2024-05-22 05:06:50,020:WARNING: 	 context_length: 77
2024-05-22 05:06:50,020:WARNING: 	 vocab_size: 49408
2024-05-22 05:06:50,020:WARNING: 	 transformer_width: 512
2024-05-22 05:06:50,020:WARNING: 	 transformer_heads: 8
2024-05-22 05:06:50,020:WARNING: 	 transformer_layers: 12
2024-05-22 05:06:50,020:WARNING: 	 cut_top_layer: 0
2024-05-22 05:06:51,060:WARNING: 	 sim_type: seqTransf
2024-05-22 05:06:55,552:INFO: --------------------
2024-05-22 05:06:55,552:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-22 05:07:06,881:INFO: device: cuda:0 n_gpu: 1
2024-05-22 05:07:06,881:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-22 05:07:07,112:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-22 05:07:07,113:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-22 05:07:07,113:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-22 05:07:07,113:WARNING: 	 embed_dim: 512
2024-05-22 05:07:07,113:WARNING: 	 image_resolution: 224
2024-05-22 05:07:07,113:WARNING: 	 vision_layers: 12
2024-05-22 05:07:07,113:WARNING: 	 vision_width: 768
2024-05-22 05:07:07,113:WARNING: 	 vision_patch_size: 32
2024-05-22 05:07:07,113:WARNING: 	 context_length: 77
2024-05-22 05:07:07,113:WARNING: 	 vocab_size: 49408
2024-05-22 05:07:07,113:WARNING: 	 transformer_width: 512
2024-05-22 05:07:07,113:WARNING: 	 transformer_heads: 8
2024-05-22 05:07:07,113:WARNING: 	 transformer_layers: 12
2024-05-22 05:07:07,113:WARNING: 	 cut_top_layer: 0
2024-05-22 05:07:08,110:WARNING: 	 sim_type: seqTransf
2024-05-22 05:07:12,596:INFO: --------------------
2024-05-22 05:07:12,596:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-22 06:03:44,351:INFO: device: cuda:0 n_gpu: 1
2024-05-22 06:03:44,351:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-22 06:03:44,581:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-22 06:03:44,581:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-22 06:03:44,581:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-22 06:03:44,581:WARNING: 	 embed_dim: 512
2024-05-22 06:03:44,581:WARNING: 	 image_resolution: 224
2024-05-22 06:03:44,581:WARNING: 	 vision_layers: 12
2024-05-22 06:03:44,581:WARNING: 	 vision_width: 768
2024-05-22 06:03:44,581:WARNING: 	 vision_patch_size: 32
2024-05-22 06:03:44,581:WARNING: 	 context_length: 77
2024-05-22 06:03:44,581:WARNING: 	 vocab_size: 49408
2024-05-22 06:03:44,581:WARNING: 	 transformer_width: 512
2024-05-22 06:03:44,581:WARNING: 	 transformer_heads: 8
2024-05-22 06:03:44,581:WARNING: 	 transformer_layers: 12
2024-05-22 06:03:44,581:WARNING: 	 cut_top_layer: 0
2024-05-22 06:03:45,570:WARNING: 	 sim_type: seqTransf
2024-05-22 06:03:50,058:INFO: --------------------
2024-05-22 06:03:50,058:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-22 06:06:00,537:INFO: device: cuda:0 n_gpu: 1
2024-05-22 06:06:00,537:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-22 06:06:00,767:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-22 06:06:00,767:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-22 06:06:00,767:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-22 06:06:00,767:WARNING: 	 embed_dim: 512
2024-05-22 06:06:00,767:WARNING: 	 image_resolution: 224
2024-05-22 06:06:00,767:WARNING: 	 vision_layers: 12
2024-05-22 06:06:00,767:WARNING: 	 vision_width: 768
2024-05-22 06:06:00,767:WARNING: 	 vision_patch_size: 32
2024-05-22 06:06:00,767:WARNING: 	 context_length: 77
2024-05-22 06:06:00,767:WARNING: 	 vocab_size: 49408
2024-05-22 06:06:00,767:WARNING: 	 transformer_width: 512
2024-05-22 06:06:00,767:WARNING: 	 transformer_heads: 8
2024-05-22 06:06:00,767:WARNING: 	 transformer_layers: 12
2024-05-22 06:06:00,767:WARNING: 	 cut_top_layer: 0
2024-05-22 06:06:01,758:WARNING: 	 sim_type: seqTransf
2024-05-22 06:06:06,243:INFO: --------------------
2024-05-22 06:06:06,243:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-22 06:06:54,841:INFO: device: cuda:0 n_gpu: 1
2024-05-22 06:06:54,842:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-22 06:06:55,087:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-22 06:06:55,088:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-22 06:06:55,088:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-22 06:06:55,089:WARNING: 	 embed_dim: 512
2024-05-22 06:06:55,090:WARNING: 	 image_resolution: 224
2024-05-22 06:06:55,090:WARNING: 	 vision_layers: 12
2024-05-22 06:06:55,090:WARNING: 	 vision_width: 768
2024-05-22 06:06:55,090:WARNING: 	 vision_patch_size: 32
2024-05-22 06:06:55,090:WARNING: 	 context_length: 77
2024-05-22 06:06:55,090:WARNING: 	 vocab_size: 49408
2024-05-22 06:06:55,090:WARNING: 	 transformer_width: 512
2024-05-22 06:06:55,090:WARNING: 	 transformer_heads: 8
2024-05-22 06:06:55,090:WARNING: 	 transformer_layers: 12
2024-05-22 06:06:55,091:WARNING: 	 cut_top_layer: 0
2024-05-22 06:06:56,111:WARNING: 	 sim_type: seqTransf
2024-05-22 06:07:00,549:INFO: --------------------
2024-05-22 06:07:00,549:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-22 06:09:10,757:INFO: device: cuda:0 n_gpu: 1
2024-05-22 06:09:10,757:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-22 06:09:10,998:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-22 06:09:10,999:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-22 06:09:10,999:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-22 06:09:11,000:WARNING: 	 embed_dim: 512
2024-05-22 06:09:11,000:WARNING: 	 image_resolution: 224
2024-05-22 06:09:11,000:WARNING: 	 vision_layers: 12
2024-05-22 06:09:11,000:WARNING: 	 vision_width: 768
2024-05-22 06:09:11,000:WARNING: 	 vision_patch_size: 32
2024-05-22 06:09:11,000:WARNING: 	 context_length: 77
2024-05-22 06:09:11,000:WARNING: 	 vocab_size: 49408
2024-05-22 06:09:11,000:WARNING: 	 transformer_width: 512
2024-05-22 06:09:11,000:WARNING: 	 transformer_heads: 8
2024-05-22 06:09:11,000:WARNING: 	 transformer_layers: 12
2024-05-22 06:09:11,000:WARNING: 	 cut_top_layer: 0
2024-05-22 06:09:12,015:WARNING: 	 sim_type: seqTransf
2024-05-22 06:09:16,543:INFO: --------------------
2024-05-22 06:09:16,543:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-22 06:10:48,403:INFO: device: cuda:0 n_gpu: 1
2024-05-22 06:10:48,403:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-22 06:10:48,636:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-22 06:10:48,636:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-22 06:10:48,637:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-22 06:10:48,637:WARNING: 	 embed_dim: 512
2024-05-22 06:10:48,637:WARNING: 	 image_resolution: 224
2024-05-22 06:10:48,637:WARNING: 	 vision_layers: 12
2024-05-22 06:10:48,637:WARNING: 	 vision_width: 768
2024-05-22 06:10:48,637:WARNING: 	 vision_patch_size: 32
2024-05-22 06:10:48,637:WARNING: 	 context_length: 77
2024-05-22 06:10:48,637:WARNING: 	 vocab_size: 49408
2024-05-22 06:10:48,637:WARNING: 	 transformer_width: 512
2024-05-22 06:10:48,637:WARNING: 	 transformer_heads: 8
2024-05-22 06:10:48,637:WARNING: 	 transformer_layers: 12
2024-05-22 06:10:48,637:WARNING: 	 cut_top_layer: 0
2024-05-22 06:10:49,632:WARNING: 	 sim_type: seqTransf
2024-05-22 06:10:54,143:INFO: --------------------
2024-05-22 06:10:54,143:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-22 06:12:30,045:INFO: device: cuda:0 n_gpu: 1
2024-05-22 06:12:30,046:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-22 06:12:30,276:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-22 06:12:30,277:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-22 06:12:30,277:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-22 06:12:30,277:WARNING: 	 embed_dim: 512
2024-05-22 06:12:30,277:WARNING: 	 image_resolution: 224
2024-05-22 06:12:30,277:WARNING: 	 vision_layers: 12
2024-05-22 06:12:30,277:WARNING: 	 vision_width: 768
2024-05-22 06:12:30,277:WARNING: 	 vision_patch_size: 32
2024-05-22 06:12:30,277:WARNING: 	 context_length: 77
2024-05-22 06:12:30,277:WARNING: 	 vocab_size: 49408
2024-05-22 06:12:30,277:WARNING: 	 transformer_width: 512
2024-05-22 06:12:30,277:WARNING: 	 transformer_heads: 8
2024-05-22 06:12:30,277:WARNING: 	 transformer_layers: 12
2024-05-22 06:12:30,277:WARNING: 	 cut_top_layer: 0
2024-05-22 06:12:31,264:WARNING: 	 sim_type: seqTransf
2024-05-22 06:12:35,740:INFO: --------------------
2024-05-22 06:12:35,740:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-22 06:15:55,871:INFO: device: cuda:0 n_gpu: 1
2024-05-22 06:15:55,871:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-22 06:15:56,106:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-22 06:15:56,106:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-22 06:15:56,107:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-22 06:15:56,107:WARNING: 	 embed_dim: 512
2024-05-22 06:15:56,107:WARNING: 	 image_resolution: 224
2024-05-22 06:15:56,107:WARNING: 	 vision_layers: 12
2024-05-22 06:15:56,107:WARNING: 	 vision_width: 768
2024-05-22 06:15:56,107:WARNING: 	 vision_patch_size: 32
2024-05-22 06:15:56,107:WARNING: 	 context_length: 77
2024-05-22 06:15:56,107:WARNING: 	 vocab_size: 49408
2024-05-22 06:15:56,107:WARNING: 	 transformer_width: 512
2024-05-22 06:15:56,107:WARNING: 	 transformer_heads: 8
2024-05-22 06:15:56,107:WARNING: 	 transformer_layers: 12
2024-05-22 06:15:56,107:WARNING: 	 cut_top_layer: 0
2024-05-22 06:15:57,102:WARNING: 	 sim_type: seqTransf
2024-05-22 06:16:01,611:INFO: --------------------
2024-05-22 06:16:01,611:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-22 06:16:13,634:INFO: device: cuda:0 n_gpu: 1
2024-05-22 06:16:13,634:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-22 06:16:13,869:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-22 06:16:13,869:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-22 06:16:13,869:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-22 06:16:13,869:WARNING: 	 embed_dim: 512
2024-05-22 06:16:13,869:WARNING: 	 image_resolution: 224
2024-05-22 06:16:13,869:WARNING: 	 vision_layers: 12
2024-05-22 06:16:13,869:WARNING: 	 vision_width: 768
2024-05-22 06:16:13,869:WARNING: 	 vision_patch_size: 32
2024-05-22 06:16:13,869:WARNING: 	 context_length: 77
2024-05-22 06:16:13,869:WARNING: 	 vocab_size: 49408
2024-05-22 06:16:13,869:WARNING: 	 transformer_width: 512
2024-05-22 06:16:13,869:WARNING: 	 transformer_heads: 8
2024-05-22 06:16:13,869:WARNING: 	 transformer_layers: 12
2024-05-22 06:16:13,869:WARNING: 	 cut_top_layer: 0
2024-05-22 06:16:14,865:WARNING: 	 sim_type: seqTransf
2024-05-22 06:16:19,352:INFO: --------------------
2024-05-22 06:16:19,352:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-22 06:17:47,800:INFO: device: cuda:0 n_gpu: 1
2024-05-22 06:17:47,870:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-22 06:17:48,092:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-22 06:17:48,092:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-22 06:17:48,093:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-22 06:17:48,093:WARNING: 	 embed_dim: 512
2024-05-22 06:17:48,093:WARNING: 	 image_resolution: 224
2024-05-22 06:17:48,093:WARNING: 	 vision_layers: 12
2024-05-22 06:17:48,093:WARNING: 	 vision_width: 768
2024-05-22 06:17:48,093:WARNING: 	 vision_patch_size: 32
2024-05-22 06:17:48,093:WARNING: 	 context_length: 77
2024-05-22 06:17:48,093:WARNING: 	 vocab_size: 49408
2024-05-22 06:17:48,093:WARNING: 	 transformer_width: 512
2024-05-22 06:17:48,093:WARNING: 	 transformer_heads: 8
2024-05-22 06:17:48,093:WARNING: 	 transformer_layers: 12
2024-05-22 06:17:48,093:WARNING: 	 cut_top_layer: 0
2024-05-22 06:17:49,078:WARNING: 	 sim_type: seqTransf
2024-05-22 06:17:53,562:INFO: --------------------
2024-05-22 06:17:53,562:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-22 06:17:55,352:INFO: ***** Running test *****
2024-05-22 06:17:55,352:INFO:   Num examples = 1
2024-05-22 06:17:55,352:INFO:   Batch size = 64
2024-05-22 06:17:55,352:INFO:   Num steps = 1
2024-05-22 06:19:14,345:INFO: device: cuda:0 n_gpu: 1
2024-05-22 06:19:14,416:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-22 06:19:14,637:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-22 06:19:14,638:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-22 06:19:14,638:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-22 06:19:14,638:WARNING: 	 embed_dim: 512
2024-05-22 06:19:14,638:WARNING: 	 image_resolution: 224
2024-05-22 06:19:14,638:WARNING: 	 vision_layers: 12
2024-05-22 06:19:14,638:WARNING: 	 vision_width: 768
2024-05-22 06:19:14,638:WARNING: 	 vision_patch_size: 32
2024-05-22 06:19:14,638:WARNING: 	 context_length: 77
2024-05-22 06:19:14,638:WARNING: 	 vocab_size: 49408
2024-05-22 06:19:14,638:WARNING: 	 transformer_width: 512
2024-05-22 06:19:14,638:WARNING: 	 transformer_heads: 8
2024-05-22 06:19:14,638:WARNING: 	 transformer_layers: 12
2024-05-22 06:19:14,638:WARNING: 	 cut_top_layer: 0
2024-05-22 06:19:15,629:WARNING: 	 sim_type: seqTransf
2024-05-22 06:19:20,115:INFO: --------------------
2024-05-22 06:19:20,115:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-22 06:19:21,880:INFO: ***** Running test *****
2024-05-22 06:19:21,880:INFO:   Num examples = 1
2024-05-22 06:19:21,880:INFO:   Batch size = 64
2024-05-22 06:19:21,880:INFO:   Num steps = 1
2024-05-22 06:19:22,128:INFO: sim matrix size: 1, 1
2024-05-22 06:19:22,128:INFO: 	 Length-T: 1, Length-V:1
2024-05-22 06:19:22,128:INFO: Text-to-Video:
2024-05-22 06:19:22,128:INFO: 	>>>  R@1: 100.0 - R@5: 100.0 - R@10: 100.0 - Median R: 1.0 - Mean R: 1.0
2024-05-22 06:19:22,128:INFO: Video-to-Text:
2024-05-22 06:19:22,128:INFO: 	>>>  V2T$R@1: 100.0 - V2T$R@5: 100.0 - V2T$R@10: 100.0 - V2T$Median R: 1.0 - V2T$Mean R: 1.0
2024-05-22 06:22:14,960:INFO: device: cuda:0 n_gpu: 1
2024-05-22 06:22:14,960:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-22 06:22:15,191:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-22 06:22:15,191:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-22 06:22:15,191:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-22 06:22:15,191:WARNING: 	 embed_dim: 512
2024-05-22 06:22:15,191:WARNING: 	 image_resolution: 224
2024-05-22 06:22:15,191:WARNING: 	 vision_layers: 12
2024-05-22 06:22:15,191:WARNING: 	 vision_width: 768
2024-05-22 06:22:15,191:WARNING: 	 vision_patch_size: 32
2024-05-22 06:22:15,191:WARNING: 	 context_length: 77
2024-05-22 06:22:15,191:WARNING: 	 vocab_size: 49408
2024-05-22 06:22:15,191:WARNING: 	 transformer_width: 512
2024-05-22 06:22:15,191:WARNING: 	 transformer_heads: 8
2024-05-22 06:22:15,191:WARNING: 	 transformer_layers: 12
2024-05-22 06:22:15,191:WARNING: 	 cut_top_layer: 0
2024-05-22 06:22:16,178:WARNING: 	 sim_type: seqTransf
2024-05-22 06:22:20,660:INFO: --------------------
2024-05-22 06:22:20,660:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-22 06:22:36,973:INFO: device: cuda:0 n_gpu: 1
2024-05-22 06:22:36,973:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-22 06:22:37,203:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-22 06:22:37,204:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-22 06:22:37,204:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-22 06:22:37,204:WARNING: 	 embed_dim: 512
2024-05-22 06:22:37,204:WARNING: 	 image_resolution: 224
2024-05-22 06:22:37,204:WARNING: 	 vision_layers: 12
2024-05-22 06:22:37,204:WARNING: 	 vision_width: 768
2024-05-22 06:22:37,204:WARNING: 	 vision_patch_size: 32
2024-05-22 06:22:37,204:WARNING: 	 context_length: 77
2024-05-22 06:22:37,204:WARNING: 	 vocab_size: 49408
2024-05-22 06:22:37,204:WARNING: 	 transformer_width: 512
2024-05-22 06:22:37,204:WARNING: 	 transformer_heads: 8
2024-05-22 06:22:37,204:WARNING: 	 transformer_layers: 12
2024-05-22 06:22:37,204:WARNING: 	 cut_top_layer: 0
2024-05-22 06:22:38,205:WARNING: 	 sim_type: seqTransf
2024-05-22 06:22:42,684:INFO: --------------------
2024-05-22 06:22:42,684:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-22 06:23:25,468:INFO: device: cuda:0 n_gpu: 1
2024-05-22 06:23:25,537:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-22 06:23:25,757:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-22 06:23:25,757:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-22 06:23:25,757:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-22 06:23:25,757:WARNING: 	 embed_dim: 512
2024-05-22 06:23:25,757:WARNING: 	 image_resolution: 224
2024-05-22 06:23:25,757:WARNING: 	 vision_layers: 12
2024-05-22 06:23:25,757:WARNING: 	 vision_width: 768
2024-05-22 06:23:25,757:WARNING: 	 vision_patch_size: 32
2024-05-22 06:23:25,757:WARNING: 	 context_length: 77
2024-05-22 06:23:25,757:WARNING: 	 vocab_size: 49408
2024-05-22 06:23:25,757:WARNING: 	 transformer_width: 512
2024-05-22 06:23:25,757:WARNING: 	 transformer_heads: 8
2024-05-22 06:23:25,757:WARNING: 	 transformer_layers: 12
2024-05-22 06:23:25,757:WARNING: 	 cut_top_layer: 0
2024-05-22 06:23:26,744:WARNING: 	 sim_type: seqTransf
2024-05-22 06:23:31,231:INFO: --------------------
2024-05-22 06:23:31,231:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-22 06:23:33,005:INFO: ***** Running test *****
2024-05-22 06:23:33,005:INFO:   Num examples = 1
2024-05-22 06:23:33,005:INFO:   Batch size = 64
2024-05-22 06:23:33,005:INFO:   Num steps = 1
2024-05-22 06:23:33,251:INFO: sim matrix size: 1, 1
2024-05-22 06:23:33,251:INFO: 	 Length-T: 1, Length-V:1
2024-05-22 06:23:33,251:INFO: Text-to-Video:
2024-05-22 06:23:33,251:INFO: 	>>>  R@1: 100.0 - R@5: 100.0 - R@10: 100.0 - Median R: 1.0 - Mean R: 1.0
2024-05-22 06:23:33,251:INFO: Video-to-Text:
2024-05-22 06:23:33,251:INFO: 	>>>  V2T$R@1: 100.0 - V2T$R@5: 100.0 - V2T$R@10: 100.0 - V2T$Median R: 1.0 - V2T$Mean R: 1.0
2024-05-22 06:33:19,844:INFO: device: cuda:0 n_gpu: 1
2024-05-22 06:33:19,844:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-22 06:33:20,076:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-22 06:33:20,076:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-22 06:33:20,076:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-22 06:33:20,077:WARNING: 	 embed_dim: 512
2024-05-22 06:33:20,077:WARNING: 	 image_resolution: 224
2024-05-22 06:33:20,077:WARNING: 	 vision_layers: 12
2024-05-22 06:33:20,077:WARNING: 	 vision_width: 768
2024-05-22 06:33:20,077:WARNING: 	 vision_patch_size: 32
2024-05-22 06:33:20,077:WARNING: 	 context_length: 77
2024-05-22 06:33:20,077:WARNING: 	 vocab_size: 49408
2024-05-22 06:33:20,077:WARNING: 	 transformer_width: 512
2024-05-22 06:33:20,077:WARNING: 	 transformer_heads: 8
2024-05-22 06:33:20,077:WARNING: 	 transformer_layers: 12
2024-05-22 06:33:20,077:WARNING: 	 cut_top_layer: 0
2024-05-22 06:33:21,073:WARNING: 	 sim_type: seqTransf
2024-05-22 06:33:25,562:INFO: --------------------
2024-05-22 06:33:25,562:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-22 06:35:30,881:INFO: device: cuda:0 n_gpu: 1
2024-05-22 06:35:30,951:INFO: Model loaded fail /workspace/CLIP4Clip/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2/pytorch_model.bin.2
2024-05-22 06:35:31,199:INFO: loading archive file /workspace/CLIP4Clip/CLIP2Video/modules/cross-base
2024-05-22 06:35:31,200:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "max_position_embeddings": 77,
  "num_attention_heads": 8,
  "num_hidden_layers": 4,
  "type_vocab_size": 2,
  "vocab_size": 512
}

2024-05-22 06:35:31,200:INFO: Weight doesn't exsits. /workspace/CLIP4Clip/CLIP2Video/modules/cross-base/cross_pytorch_model.bin
2024-05-22 06:35:31,201:WARNING: 	 embed_dim: 512
2024-05-22 06:35:31,201:WARNING: 	 image_resolution: 224
2024-05-22 06:35:31,201:WARNING: 	 vision_layers: 12
2024-05-22 06:35:31,201:WARNING: 	 vision_width: 768
2024-05-22 06:35:31,201:WARNING: 	 vision_patch_size: 32
2024-05-22 06:35:31,201:WARNING: 	 context_length: 77
2024-05-22 06:35:31,201:WARNING: 	 vocab_size: 49408
2024-05-22 06:35:31,201:WARNING: 	 transformer_width: 512
2024-05-22 06:35:31,201:WARNING: 	 transformer_heads: 8
2024-05-22 06:35:31,202:WARNING: 	 transformer_layers: 12
2024-05-22 06:35:31,202:WARNING: 	 cut_top_layer: 0
2024-05-22 06:35:32,208:WARNING: 	 sim_type: seqTransf
2024-05-22 06:35:36,717:INFO: --------------------
2024-05-22 06:35:36,718:INFO: Weights of CLIP2Video not initialized from pretrained model: 
   weight_center
   emb_center
   trans_layernorm.weight
   trans_layernorm.bias
2024-05-22 06:35:38,497:INFO: ***** Running test *****
2024-05-22 06:35:38,497:INFO:   Num examples = 1
2024-05-22 06:35:38,497:INFO:   Batch size = 64
2024-05-22 06:35:38,497:INFO:   Num steps = 1
